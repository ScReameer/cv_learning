{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TdBk6CFF-RVl"
   },
   "source": [
    "Воспользуйтеесь инструкцией с https://www.analyticsvidhya.com/blog/2021/06/how-to-load-kaggle-datasets-directly-into-google-colab/ для скачки датасета"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N5OZ5GBZaUYa",
    "outputId": "a294bdf7-ba1e-4c9b-eb83-a660d2f46d4b"
   },
   "source": [
    "!mkdir ~/.kaggle\n",
    "!pip install kaggle\n",
    "!cp kaggle.json ~/.kaggle/kaggle.json\n",
    "!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8dQ-b0U3_b_J",
    "outputId": "d923811a-0e4e-41aa-ece6-c8c703921e33"
   },
   "source": [
    "!unzip -qq chest-xray-pneumonia.zip"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jrMGRbREgLrP",
    "outputId": "5cceb1e0-62e1-4623-da4d-9f6c3ceb3699"
   },
   "source": [
    "!pip install torchmetrics -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "tI0KcjC3auG4"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torchvision\n",
    "from torchvision.transforms import Compose, RandomCrop, ToTensor, ToPILImage, CenterCrop, Resize, Grayscale\n",
    "from torchmetrics import StructuralSimilarityIndexMeasure, PeakSignalNoiseRatio\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bgr0F6vldlcC",
    "outputId": "eeae55db-9a26-412d-9127-2dc6a4ce77b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x1d94e096b20>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Y9gCiSoBdnXC"
   },
   "outputs": [],
   "source": [
    "UPSCALE_FACTOR = 4\n",
    "CROP_SIZE = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "N0tpRB2Jdys4"
   },
   "outputs": [],
   "source": [
    "from dataset import TrainDatasetFromFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "re2-OAGQv-aQ",
    "outputId": "4a1985e8-a19d-4547-a56a-9db587e01085"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\transforms.py:287: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_set = TrainDatasetFromFolder(\"chest_xray/train\", crop_size=CROP_SIZE,\n",
    "                                   upscale_factor=UPSCALE_FACTOR)\n",
    "trainloader = DataLoader(train_set, batch_size=2, num_workers=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hL48P4d_BCEM",
    "outputId": "a23da5e5-056f-45dd-a38e-f9ea4e689562"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 128, 128]), torch.Size([1, 512, 512]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.__getitem__(0)[0].shape, train_set.__getitem__(0)[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ZZnfl5c0uzUI"
   },
   "outputs": [],
   "source": [
    "class D_Block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, (3, 3), stride=stride, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        return self.layer(x)\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_size, in_channels=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv_1_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 64, (3, 3), stride=1, padding=1), nn.LeakyReLU()\n",
    "        )\n",
    "\n",
    "        self.block_1_1 = D_Block(64, 64, stride=2)  # stride= 2 if output 4x\n",
    "        self.block_1_2 = D_Block(64, 128, stride=1)\n",
    "        self.block_1_3 = D_Block(128, 128)\n",
    "\n",
    "        self.conv_2_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 64, (3, 3), stride=1, padding=1), nn.LeakyReLU()\n",
    "        )\n",
    "\n",
    "        self.block_2_2 = D_Block(64, 128, stride=1)\n",
    "\n",
    "        self.block3 = D_Block(256, 256, stride=1)\n",
    "        self.block4 = D_Block(256, 256)\n",
    "        self.block5 = D_Block(256, 512, stride=1)\n",
    "        self.block6 = D_Block(512, 512)\n",
    "        self.block7 = D_Block(512, 1024)\n",
    "        self.block8 = D_Block(1024, 1024)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.fc1 = nn.Linear(1024 * img_size[0] * img_size[1] // 256, 100) # Change based on input image size\n",
    "        self.fc2 = nn.Linear(100, 2)\n",
    "\n",
    "        self.relu = nn.LeakyReLU(negative_slope=0.2)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "\n",
    "        x_1 = self.block_1_3(self.block_1_2(self.block_1_1(self.conv_1_1(x1))))\n",
    "        x_2 = self.block_2_2(self.conv_2_1(x2))\n",
    "\n",
    "        x = torch.cat([x_1, x_2], dim=1)\n",
    "        x = self.block8(\n",
    "            self.block7(self.block6(self.block5(self.block4(self.block3(x)))))\n",
    "        )\n",
    "\n",
    "        x = self.flatten(x)\n",
    "\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(self.relu(x))\n",
    "\n",
    "        return self.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "Ue5xbeyUuzWF",
    "outputId": "485e7058-7ff9-435a-c038-8ac159c65dc1"
   },
   "outputs": [],
   "source": [
    "class RWMAB(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels, (3, 3), stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels, in_channels, (3, 3), stride=1, padding=1),\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels, (1, 1), stride=1, padding=0),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x_ = self.layer1(x)\n",
    "        x__ = self.layer2(x_)\n",
    "\n",
    "        x = x__ * x_ + x\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class ShortResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = nn.ModuleList([RWMAB(in_channels) for _ in range(16)])\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x_ = x.clone()\n",
    "\n",
    "        for layer in self.layers:\n",
    "            x_ = layer(x_)\n",
    "\n",
    "        return x_ + x\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, in_channels=1, blocks=8):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels, 64, (3, 3), stride=1, padding=1)\n",
    "\n",
    "        self.short_blocks = nn.ModuleList(\n",
    "            [ShortResidualBlock(64) for _ in range(blocks)]\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Conv2d(64, 64, (1, 1), stride=1, padding=0)\n",
    "\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, (3, 3), stride=1, padding=1),\n",
    "            nn.PixelShuffle(2),\n",
    "            nn.Conv2d(64, 256, (3, 3), stride=1, padding=1),\n",
    "            nn.PixelShuffle(2),  # Remove if output is 2x the input\n",
    "            nn.Conv2d(64, 1, (1, 1), stride=1, padding=0),  # Change 64 -> 256\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv(x)\n",
    "        x_ = x.clone()\n",
    "\n",
    "        for layer in self.short_blocks:\n",
    "            x_ = layer(x_)\n",
    "\n",
    "        x = torch.cat([self.conv2(x_), x], dim=1)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tzzSCJjjy7I9",
    "outputId": "29c3e46f-e1d8-4841-a2c4-7ec9edebd42a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device  = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Standard device selectoin\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "4oGBnX7PLGJ-"
   },
   "outputs": [],
   "source": [
    "netG = Generator(in_channels=1, blocks=2)\n",
    "netD = Discriminator(\n",
    "    [int(CROP_SIZE/UPSCALE_FACTOR), \n",
    "     int(CROP_SIZE/UPSCALE_FACTOR)],\n",
    "     in_channels=1\n",
    ")\n",
    "\n",
    "\n",
    "gen = netG.to(device)\n",
    "disc = netD.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "zrrT9RbYMPNg"
   },
   "outputs": [],
   "source": [
    "feature_extractor = torchvision.models.mobilenetv3.mobilenet_v3_small(in_channels=1)\n",
    "feature_extractor.features[0][0] = nn.Conv2d(1, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = feature_extractor.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "gDlYj1loLiD_"
   },
   "outputs": [],
   "source": [
    "optimizer_G = optim.Adam(gen.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "optimizer_D = optim.Adam(disc.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "loss_function = torch.nn.L1Loss().to(device)\n",
    "gan_loss = torch.nn.BCEWithLogitsLoss().to(device)\n",
    "scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "doBMeLWOLs_0"
   },
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"d_loss\":[],\n",
    "    \"g_loss\":[],\n",
    "    \"d_score\": [],\n",
    "    \"g_score\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "BeTxlp0eML1d"
   },
   "outputs": [],
   "source": [
    "N_EPOCHS = 150 # 150 is good enough for our model. gives decent enough results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "iHadZtxcMO01",
    "outputId": "b66ea0f9-b5a5-4922-9aea-7329145b8476"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[1/150] Loss_D: 1.4120 Loss_G: 0.7498 D(x): 0.4640 D(G(z)): 0.6988 PSNR: 5.405110 SSIM: 0.003313:   9%| | 224/2608 [59:"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, N_EPOCHS + 1):\n",
    "  train_bar = tqdm(trainloader)\n",
    "  running_results = {'batch_sizes':0, 'd_loss':0,\n",
    "                     \"g_loss\":0, \"d_score\":0, \"g_score\":0}\n",
    "\n",
    "  metrics = [PeakSignalNoiseRatio(), StructuralSimilarityIndexMeasure()]\n",
    "\n",
    "  netG.train()\n",
    "  netD.train()\n",
    "  for data in train_bar:\n",
    "    batch_size = data[0].size(0)\n",
    "    running_results['batch_sizes'] += batch_size\n",
    "\n",
    "    lr_img, hr_img = data\n",
    "\n",
    "    lr_img, hr_img = lr_img.to(device), hr_img.to(device)\n",
    "\n",
    "    valid = Variable(torch.Tensor(np.ones((lr_img.shape[0], 2))), requires_grad=False).to(device)\n",
    "    fake = Variable(torch.Tensor(np.zeros((lr_img.shape[0], 2))), requires_grad=False).to(device)\n",
    "\n",
    "    pred_hr = gen(lr_img)\n",
    "\n",
    "    content_loss = loss_function(pred_hr, hr_img)\n",
    "\n",
    "    pred_features = feature_extractor(pred_hr)\n",
    "    hr_features = feature_extractor(hr_img)\n",
    "\n",
    "    feature_loss = 0.0\n",
    "\n",
    "    for pred_feature, hr_feature in zip(pred_features, hr_features):\n",
    "        feature_loss += loss_function(pred_feature, hr_feature)\n",
    "\n",
    "    pred_real = disc(hr_img.detach(), lr_img)\n",
    "    pred_fake = disc(pred_hr, lr_img)\n",
    "\n",
    "    gan_loss_num = gan_loss(\n",
    "        pred_fake - pred_real.mean(0, keepdim=True), valid\n",
    "    )\n",
    "\n",
    "    loss_G = content_loss * 0.1 + feature_loss * 0.1 + gan_loss_num\n",
    "\n",
    "    optimizer_G.zero_grad()\n",
    "    scaler.scale(loss_G).backward()\n",
    "    scaler.step(optimizer_G)\n",
    "    scaler.update()\n",
    "\n",
    "    # Train Discriminator\n",
    "\n",
    "    pred_real = disc(hr_img, lr_img)\n",
    "    pred_fake = disc(pred_hr.detach(), lr_img)\n",
    "\n",
    "    loss_real = gan_loss(pred_real - pred_fake.mean(0, keepdim=True), valid)\n",
    "    loss_fake = gan_loss(pred_fake - pred_real.mean(0, keepdim=True), fake)\n",
    "\n",
    "    loss_real_num = gan_loss(pred_real, valid)\n",
    "    loss_fake_num = gan_loss(pred_fake, fake)\n",
    "\n",
    "    loss_D = ((loss_real + loss_fake) / 2) + (\n",
    "        (loss_real_num + loss_fake_num) / 2\n",
    "    )\n",
    "\n",
    "    optimizer_D.zero_grad()\n",
    "\n",
    "    running_results['g_loss'] += loss_G.item() * batch_size\n",
    "    running_results['d_loss'] += loss_D.item() * batch_size\n",
    "    running_results['d_score'] += loss_real_num.item() * batch_size\n",
    "    running_results['g_score'] += gan_loss_num.item() * batch_size\n",
    "    metrics[0](hr_img.detach().cpu()*255, pred_hr.detach().cpu()*255).item()\n",
    "    metrics[1](hr_img.detach().cpu()*255, pred_hr.detach().cpu()*255).item()\n",
    "\n",
    "    ## Updating the progress bar\n",
    "    train_bar.set_description(desc=\"[%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f PSNR: %2f SSIM: %2f\" % (\n",
    "        epoch, N_EPOCHS, running_results['d_loss'] / running_results['batch_sizes'],\n",
    "        running_results['g_loss'] / running_results['batch_sizes'],\n",
    "        running_results['d_score'] / running_results['batch_sizes'],\n",
    "        running_results['g_score'] / running_results['batch_sizes'],\n",
    "        metrics[0].compute().item(),\n",
    "        metrics[1].compute().item()\n",
    "    ))\n",
    "  netG.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f_tWatOGrfoP"
   },
   "outputs": [],
   "source": [
    "def plot_images(images):\n",
    "  grid_img = torchvision.utils.make_grid(images.detach().cpu()[:16])\n",
    "  grid_img = (grid_img.permute(1, 2, 0).numpy()*255)\n",
    "\n",
    "  plt.figure(figsize=(20, 20))\n",
    "  plt.imshow(grid_img.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VKlN5jD1Pm6k"
   },
   "outputs": [],
   "source": [
    "plot_images(fake_img)\n",
    "plot_images(real_img)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MedSRGAN.ipynb\"",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
