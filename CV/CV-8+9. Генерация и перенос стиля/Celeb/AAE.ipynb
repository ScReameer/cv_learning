{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rX_aM5xf758L"
      },
      "source": [
        "# Загрузка библиотек"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0tFyXK-h7_P4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "import numpy as np\n",
        "import math\n",
        "import itertools\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTLIiavS882M"
      },
      "source": [
        "# Подготовка данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIbixKNOXB4P",
        "outputId": "a7d68550-17e4-4424-ef80-0b4769bc85e2"
      },
      "outputs": [],
      "source": [
        "ngpu = 1\n",
        "device = torch.device('cuda:0' if (\n",
        "    torch.cuda.is_available() and ngpu > 0) else 'cpu')\n",
        "\n",
        "# Путь к папке с данными\n",
        "dataset_folder = f'/home/cv_learning/CV/CV-8+9. Генерация и перенос стиля/Celeb/CelebA/Img/img_align_celeba'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Md5DlqApXDZY"
      },
      "outputs": [],
      "source": [
        "class CelebADataset(Dataset):\n",
        "  def __init__(self, root_dir, transform=None):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      root_dir (string): Directory with all the images\n",
        "      transform (callable, optional): transform to be applied to each image sample\n",
        "    \"\"\"\n",
        "    # Считываем название файлов\n",
        "\n",
        "    self.root_dir = root_dir\n",
        "    self.transform = transform \n",
        "    self.image_names = os.listdir(root_dir)\n",
        "\n",
        "  def __len__(self): \n",
        "    return len(self.image_names)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    # Получаем путь к файлу\n",
        "    img_path = os.path.join(self.root_dir, self.image_names[idx])\n",
        "    # Загружаем изображение\n",
        "    img = Image.open(img_path).convert('RGB')\n",
        "    # Применяем преобразования\n",
        "    if self.transform:\n",
        "      img = self.transform(img)\n",
        "\n",
        "    return img\n",
        "\n",
        "## Загружаем датасет \n",
        "# Путь к директории со всеми изображениями\n",
        "# Фиксипуем размер изображения\n",
        "image_size = 64\n",
        "# Преоьразования\n",
        "transform=transforms.Compose([\n",
        "    transforms.Resize(image_size),\n",
        "    transforms.CenterCrop(image_size),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "      mean=[0.5, 0.5, 0.5],\n",
        "      std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "celeba_dataset = CelebADataset(dataset_folder, transform)\n",
        "\n",
        "batch_size = 128\n",
        "num_workers = 0 if device.type == 'cuda' else 2\n",
        "pin_memory = True if device.type == 'cuda' else False\n",
        "\n",
        "celeba_dataloader = DataLoader(\n",
        "  celeba_dataset,\n",
        "  batch_size=batch_size,\n",
        "  num_workers=num_workers,\n",
        "  pin_memory=pin_memory,\n",
        "  shuffle=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLOrTixC_hJY"
      },
      "source": [
        "# Модель"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "z7Q5fsT4WTGk"
      },
      "outputs": [],
      "source": [
        "n_epochs = 2\n",
        "lr = 0.0002\n",
        "b1, b2 = 0.5, 0.999\n",
        "channels = 3\n",
        "latent_dim = 10\n",
        "sample_interval = 400\n",
        "\n",
        "img_shape = (channels, image_size, image_size)\n",
        "\n",
        "cuda = True if torch.cuda.is_available() else False\n",
        "\n",
        "\n",
        "def reparameterization(mu, logvar):\n",
        "    std = torch.exp(logvar / 2)\n",
        "    sampled_z = Variable(Tensor(np.random.normal(0, 1, (mu.size(0), latent_dim))))\n",
        "    z = sampled_z * std + mu\n",
        "    return z\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(int(np.prod(img_shape)), 512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "        )\n",
        "\n",
        "        self.mu = nn.Linear(512, latent_dim)\n",
        "        self.logvar = nn.Linear(512, latent_dim)\n",
        "\n",
        "    def forward(self, img):\n",
        "        img_flat = img.view(img.shape[0], -1)\n",
        "        x = self.model(img_flat)\n",
        "        mu = self.mu(x)\n",
        "        logvar = self.logvar(x)\n",
        "        z = reparameterization(mu, logvar)\n",
        "        return z\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(512, int(np.prod(img_shape))),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        img_flat = self.model(z)\n",
        "        img = img_flat.view(img_flat.shape[0], *img_shape)\n",
        "        return img\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        validity = self.model(z)\n",
        "        return validity\n",
        "\n",
        "\n",
        "# Функция потерь\n",
        "adversarial_loss = torch.nn.BCELoss()\n",
        "pixelwise_loss = torch.nn.L1Loss()\n",
        "\n",
        "# Инициализируем генератор и дискриминатор\n",
        "encoder = Encoder()\n",
        "decoder = Decoder()\n",
        "discriminator = Discriminator()\n",
        "\n",
        "if cuda:\n",
        "    encoder.cuda()\n",
        "    decoder.cuda()\n",
        "    discriminator.cuda()\n",
        "    adversarial_loss.cuda()\n",
        "    pixelwise_loss.cuda()\n",
        "\n",
        "\n",
        "# Оптимизаторы\n",
        "optimizer_G = torch.optim.Adam(\n",
        "    itertools.chain(encoder.parameters(), decoder.parameters()), lr=lr, betas=(b1, b2)\n",
        ")\n",
        "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(b1, b2))\n",
        "\n",
        "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
        "\n",
        "\n",
        "def sample_image(n_row, batches_done):\n",
        "    \"\"\"Saves a grid of generated digits\"\"\"\n",
        "    z = Variable(Tensor(np.random.normal(0, 1, (n_row ** 2, latent_dim))))\n",
        "    gen_imgs = decoder(z)\n",
        "    save_image(gen_imgs.data, \"data/%d.png\" % batches_done, nrow=n_row, normalize=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09evxI71-R4s"
      },
      "source": [
        "# Обучение модели "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjBFzAQy-UN5",
        "outputId": "6c7e86f3-66c9-4c37-a8f5-114b299c4028"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 0/2] [Batch 0/1583] [D loss: 0.690496] [G loss: 0.555650]\n",
            "[Epoch 0/2] [Batch 1/1583] [D loss: 0.682476] [G loss: 0.551544]\n",
            "[Epoch 0/2] [Batch 2/1583] [D loss: 0.675199] [G loss: 0.511538]\n",
            "[Epoch 0/2] [Batch 3/1583] [D loss: 0.654594] [G loss: 0.511390]\n",
            "[Epoch 0/2] [Batch 4/1583] [D loss: 0.639780] [G loss: 0.502827]\n",
            "[Epoch 0/2] [Batch 5/1583] [D loss: 0.634238] [G loss: 0.476861]\n",
            "[Epoch 0/2] [Batch 6/1583] [D loss: 0.632450] [G loss: 0.482778]\n",
            "[Epoch 0/2] [Batch 7/1583] [D loss: 0.623898] [G loss: 0.462934]\n",
            "[Epoch 0/2] [Batch 8/1583] [D loss: 0.599057] [G loss: 0.463240]\n",
            "[Epoch 0/2] [Batch 9/1583] [D loss: 0.589076] [G loss: 0.431849]\n",
            "[Epoch 0/2] [Batch 10/1583] [D loss: 0.578618] [G loss: 0.427873]\n",
            "[Epoch 0/2] [Batch 11/1583] [D loss: 0.565402] [G loss: 0.403671]\n",
            "[Epoch 0/2] [Batch 12/1583] [D loss: 0.541434] [G loss: 0.407199]\n",
            "[Epoch 0/2] [Batch 13/1583] [D loss: 0.525832] [G loss: 0.383847]\n",
            "[Epoch 0/2] [Batch 14/1583] [D loss: 0.518316] [G loss: 0.370833]\n",
            "[Epoch 0/2] [Batch 15/1583] [D loss: 0.500662] [G loss: 0.375141]\n",
            "[Epoch 0/2] [Batch 16/1583] [D loss: 0.480652] [G loss: 0.361335]\n",
            "[Epoch 0/2] [Batch 17/1583] [D loss: 0.477794] [G loss: 0.370359]\n",
            "[Epoch 0/2] [Batch 18/1583] [D loss: 0.459292] [G loss: 0.355125]\n",
            "[Epoch 0/2] [Batch 19/1583] [D loss: 0.461649] [G loss: 0.361840]\n",
            "[Epoch 0/2] [Batch 20/1583] [D loss: 0.443847] [G loss: 0.336187]\n",
            "[Epoch 0/2] [Batch 21/1583] [D loss: 0.434261] [G loss: 0.340349]\n",
            "[Epoch 0/2] [Batch 22/1583] [D loss: 0.417788] [G loss: 0.344951]\n",
            "[Epoch 0/2] [Batch 23/1583] [D loss: 0.418934] [G loss: 0.338358]\n",
            "[Epoch 0/2] [Batch 24/1583] [D loss: 0.411266] [G loss: 0.340435]\n",
            "[Epoch 0/2] [Batch 25/1583] [D loss: 0.423923] [G loss: 0.351052]\n",
            "[Epoch 0/2] [Batch 26/1583] [D loss: 0.420215] [G loss: 0.348398]\n",
            "[Epoch 0/2] [Batch 27/1583] [D loss: 0.393018] [G loss: 0.344483]\n",
            "[Epoch 0/2] [Batch 28/1583] [D loss: 0.406587] [G loss: 0.339482]\n",
            "[Epoch 0/2] [Batch 29/1583] [D loss: 0.401054] [G loss: 0.332746]\n",
            "[Epoch 0/2] [Batch 30/1583] [D loss: 0.382322] [G loss: 0.336917]\n",
            "[Epoch 0/2] [Batch 31/1583] [D loss: 0.373333] [G loss: 0.321372]\n",
            "[Epoch 0/2] [Batch 32/1583] [D loss: 0.380859] [G loss: 0.337607]\n",
            "[Epoch 0/2] [Batch 33/1583] [D loss: 0.364789] [G loss: 0.326877]\n",
            "[Epoch 0/2] [Batch 34/1583] [D loss: 0.358179] [G loss: 0.322615]\n",
            "[Epoch 0/2] [Batch 35/1583] [D loss: 0.356514] [G loss: 0.331327]\n",
            "[Epoch 0/2] [Batch 36/1583] [D loss: 0.350314] [G loss: 0.324965]\n",
            "[Epoch 0/2] [Batch 37/1583] [D loss: 0.311695] [G loss: 0.331237]\n",
            "[Epoch 0/2] [Batch 38/1583] [D loss: 0.340475] [G loss: 0.318511]\n",
            "[Epoch 0/2] [Batch 39/1583] [D loss: 0.354670] [G loss: 0.329665]\n",
            "[Epoch 0/2] [Batch 40/1583] [D loss: 0.309716] [G loss: 0.323585]\n",
            "[Epoch 0/2] [Batch 41/1583] [D loss: 0.329644] [G loss: 0.311318]\n",
            "[Epoch 0/2] [Batch 42/1583] [D loss: 0.302142] [G loss: 0.313707]\n",
            "[Epoch 0/2] [Batch 43/1583] [D loss: 0.330600] [G loss: 0.320815]\n",
            "[Epoch 0/2] [Batch 44/1583] [D loss: 0.301968] [G loss: 0.320523]\n",
            "[Epoch 0/2] [Batch 45/1583] [D loss: 0.300419] [G loss: 0.306094]\n",
            "[Epoch 0/2] [Batch 46/1583] [D loss: 0.287988] [G loss: 0.314224]\n",
            "[Epoch 0/2] [Batch 47/1583] [D loss: 0.266521] [G loss: 0.312716]\n",
            "[Epoch 0/2] [Batch 48/1583] [D loss: 0.292172] [G loss: 0.318539]\n",
            "[Epoch 0/2] [Batch 49/1583] [D loss: 0.280791] [G loss: 0.299673]\n",
            "[Epoch 0/2] [Batch 50/1583] [D loss: 0.256513] [G loss: 0.295008]\n",
            "[Epoch 0/2] [Batch 51/1583] [D loss: 0.260385] [G loss: 0.291618]\n",
            "[Epoch 0/2] [Batch 52/1583] [D loss: 0.240565] [G loss: 0.300640]\n",
            "[Epoch 0/2] [Batch 53/1583] [D loss: 0.286349] [G loss: 0.304727]\n",
            "[Epoch 0/2] [Batch 54/1583] [D loss: 0.263040] [G loss: 0.296988]\n",
            "[Epoch 0/2] [Batch 55/1583] [D loss: 0.257922] [G loss: 0.300773]\n",
            "[Epoch 0/2] [Batch 56/1583] [D loss: 0.231636] [G loss: 0.295121]\n",
            "[Epoch 0/2] [Batch 57/1583] [D loss: 0.245814] [G loss: 0.294804]\n",
            "[Epoch 0/2] [Batch 58/1583] [D loss: 0.239506] [G loss: 0.289743]\n",
            "[Epoch 0/2] [Batch 59/1583] [D loss: 0.228827] [G loss: 0.280947]\n",
            "[Epoch 0/2] [Batch 60/1583] [D loss: 0.232857] [G loss: 0.288192]\n",
            "[Epoch 0/2] [Batch 61/1583] [D loss: 0.235048] [G loss: 0.293123]\n",
            "[Epoch 0/2] [Batch 62/1583] [D loss: 0.231492] [G loss: 0.289168]\n",
            "[Epoch 0/2] [Batch 63/1583] [D loss: 0.225168] [G loss: 0.298983]\n",
            "[Epoch 0/2] [Batch 64/1583] [D loss: 0.195955] [G loss: 0.306556]\n",
            "[Epoch 0/2] [Batch 65/1583] [D loss: 0.226825] [G loss: 0.287621]\n",
            "[Epoch 0/2] [Batch 66/1583] [D loss: 0.226169] [G loss: 0.283168]\n",
            "[Epoch 0/2] [Batch 67/1583] [D loss: 0.227619] [G loss: 0.284881]\n",
            "[Epoch 0/2] [Batch 68/1583] [D loss: 0.209366] [G loss: 0.289526]\n",
            "[Epoch 0/2] [Batch 69/1583] [D loss: 0.221489] [G loss: 0.290120]\n",
            "[Epoch 0/2] [Batch 70/1583] [D loss: 0.206922] [G loss: 0.290583]\n",
            "[Epoch 0/2] [Batch 71/1583] [D loss: 0.233135] [G loss: 0.294629]\n",
            "[Epoch 0/2] [Batch 72/1583] [D loss: 0.203617] [G loss: 0.290464]\n",
            "[Epoch 0/2] [Batch 73/1583] [D loss: 0.225741] [G loss: 0.290854]\n",
            "[Epoch 0/2] [Batch 74/1583] [D loss: 0.200953] [G loss: 0.277952]\n",
            "[Epoch 0/2] [Batch 75/1583] [D loss: 0.228270] [G loss: 0.291054]\n",
            "[Epoch 0/2] [Batch 76/1583] [D loss: 0.243634] [G loss: 0.275526]\n",
            "[Epoch 0/2] [Batch 77/1583] [D loss: 0.202339] [G loss: 0.272228]\n",
            "[Epoch 0/2] [Batch 78/1583] [D loss: 0.239967] [G loss: 0.282647]\n",
            "[Epoch 0/2] [Batch 79/1583] [D loss: 0.220547] [G loss: 0.281464]\n",
            "[Epoch 0/2] [Batch 80/1583] [D loss: 0.223488] [G loss: 0.274046]\n",
            "[Epoch 0/2] [Batch 81/1583] [D loss: 0.204727] [G loss: 0.286140]\n",
            "[Epoch 0/2] [Batch 82/1583] [D loss: 0.218118] [G loss: 0.280142]\n",
            "[Epoch 0/2] [Batch 83/1583] [D loss: 0.217064] [G loss: 0.271298]\n",
            "[Epoch 0/2] [Batch 84/1583] [D loss: 0.199389] [G loss: 0.282892]\n",
            "[Epoch 0/2] [Batch 85/1583] [D loss: 0.206793] [G loss: 0.282804]\n",
            "[Epoch 0/2] [Batch 86/1583] [D loss: 0.180115] [G loss: 0.280257]\n",
            "[Epoch 0/2] [Batch 87/1583] [D loss: 0.183131] [G loss: 0.273000]\n",
            "[Epoch 0/2] [Batch 88/1583] [D loss: 0.270171] [G loss: 0.280720]\n",
            "[Epoch 0/2] [Batch 89/1583] [D loss: 0.206160] [G loss: 0.277445]\n",
            "[Epoch 0/2] [Batch 90/1583] [D loss: 0.247657] [G loss: 0.267375]\n",
            "[Epoch 0/2] [Batch 91/1583] [D loss: 0.208978] [G loss: 0.273758]\n",
            "[Epoch 0/2] [Batch 92/1583] [D loss: 0.210922] [G loss: 0.283917]\n",
            "[Epoch 0/2] [Batch 93/1583] [D loss: 0.220822] [G loss: 0.271220]\n",
            "[Epoch 0/2] [Batch 94/1583] [D loss: 0.223118] [G loss: 0.267810]\n",
            "[Epoch 0/2] [Batch 95/1583] [D loss: 0.195214] [G loss: 0.284718]\n",
            "[Epoch 0/2] [Batch 96/1583] [D loss: 0.239713] [G loss: 0.285548]\n",
            "[Epoch 0/2] [Batch 97/1583] [D loss: 0.268665] [G loss: 0.270770]\n",
            "[Epoch 0/2] [Batch 98/1583] [D loss: 0.210504] [G loss: 0.270237]\n",
            "[Epoch 0/2] [Batch 99/1583] [D loss: 0.198382] [G loss: 0.274233]\n",
            "[Epoch 0/2] [Batch 100/1583] [D loss: 0.216639] [G loss: 0.270467]\n",
            "[Epoch 0/2] [Batch 101/1583] [D loss: 0.199119] [G loss: 0.272738]\n",
            "[Epoch 0/2] [Batch 102/1583] [D loss: 0.219315] [G loss: 0.272987]\n",
            "[Epoch 0/2] [Batch 103/1583] [D loss: 0.225764] [G loss: 0.273752]\n",
            "[Epoch 0/2] [Batch 104/1583] [D loss: 0.231600] [G loss: 0.271872]\n",
            "[Epoch 0/2] [Batch 105/1583] [D loss: 0.241190] [G loss: 0.279539]\n",
            "[Epoch 0/2] [Batch 106/1583] [D loss: 0.214651] [G loss: 0.269671]\n",
            "[Epoch 0/2] [Batch 107/1583] [D loss: 0.203581] [G loss: 0.273851]\n",
            "[Epoch 0/2] [Batch 108/1583] [D loss: 0.258905] [G loss: 0.279149]\n",
            "[Epoch 0/2] [Batch 109/1583] [D loss: 0.234397] [G loss: 0.278224]\n",
            "[Epoch 0/2] [Batch 110/1583] [D loss: 0.226670] [G loss: 0.269932]\n",
            "[Epoch 0/2] [Batch 111/1583] [D loss: 0.234394] [G loss: 0.263706]\n",
            "[Epoch 0/2] [Batch 112/1583] [D loss: 0.255961] [G loss: 0.278320]\n",
            "[Epoch 0/2] [Batch 113/1583] [D loss: 0.309813] [G loss: 0.277178]\n",
            "[Epoch 0/2] [Batch 114/1583] [D loss: 0.244271] [G loss: 0.274879]\n",
            "[Epoch 0/2] [Batch 115/1583] [D loss: 0.269166] [G loss: 0.276356]\n",
            "[Epoch 0/2] [Batch 116/1583] [D loss: 0.242564] [G loss: 0.280501]\n",
            "[Epoch 0/2] [Batch 117/1583] [D loss: 0.228926] [G loss: 0.268870]\n",
            "[Epoch 0/2] [Batch 118/1583] [D loss: 0.221634] [G loss: 0.258903]\n",
            "[Epoch 0/2] [Batch 119/1583] [D loss: 0.228861] [G loss: 0.277337]\n",
            "[Epoch 0/2] [Batch 120/1583] [D loss: 0.241728] [G loss: 0.256305]\n",
            "[Epoch 0/2] [Batch 121/1583] [D loss: 0.230983] [G loss: 0.267394]\n",
            "[Epoch 0/2] [Batch 122/1583] [D loss: 0.244086] [G loss: 0.266061]\n",
            "[Epoch 0/2] [Batch 123/1583] [D loss: 0.232086] [G loss: 0.256957]\n",
            "[Epoch 0/2] [Batch 124/1583] [D loss: 0.224501] [G loss: 0.259939]\n",
            "[Epoch 0/2] [Batch 125/1583] [D loss: 0.269866] [G loss: 0.266381]\n",
            "[Epoch 0/2] [Batch 126/1583] [D loss: 0.323668] [G loss: 0.263604]\n",
            "[Epoch 0/2] [Batch 127/1583] [D loss: 0.276251] [G loss: 0.261897]\n",
            "[Epoch 0/2] [Batch 128/1583] [D loss: 0.235515] [G loss: 0.272645]\n",
            "[Epoch 0/2] [Batch 129/1583] [D loss: 0.320275] [G loss: 0.265677]\n",
            "[Epoch 0/2] [Batch 130/1583] [D loss: 0.252520] [G loss: 0.265698]\n",
            "[Epoch 0/2] [Batch 131/1583] [D loss: 0.280756] [G loss: 0.256130]\n",
            "[Epoch 0/2] [Batch 132/1583] [D loss: 0.327105] [G loss: 0.255785]\n",
            "[Epoch 0/2] [Batch 133/1583] [D loss: 0.331822] [G loss: 0.255877]\n",
            "[Epoch 0/2] [Batch 134/1583] [D loss: 0.321618] [G loss: 0.276828]\n",
            "[Epoch 0/2] [Batch 135/1583] [D loss: 0.292536] [G loss: 0.248298]\n",
            "[Epoch 0/2] [Batch 136/1583] [D loss: 0.302940] [G loss: 0.261532]\n",
            "[Epoch 0/2] [Batch 137/1583] [D loss: 0.307513] [G loss: 0.266076]\n",
            "[Epoch 0/2] [Batch 138/1583] [D loss: 0.287712] [G loss: 0.258203]\n",
            "[Epoch 0/2] [Batch 139/1583] [D loss: 0.306659] [G loss: 0.260210]\n",
            "[Epoch 0/2] [Batch 140/1583] [D loss: 0.271107] [G loss: 0.262574]\n",
            "[Epoch 0/2] [Batch 141/1583] [D loss: 0.272467] [G loss: 0.265757]\n",
            "[Epoch 0/2] [Batch 142/1583] [D loss: 0.280828] [G loss: 0.252083]\n",
            "[Epoch 0/2] [Batch 143/1583] [D loss: 0.302009] [G loss: 0.251456]\n",
            "[Epoch 0/2] [Batch 144/1583] [D loss: 0.242300] [G loss: 0.260353]\n",
            "[Epoch 0/2] [Batch 145/1583] [D loss: 0.326930] [G loss: 0.251908]\n",
            "[Epoch 0/2] [Batch 146/1583] [D loss: 0.297198] [G loss: 0.268358]\n",
            "[Epoch 0/2] [Batch 147/1583] [D loss: 0.271026] [G loss: 0.254702]\n",
            "[Epoch 0/2] [Batch 148/1583] [D loss: 0.300519] [G loss: 0.260832]\n",
            "[Epoch 0/2] [Batch 149/1583] [D loss: 0.310880] [G loss: 0.247865]\n",
            "[Epoch 0/2] [Batch 150/1583] [D loss: 0.274145] [G loss: 0.245644]\n",
            "[Epoch 0/2] [Batch 151/1583] [D loss: 0.299208] [G loss: 0.256970]\n",
            "[Epoch 0/2] [Batch 152/1583] [D loss: 0.315654] [G loss: 0.253208]\n",
            "[Epoch 0/2] [Batch 153/1583] [D loss: 0.335748] [G loss: 0.251319]\n",
            "[Epoch 0/2] [Batch 154/1583] [D loss: 0.330463] [G loss: 0.254711]\n",
            "[Epoch 0/2] [Batch 155/1583] [D loss: 0.326695] [G loss: 0.256624]\n",
            "[Epoch 0/2] [Batch 156/1583] [D loss: 0.343937] [G loss: 0.248334]\n",
            "[Epoch 0/2] [Batch 157/1583] [D loss: 0.298685] [G loss: 0.246187]\n",
            "[Epoch 0/2] [Batch 158/1583] [D loss: 0.334211] [G loss: 0.244940]\n",
            "[Epoch 0/2] [Batch 159/1583] [D loss: 0.288132] [G loss: 0.255780]\n",
            "[Epoch 0/2] [Batch 160/1583] [D loss: 0.307631] [G loss: 0.251529]\n",
            "[Epoch 0/2] [Batch 161/1583] [D loss: 0.320371] [G loss: 0.242902]\n",
            "[Epoch 0/2] [Batch 162/1583] [D loss: 0.327244] [G loss: 0.259053]\n",
            "[Epoch 0/2] [Batch 163/1583] [D loss: 0.317995] [G loss: 0.258389]\n",
            "[Epoch 0/2] [Batch 164/1583] [D loss: 0.304144] [G loss: 0.249097]\n",
            "[Epoch 0/2] [Batch 165/1583] [D loss: 0.332849] [G loss: 0.258811]\n",
            "[Epoch 0/2] [Batch 166/1583] [D loss: 0.331865] [G loss: 0.260264]\n",
            "[Epoch 0/2] [Batch 167/1583] [D loss: 0.306986] [G loss: 0.242101]\n",
            "[Epoch 0/2] [Batch 168/1583] [D loss: 0.325353] [G loss: 0.251251]\n",
            "[Epoch 0/2] [Batch 169/1583] [D loss: 0.327313] [G loss: 0.252690]\n",
            "[Epoch 0/2] [Batch 170/1583] [D loss: 0.329764] [G loss: 0.253417]\n",
            "[Epoch 0/2] [Batch 171/1583] [D loss: 0.304311] [G loss: 0.260561]\n",
            "[Epoch 0/2] [Batch 172/1583] [D loss: 0.333023] [G loss: 0.238860]\n",
            "[Epoch 0/2] [Batch 173/1583] [D loss: 0.307462] [G loss: 0.246304]\n",
            "[Epoch 0/2] [Batch 174/1583] [D loss: 0.302974] [G loss: 0.265547]\n",
            "[Epoch 0/2] [Batch 175/1583] [D loss: 0.348552] [G loss: 0.244144]\n",
            "[Epoch 0/2] [Batch 176/1583] [D loss: 0.337507] [G loss: 0.249008]\n",
            "[Epoch 0/2] [Batch 177/1583] [D loss: 0.377273] [G loss: 0.247783]\n",
            "[Epoch 0/2] [Batch 178/1583] [D loss: 0.291754] [G loss: 0.258695]\n",
            "[Epoch 0/2] [Batch 179/1583] [D loss: 0.331735] [G loss: 0.250018]\n",
            "[Epoch 0/2] [Batch 180/1583] [D loss: 0.337092] [G loss: 0.255966]\n",
            "[Epoch 0/2] [Batch 181/1583] [D loss: 0.301975] [G loss: 0.250856]\n",
            "[Epoch 0/2] [Batch 182/1583] [D loss: 0.386806] [G loss: 0.243488]\n",
            "[Epoch 0/2] [Batch 183/1583] [D loss: 0.376139] [G loss: 0.250149]\n",
            "[Epoch 0/2] [Batch 184/1583] [D loss: 0.343318] [G loss: 0.247946]\n",
            "[Epoch 0/2] [Batch 185/1583] [D loss: 0.396889] [G loss: 0.244233]\n",
            "[Epoch 0/2] [Batch 186/1583] [D loss: 0.342899] [G loss: 0.257293]\n",
            "[Epoch 0/2] [Batch 187/1583] [D loss: 0.324629] [G loss: 0.247841]\n",
            "[Epoch 0/2] [Batch 188/1583] [D loss: 0.356858] [G loss: 0.247001]\n",
            "[Epoch 0/2] [Batch 189/1583] [D loss: 0.335701] [G loss: 0.249082]\n",
            "[Epoch 0/2] [Batch 190/1583] [D loss: 0.331768] [G loss: 0.248564]\n",
            "[Epoch 0/2] [Batch 191/1583] [D loss: 0.328858] [G loss: 0.250160]\n",
            "[Epoch 0/2] [Batch 192/1583] [D loss: 0.352454] [G loss: 0.252088]\n",
            "[Epoch 0/2] [Batch 193/1583] [D loss: 0.353609] [G loss: 0.243300]\n",
            "[Epoch 0/2] [Batch 194/1583] [D loss: 0.340520] [G loss: 0.251968]\n",
            "[Epoch 0/2] [Batch 195/1583] [D loss: 0.315624] [G loss: 0.245764]\n",
            "[Epoch 0/2] [Batch 196/1583] [D loss: 0.317201] [G loss: 0.246970]\n",
            "[Epoch 0/2] [Batch 197/1583] [D loss: 0.341689] [G loss: 0.252967]\n",
            "[Epoch 0/2] [Batch 198/1583] [D loss: 0.371881] [G loss: 0.238304]\n",
            "[Epoch 0/2] [Batch 199/1583] [D loss: 0.369973] [G loss: 0.247541]\n",
            "[Epoch 0/2] [Batch 200/1583] [D loss: 0.378335] [G loss: 0.246536]\n",
            "[Epoch 0/2] [Batch 201/1583] [D loss: 0.386051] [G loss: 0.242298]\n",
            "[Epoch 0/2] [Batch 202/1583] [D loss: 0.342308] [G loss: 0.242115]\n",
            "[Epoch 0/2] [Batch 203/1583] [D loss: 0.350499] [G loss: 0.252595]\n",
            "[Epoch 0/2] [Batch 204/1583] [D loss: 0.382074] [G loss: 0.253036]\n",
            "[Epoch 0/2] [Batch 205/1583] [D loss: 0.356700] [G loss: 0.244489]\n",
            "[Epoch 0/2] [Batch 206/1583] [D loss: 0.335342] [G loss: 0.249518]\n",
            "[Epoch 0/2] [Batch 207/1583] [D loss: 0.377250] [G loss: 0.246056]\n",
            "[Epoch 0/2] [Batch 208/1583] [D loss: 0.307096] [G loss: 0.251441]\n",
            "[Epoch 0/2] [Batch 209/1583] [D loss: 0.395675] [G loss: 0.241599]\n",
            "[Epoch 0/2] [Batch 210/1583] [D loss: 0.379362] [G loss: 0.237515]\n",
            "[Epoch 0/2] [Batch 211/1583] [D loss: 0.373463] [G loss: 0.247119]\n",
            "[Epoch 0/2] [Batch 212/1583] [D loss: 0.379877] [G loss: 0.257382]\n",
            "[Epoch 0/2] [Batch 213/1583] [D loss: 0.373523] [G loss: 0.238159]\n",
            "[Epoch 0/2] [Batch 214/1583] [D loss: 0.343562] [G loss: 0.247823]\n",
            "[Epoch 0/2] [Batch 215/1583] [D loss: 0.382489] [G loss: 0.235077]\n",
            "[Epoch 0/2] [Batch 216/1583] [D loss: 0.316805] [G loss: 0.234443]\n",
            "[Epoch 0/2] [Batch 217/1583] [D loss: 0.342387] [G loss: 0.257813]\n",
            "[Epoch 0/2] [Batch 218/1583] [D loss: 0.347413] [G loss: 0.249376]\n",
            "[Epoch 0/2] [Batch 219/1583] [D loss: 0.425317] [G loss: 0.242547]\n",
            "[Epoch 0/2] [Batch 220/1583] [D loss: 0.378884] [G loss: 0.246123]\n",
            "[Epoch 0/2] [Batch 221/1583] [D loss: 0.412872] [G loss: 0.244194]\n",
            "[Epoch 0/2] [Batch 222/1583] [D loss: 0.432242] [G loss: 0.237642]\n",
            "[Epoch 0/2] [Batch 223/1583] [D loss: 0.437169] [G loss: 0.247052]\n",
            "[Epoch 0/2] [Batch 224/1583] [D loss: 0.428901] [G loss: 0.242464]\n",
            "[Epoch 0/2] [Batch 225/1583] [D loss: 0.365387] [G loss: 0.255653]\n",
            "[Epoch 0/2] [Batch 226/1583] [D loss: 0.370071] [G loss: 0.250481]\n",
            "[Epoch 0/2] [Batch 227/1583] [D loss: 0.411245] [G loss: 0.254958]\n",
            "[Epoch 0/2] [Batch 228/1583] [D loss: 0.429201] [G loss: 0.242498]\n",
            "[Epoch 0/2] [Batch 229/1583] [D loss: 0.420095] [G loss: 0.246274]\n",
            "[Epoch 0/2] [Batch 230/1583] [D loss: 0.434499] [G loss: 0.255828]\n",
            "[Epoch 0/2] [Batch 231/1583] [D loss: 0.400872] [G loss: 0.243862]\n",
            "[Epoch 0/2] [Batch 232/1583] [D loss: 0.400066] [G loss: 0.234610]\n",
            "[Epoch 0/2] [Batch 233/1583] [D loss: 0.369355] [G loss: 0.237508]\n",
            "[Epoch 0/2] [Batch 234/1583] [D loss: 0.425335] [G loss: 0.255822]\n",
            "[Epoch 0/2] [Batch 235/1583] [D loss: 0.448636] [G loss: 0.231736]\n",
            "[Epoch 0/2] [Batch 236/1583] [D loss: 0.386476] [G loss: 0.263775]\n",
            "[Epoch 0/2] [Batch 237/1583] [D loss: 0.403914] [G loss: 0.244105]\n",
            "[Epoch 0/2] [Batch 238/1583] [D loss: 0.417631] [G loss: 0.237598]\n",
            "[Epoch 0/2] [Batch 239/1583] [D loss: 0.447437] [G loss: 0.245008]\n",
            "[Epoch 0/2] [Batch 240/1583] [D loss: 0.473110] [G loss: 0.241378]\n",
            "[Epoch 0/2] [Batch 241/1583] [D loss: 0.420267] [G loss: 0.240363]\n",
            "[Epoch 0/2] [Batch 242/1583] [D loss: 0.415272] [G loss: 0.246009]\n",
            "[Epoch 0/2] [Batch 243/1583] [D loss: 0.436189] [G loss: 0.235195]\n",
            "[Epoch 0/2] [Batch 244/1583] [D loss: 0.435299] [G loss: 0.243383]\n",
            "[Epoch 0/2] [Batch 245/1583] [D loss: 0.470259] [G loss: 0.240672]\n",
            "[Epoch 0/2] [Batch 246/1583] [D loss: 0.505445] [G loss: 0.239985]\n",
            "[Epoch 0/2] [Batch 247/1583] [D loss: 0.425646] [G loss: 0.251300]\n",
            "[Epoch 0/2] [Batch 248/1583] [D loss: 0.467227] [G loss: 0.233649]\n",
            "[Epoch 0/2] [Batch 249/1583] [D loss: 0.430162] [G loss: 0.233424]\n",
            "[Epoch 0/2] [Batch 250/1583] [D loss: 0.469539] [G loss: 0.245256]\n",
            "[Epoch 0/2] [Batch 251/1583] [D loss: 0.531341] [G loss: 0.242183]\n",
            "[Epoch 0/2] [Batch 252/1583] [D loss: 0.450812] [G loss: 0.237432]\n",
            "[Epoch 0/2] [Batch 253/1583] [D loss: 0.475772] [G loss: 0.247416]\n",
            "[Epoch 0/2] [Batch 254/1583] [D loss: 0.473704] [G loss: 0.236925]\n",
            "[Epoch 0/2] [Batch 255/1583] [D loss: 0.509909] [G loss: 0.242541]\n",
            "[Epoch 0/2] [Batch 256/1583] [D loss: 0.454571] [G loss: 0.239447]\n",
            "[Epoch 0/2] [Batch 257/1583] [D loss: 0.563062] [G loss: 0.236616]\n",
            "[Epoch 0/2] [Batch 258/1583] [D loss: 0.447884] [G loss: 0.240148]\n",
            "[Epoch 0/2] [Batch 259/1583] [D loss: 0.563374] [G loss: 0.240933]\n",
            "[Epoch 0/2] [Batch 260/1583] [D loss: 0.545150] [G loss: 0.234002]\n",
            "[Epoch 0/2] [Batch 261/1583] [D loss: 0.513840] [G loss: 0.241554]\n",
            "[Epoch 0/2] [Batch 262/1583] [D loss: 0.492322] [G loss: 0.239228]\n",
            "[Epoch 0/2] [Batch 263/1583] [D loss: 0.498314] [G loss: 0.239853]\n",
            "[Epoch 0/2] [Batch 264/1583] [D loss: 0.471670] [G loss: 0.231599]\n",
            "[Epoch 0/2] [Batch 265/1583] [D loss: 0.516984] [G loss: 0.229530]\n",
            "[Epoch 0/2] [Batch 266/1583] [D loss: 0.515500] [G loss: 0.235468]\n",
            "[Epoch 0/2] [Batch 267/1583] [D loss: 0.581162] [G loss: 0.240642]\n",
            "[Epoch 0/2] [Batch 268/1583] [D loss: 0.517545] [G loss: 0.243874]\n",
            "[Epoch 0/2] [Batch 269/1583] [D loss: 0.477861] [G loss: 0.244841]\n",
            "[Epoch 0/2] [Batch 270/1583] [D loss: 0.546250] [G loss: 0.243512]\n",
            "[Epoch 0/2] [Batch 271/1583] [D loss: 0.505288] [G loss: 0.231793]\n",
            "[Epoch 0/2] [Batch 272/1583] [D loss: 0.549301] [G loss: 0.245084]\n",
            "[Epoch 0/2] [Batch 273/1583] [D loss: 0.487576] [G loss: 0.244252]\n",
            "[Epoch 0/2] [Batch 274/1583] [D loss: 0.522517] [G loss: 0.248251]\n",
            "[Epoch 0/2] [Batch 275/1583] [D loss: 0.563818] [G loss: 0.232707]\n",
            "[Epoch 0/2] [Batch 276/1583] [D loss: 0.499301] [G loss: 0.240918]\n",
            "[Epoch 0/2] [Batch 277/1583] [D loss: 0.517613] [G loss: 0.248009]\n",
            "[Epoch 0/2] [Batch 278/1583] [D loss: 0.527482] [G loss: 0.231533]\n",
            "[Epoch 0/2] [Batch 279/1583] [D loss: 0.536693] [G loss: 0.230144]\n",
            "[Epoch 0/2] [Batch 280/1583] [D loss: 0.538819] [G loss: 0.235927]\n",
            "[Epoch 0/2] [Batch 281/1583] [D loss: 0.551534] [G loss: 0.240436]\n",
            "[Epoch 0/2] [Batch 282/1583] [D loss: 0.537014] [G loss: 0.239918]\n",
            "[Epoch 0/2] [Batch 283/1583] [D loss: 0.526915] [G loss: 0.243491]\n",
            "[Epoch 0/2] [Batch 284/1583] [D loss: 0.526822] [G loss: 0.225657]\n",
            "[Epoch 0/2] [Batch 285/1583] [D loss: 0.478473] [G loss: 0.236874]\n",
            "[Epoch 0/2] [Batch 286/1583] [D loss: 0.520588] [G loss: 0.240073]\n",
            "[Epoch 0/2] [Batch 287/1583] [D loss: 0.469721] [G loss: 0.237628]\n",
            "[Epoch 0/2] [Batch 288/1583] [D loss: 0.492924] [G loss: 0.233971]\n",
            "[Epoch 0/2] [Batch 289/1583] [D loss: 0.493830] [G loss: 0.232456]\n",
            "[Epoch 0/2] [Batch 290/1583] [D loss: 0.479625] [G loss: 0.233098]\n",
            "[Epoch 0/2] [Batch 291/1583] [D loss: 0.482455] [G loss: 0.231638]\n",
            "[Epoch 0/2] [Batch 292/1583] [D loss: 0.514954] [G loss: 0.233182]\n",
            "[Epoch 0/2] [Batch 293/1583] [D loss: 0.509255] [G loss: 0.235756]\n",
            "[Epoch 0/2] [Batch 294/1583] [D loss: 0.486807] [G loss: 0.237591]\n",
            "[Epoch 0/2] [Batch 295/1583] [D loss: 0.496431] [G loss: 0.230163]\n",
            "[Epoch 0/2] [Batch 296/1583] [D loss: 0.526934] [G loss: 0.235414]\n",
            "[Epoch 0/2] [Batch 297/1583] [D loss: 0.507073] [G loss: 0.231590]\n",
            "[Epoch 0/2] [Batch 298/1583] [D loss: 0.481223] [G loss: 0.233918]\n",
            "[Epoch 0/2] [Batch 299/1583] [D loss: 0.511572] [G loss: 0.235605]\n",
            "[Epoch 0/2] [Batch 300/1583] [D loss: 0.531590] [G loss: 0.233929]\n",
            "[Epoch 0/2] [Batch 301/1583] [D loss: 0.515655] [G loss: 0.238215]\n",
            "[Epoch 0/2] [Batch 302/1583] [D loss: 0.464750] [G loss: 0.230337]\n",
            "[Epoch 0/2] [Batch 303/1583] [D loss: 0.502721] [G loss: 0.228802]\n",
            "[Epoch 0/2] [Batch 304/1583] [D loss: 0.480484] [G loss: 0.225529]\n",
            "[Epoch 0/2] [Batch 305/1583] [D loss: 0.550685] [G loss: 0.230319]\n",
            "[Epoch 0/2] [Batch 306/1583] [D loss: 0.490402] [G loss: 0.236364]\n",
            "[Epoch 0/2] [Batch 307/1583] [D loss: 0.541136] [G loss: 0.234844]\n",
            "[Epoch 0/2] [Batch 308/1583] [D loss: 0.513718] [G loss: 0.232817]\n",
            "[Epoch 0/2] [Batch 309/1583] [D loss: 0.527347] [G loss: 0.236783]\n",
            "[Epoch 0/2] [Batch 310/1583] [D loss: 0.487274] [G loss: 0.233629]\n",
            "[Epoch 0/2] [Batch 311/1583] [D loss: 0.493128] [G loss: 0.234931]\n",
            "[Epoch 0/2] [Batch 312/1583] [D loss: 0.523892] [G loss: 0.228752]\n",
            "[Epoch 0/2] [Batch 313/1583] [D loss: 0.506475] [G loss: 0.230822]\n",
            "[Epoch 0/2] [Batch 314/1583] [D loss: 0.459307] [G loss: 0.230078]\n",
            "[Epoch 0/2] [Batch 315/1583] [D loss: 0.514687] [G loss: 0.230023]\n",
            "[Epoch 0/2] [Batch 316/1583] [D loss: 0.517965] [G loss: 0.243061]\n",
            "[Epoch 0/2] [Batch 317/1583] [D loss: 0.469137] [G loss: 0.223886]\n",
            "[Epoch 0/2] [Batch 318/1583] [D loss: 0.478390] [G loss: 0.236143]\n",
            "[Epoch 0/2] [Batch 319/1583] [D loss: 0.495973] [G loss: 0.230017]\n",
            "[Epoch 0/2] [Batch 320/1583] [D loss: 0.521878] [G loss: 0.221247]\n",
            "[Epoch 0/2] [Batch 321/1583] [D loss: 0.476404] [G loss: 0.231689]\n",
            "[Epoch 0/2] [Batch 322/1583] [D loss: 0.567364] [G loss: 0.225887]\n",
            "[Epoch 0/2] [Batch 323/1583] [D loss: 0.545343] [G loss: 0.230958]\n",
            "[Epoch 0/2] [Batch 324/1583] [D loss: 0.487436] [G loss: 0.226366]\n",
            "[Epoch 0/2] [Batch 325/1583] [D loss: 0.526338] [G loss: 0.234783]\n",
            "[Epoch 0/2] [Batch 326/1583] [D loss: 0.511428] [G loss: 0.228387]\n",
            "[Epoch 0/2] [Batch 327/1583] [D loss: 0.513220] [G loss: 0.232344]\n",
            "[Epoch 0/2] [Batch 328/1583] [D loss: 0.521972] [G loss: 0.231124]\n",
            "[Epoch 0/2] [Batch 329/1583] [D loss: 0.491548] [G loss: 0.244810]\n",
            "[Epoch 0/2] [Batch 330/1583] [D loss: 0.560169] [G loss: 0.237068]\n",
            "[Epoch 0/2] [Batch 331/1583] [D loss: 0.494064] [G loss: 0.228100]\n",
            "[Epoch 0/2] [Batch 332/1583] [D loss: 0.531466] [G loss: 0.224698]\n",
            "[Epoch 0/2] [Batch 333/1583] [D loss: 0.509918] [G loss: 0.234752]\n",
            "[Epoch 0/2] [Batch 334/1583] [D loss: 0.478595] [G loss: 0.226792]\n",
            "[Epoch 0/2] [Batch 335/1583] [D loss: 0.507714] [G loss: 0.237896]\n",
            "[Epoch 0/2] [Batch 336/1583] [D loss: 0.530434] [G loss: 0.228438]\n",
            "[Epoch 0/2] [Batch 337/1583] [D loss: 0.500865] [G loss: 0.236726]\n",
            "[Epoch 0/2] [Batch 338/1583] [D loss: 0.499273] [G loss: 0.228566]\n",
            "[Epoch 0/2] [Batch 339/1583] [D loss: 0.512814] [G loss: 0.235124]\n",
            "[Epoch 0/2] [Batch 340/1583] [D loss: 0.536305] [G loss: 0.236788]\n",
            "[Epoch 0/2] [Batch 341/1583] [D loss: 0.518314] [G loss: 0.233563]\n",
            "[Epoch 0/2] [Batch 342/1583] [D loss: 0.510722] [G loss: 0.241928]\n",
            "[Epoch 0/2] [Batch 343/1583] [D loss: 0.500056] [G loss: 0.232624]\n",
            "[Epoch 0/2] [Batch 344/1583] [D loss: 0.509325] [G loss: 0.223447]\n",
            "[Epoch 0/2] [Batch 345/1583] [D loss: 0.485760] [G loss: 0.235766]\n",
            "[Epoch 0/2] [Batch 346/1583] [D loss: 0.520148] [G loss: 0.229583]\n",
            "[Epoch 0/2] [Batch 347/1583] [D loss: 0.524857] [G loss: 0.226483]\n",
            "[Epoch 0/2] [Batch 348/1583] [D loss: 0.523737] [G loss: 0.228519]\n",
            "[Epoch 0/2] [Batch 349/1583] [D loss: 0.533188] [G loss: 0.224828]\n",
            "[Epoch 0/2] [Batch 350/1583] [D loss: 0.500085] [G loss: 0.225881]\n",
            "[Epoch 0/2] [Batch 351/1583] [D loss: 0.510840] [G loss: 0.219552]\n",
            "[Epoch 0/2] [Batch 352/1583] [D loss: 0.490174] [G loss: 0.232481]\n",
            "[Epoch 0/2] [Batch 353/1583] [D loss: 0.526220] [G loss: 0.230487]\n",
            "[Epoch 0/2] [Batch 354/1583] [D loss: 0.507962] [G loss: 0.233127]\n",
            "[Epoch 0/2] [Batch 355/1583] [D loss: 0.527532] [G loss: 0.223365]\n",
            "[Epoch 0/2] [Batch 356/1583] [D loss: 0.532393] [G loss: 0.232348]\n",
            "[Epoch 0/2] [Batch 357/1583] [D loss: 0.529762] [G loss: 0.228012]\n",
            "[Epoch 0/2] [Batch 358/1583] [D loss: 0.544367] [G loss: 0.230451]\n",
            "[Epoch 0/2] [Batch 359/1583] [D loss: 0.540969] [G loss: 0.240647]\n",
            "[Epoch 0/2] [Batch 360/1583] [D loss: 0.538137] [G loss: 0.239708]\n",
            "[Epoch 0/2] [Batch 361/1583] [D loss: 0.500097] [G loss: 0.231488]\n",
            "[Epoch 0/2] [Batch 362/1583] [D loss: 0.537645] [G loss: 0.238855]\n",
            "[Epoch 0/2] [Batch 363/1583] [D loss: 0.550431] [G loss: 0.223466]\n",
            "[Epoch 0/2] [Batch 364/1583] [D loss: 0.527778] [G loss: 0.233821]\n",
            "[Epoch 0/2] [Batch 365/1583] [D loss: 0.561073] [G loss: 0.227698]\n",
            "[Epoch 0/2] [Batch 366/1583] [D loss: 0.558596] [G loss: 0.224649]\n",
            "[Epoch 0/2] [Batch 367/1583] [D loss: 0.546765] [G loss: 0.227625]\n",
            "[Epoch 0/2] [Batch 368/1583] [D loss: 0.508507] [G loss: 0.229116]\n",
            "[Epoch 0/2] [Batch 369/1583] [D loss: 0.547294] [G loss: 0.224227]\n",
            "[Epoch 0/2] [Batch 370/1583] [D loss: 0.521128] [G loss: 0.232388]\n",
            "[Epoch 0/2] [Batch 371/1583] [D loss: 0.547168] [G loss: 0.234650]\n",
            "[Epoch 0/2] [Batch 372/1583] [D loss: 0.558811] [G loss: 0.227243]\n",
            "[Epoch 0/2] [Batch 373/1583] [D loss: 0.539711] [G loss: 0.225280]\n",
            "[Epoch 0/2] [Batch 374/1583] [D loss: 0.547307] [G loss: 0.214611]\n",
            "[Epoch 0/2] [Batch 375/1583] [D loss: 0.541981] [G loss: 0.225795]\n",
            "[Epoch 0/2] [Batch 376/1583] [D loss: 0.570692] [G loss: 0.230473]\n",
            "[Epoch 0/2] [Batch 377/1583] [D loss: 0.550834] [G loss: 0.230056]\n",
            "[Epoch 0/2] [Batch 378/1583] [D loss: 0.537213] [G loss: 0.227692]\n",
            "[Epoch 0/2] [Batch 379/1583] [D loss: 0.542231] [G loss: 0.227662]\n",
            "[Epoch 0/2] [Batch 380/1583] [D loss: 0.577504] [G loss: 0.219427]\n",
            "[Epoch 0/2] [Batch 381/1583] [D loss: 0.578309] [G loss: 0.231391]\n",
            "[Epoch 0/2] [Batch 382/1583] [D loss: 0.551968] [G loss: 0.230655]\n",
            "[Epoch 0/2] [Batch 383/1583] [D loss: 0.518514] [G loss: 0.221083]\n",
            "[Epoch 0/2] [Batch 384/1583] [D loss: 0.552371] [G loss: 0.236187]\n",
            "[Epoch 0/2] [Batch 385/1583] [D loss: 0.535239] [G loss: 0.228533]\n",
            "[Epoch 0/2] [Batch 386/1583] [D loss: 0.535379] [G loss: 0.231885]\n",
            "[Epoch 0/2] [Batch 387/1583] [D loss: 0.549084] [G loss: 0.221439]\n",
            "[Epoch 0/2] [Batch 388/1583] [D loss: 0.567689] [G loss: 0.225977]\n",
            "[Epoch 0/2] [Batch 389/1583] [D loss: 0.534599] [G loss: 0.232832]\n",
            "[Epoch 0/2] [Batch 390/1583] [D loss: 0.540755] [G loss: 0.219657]\n",
            "[Epoch 0/2] [Batch 391/1583] [D loss: 0.560571] [G loss: 0.234384]\n",
            "[Epoch 0/2] [Batch 392/1583] [D loss: 0.549782] [G loss: 0.217162]\n",
            "[Epoch 0/2] [Batch 393/1583] [D loss: 0.544433] [G loss: 0.228591]\n",
            "[Epoch 0/2] [Batch 394/1583] [D loss: 0.515961] [G loss: 0.231914]\n",
            "[Epoch 0/2] [Batch 395/1583] [D loss: 0.523222] [G loss: 0.219131]\n",
            "[Epoch 0/2] [Batch 396/1583] [D loss: 0.536729] [G loss: 0.226298]\n",
            "[Epoch 0/2] [Batch 397/1583] [D loss: 0.542652] [G loss: 0.226384]\n",
            "[Epoch 0/2] [Batch 398/1583] [D loss: 0.593028] [G loss: 0.227894]\n",
            "[Epoch 0/2] [Batch 399/1583] [D loss: 0.612708] [G loss: 0.225311]\n",
            "[Epoch 0/2] [Batch 400/1583] [D loss: 0.557550] [G loss: 0.223655]\n",
            "[Epoch 0/2] [Batch 401/1583] [D loss: 0.572398] [G loss: 0.223103]\n",
            "[Epoch 0/2] [Batch 402/1583] [D loss: 0.574101] [G loss: 0.215694]\n",
            "[Epoch 0/2] [Batch 403/1583] [D loss: 0.520116] [G loss: 0.238518]\n",
            "[Epoch 0/2] [Batch 404/1583] [D loss: 0.559997] [G loss: 0.222031]\n",
            "[Epoch 0/2] [Batch 405/1583] [D loss: 0.584676] [G loss: 0.224322]\n",
            "[Epoch 0/2] [Batch 406/1583] [D loss: 0.549748] [G loss: 0.229473]\n",
            "[Epoch 0/2] [Batch 407/1583] [D loss: 0.546391] [G loss: 0.226648]\n",
            "[Epoch 0/2] [Batch 408/1583] [D loss: 0.547723] [G loss: 0.226908]\n",
            "[Epoch 0/2] [Batch 409/1583] [D loss: 0.566866] [G loss: 0.232161]\n",
            "[Epoch 0/2] [Batch 410/1583] [D loss: 0.566695] [G loss: 0.222205]\n",
            "[Epoch 0/2] [Batch 411/1583] [D loss: 0.529112] [G loss: 0.224408]\n",
            "[Epoch 0/2] [Batch 412/1583] [D loss: 0.589438] [G loss: 0.230103]\n",
            "[Epoch 0/2] [Batch 413/1583] [D loss: 0.605808] [G loss: 0.222471]\n",
            "[Epoch 0/2] [Batch 414/1583] [D loss: 0.568189] [G loss: 0.226597]\n",
            "[Epoch 0/2] [Batch 415/1583] [D loss: 0.562964] [G loss: 0.230618]\n",
            "[Epoch 0/2] [Batch 416/1583] [D loss: 0.557721] [G loss: 0.227603]\n",
            "[Epoch 0/2] [Batch 417/1583] [D loss: 0.551557] [G loss: 0.227431]\n",
            "[Epoch 0/2] [Batch 418/1583] [D loss: 0.569922] [G loss: 0.220906]\n",
            "[Epoch 0/2] [Batch 419/1583] [D loss: 0.595307] [G loss: 0.229288]\n",
            "[Epoch 0/2] [Batch 420/1583] [D loss: 0.536302] [G loss: 0.231316]\n",
            "[Epoch 0/2] [Batch 421/1583] [D loss: 0.556740] [G loss: 0.233946]\n",
            "[Epoch 0/2] [Batch 422/1583] [D loss: 0.568633] [G loss: 0.218396]\n",
            "[Epoch 0/2] [Batch 423/1583] [D loss: 0.560369] [G loss: 0.229503]\n",
            "[Epoch 0/2] [Batch 424/1583] [D loss: 0.515069] [G loss: 0.225509]\n",
            "[Epoch 0/2] [Batch 425/1583] [D loss: 0.527470] [G loss: 0.227509]\n",
            "[Epoch 0/2] [Batch 426/1583] [D loss: 0.558984] [G loss: 0.230709]\n",
            "[Epoch 0/2] [Batch 427/1583] [D loss: 0.579519] [G loss: 0.224155]\n",
            "[Epoch 0/2] [Batch 428/1583] [D loss: 0.530190] [G loss: 0.220696]\n",
            "[Epoch 0/2] [Batch 429/1583] [D loss: 0.563022] [G loss: 0.219279]\n",
            "[Epoch 0/2] [Batch 430/1583] [D loss: 0.546621] [G loss: 0.221456]\n",
            "[Epoch 0/2] [Batch 431/1583] [D loss: 0.561726] [G loss: 0.214064]\n",
            "[Epoch 0/2] [Batch 432/1583] [D loss: 0.549992] [G loss: 0.219192]\n",
            "[Epoch 0/2] [Batch 433/1583] [D loss: 0.546277] [G loss: 0.220460]\n",
            "[Epoch 0/2] [Batch 434/1583] [D loss: 0.582857] [G loss: 0.214514]\n",
            "[Epoch 0/2] [Batch 435/1583] [D loss: 0.567110] [G loss: 0.226298]\n",
            "[Epoch 0/2] [Batch 436/1583] [D loss: 0.526020] [G loss: 0.228885]\n",
            "[Epoch 0/2] [Batch 437/1583] [D loss: 0.536413] [G loss: 0.225513]\n",
            "[Epoch 0/2] [Batch 438/1583] [D loss: 0.529759] [G loss: 0.223554]\n",
            "[Epoch 0/2] [Batch 439/1583] [D loss: 0.563922] [G loss: 0.227389]\n",
            "[Epoch 0/2] [Batch 440/1583] [D loss: 0.558832] [G loss: 0.221162]\n",
            "[Epoch 0/2] [Batch 441/1583] [D loss: 0.557023] [G loss: 0.225993]\n",
            "[Epoch 0/2] [Batch 442/1583] [D loss: 0.562937] [G loss: 0.221572]\n",
            "[Epoch 0/2] [Batch 443/1583] [D loss: 0.528257] [G loss: 0.222936]\n",
            "[Epoch 0/2] [Batch 444/1583] [D loss: 0.580110] [G loss: 0.220012]\n",
            "[Epoch 0/2] [Batch 445/1583] [D loss: 0.574745] [G loss: 0.222951]\n",
            "[Epoch 0/2] [Batch 446/1583] [D loss: 0.565886] [G loss: 0.226203]\n",
            "[Epoch 0/2] [Batch 447/1583] [D loss: 0.557282] [G loss: 0.230066]\n",
            "[Epoch 0/2] [Batch 448/1583] [D loss: 0.551230] [G loss: 0.225799]\n",
            "[Epoch 0/2] [Batch 449/1583] [D loss: 0.559424] [G loss: 0.229020]\n",
            "[Epoch 0/2] [Batch 450/1583] [D loss: 0.557296] [G loss: 0.226536]\n",
            "[Epoch 0/2] [Batch 451/1583] [D loss: 0.609574] [G loss: 0.230834]\n",
            "[Epoch 0/2] [Batch 452/1583] [D loss: 0.548745] [G loss: 0.230378]\n",
            "[Epoch 0/2] [Batch 453/1583] [D loss: 0.529812] [G loss: 0.223273]\n",
            "[Epoch 0/2] [Batch 454/1583] [D loss: 0.598543] [G loss: 0.216257]\n",
            "[Epoch 0/2] [Batch 455/1583] [D loss: 0.570666] [G loss: 0.224281]\n",
            "[Epoch 0/2] [Batch 456/1583] [D loss: 0.551535] [G loss: 0.221108]\n",
            "[Epoch 0/2] [Batch 457/1583] [D loss: 0.559609] [G loss: 0.219424]\n",
            "[Epoch 0/2] [Batch 458/1583] [D loss: 0.597975] [G loss: 0.224137]\n",
            "[Epoch 0/2] [Batch 459/1583] [D loss: 0.543508] [G loss: 0.223186]\n",
            "[Epoch 0/2] [Batch 460/1583] [D loss: 0.552480] [G loss: 0.217254]\n",
            "[Epoch 0/2] [Batch 461/1583] [D loss: 0.556665] [G loss: 0.219397]\n",
            "[Epoch 0/2] [Batch 462/1583] [D loss: 0.580157] [G loss: 0.225519]\n",
            "[Epoch 0/2] [Batch 463/1583] [D loss: 0.568689] [G loss: 0.228624]\n",
            "[Epoch 0/2] [Batch 464/1583] [D loss: 0.537995] [G loss: 0.226988]\n",
            "[Epoch 0/2] [Batch 465/1583] [D loss: 0.566713] [G loss: 0.220709]\n",
            "[Epoch 0/2] [Batch 466/1583] [D loss: 0.558402] [G loss: 0.223376]\n",
            "[Epoch 0/2] [Batch 467/1583] [D loss: 0.566936] [G loss: 0.218611]\n",
            "[Epoch 0/2] [Batch 468/1583] [D loss: 0.606745] [G loss: 0.217324]\n",
            "[Epoch 0/2] [Batch 469/1583] [D loss: 0.607681] [G loss: 0.224196]\n",
            "[Epoch 0/2] [Batch 470/1583] [D loss: 0.536784] [G loss: 0.219853]\n",
            "[Epoch 0/2] [Batch 471/1583] [D loss: 0.516722] [G loss: 0.212225]\n",
            "[Epoch 0/2] [Batch 472/1583] [D loss: 0.535401] [G loss: 0.222189]\n",
            "[Epoch 0/2] [Batch 473/1583] [D loss: 0.575774] [G loss: 0.219922]\n",
            "[Epoch 0/2] [Batch 474/1583] [D loss: 0.554535] [G loss: 0.219178]\n",
            "[Epoch 0/2] [Batch 475/1583] [D loss: 0.554323] [G loss: 0.215748]\n",
            "[Epoch 0/2] [Batch 476/1583] [D loss: 0.586545] [G loss: 0.226258]\n",
            "[Epoch 0/2] [Batch 477/1583] [D loss: 0.569733] [G loss: 0.220324]\n",
            "[Epoch 0/2] [Batch 478/1583] [D loss: 0.558432] [G loss: 0.224277]\n",
            "[Epoch 0/2] [Batch 479/1583] [D loss: 0.555096] [G loss: 0.219754]\n",
            "[Epoch 0/2] [Batch 480/1583] [D loss: 0.595887] [G loss: 0.221897]\n",
            "[Epoch 0/2] [Batch 481/1583] [D loss: 0.573923] [G loss: 0.219412]\n",
            "[Epoch 0/2] [Batch 482/1583] [D loss: 0.549079] [G loss: 0.224281]\n",
            "[Epoch 0/2] [Batch 483/1583] [D loss: 0.582582] [G loss: 0.215975]\n",
            "[Epoch 0/2] [Batch 484/1583] [D loss: 0.572632] [G loss: 0.207641]\n",
            "[Epoch 0/2] [Batch 485/1583] [D loss: 0.550974] [G loss: 0.226768]\n",
            "[Epoch 0/2] [Batch 486/1583] [D loss: 0.604858] [G loss: 0.221481]\n",
            "[Epoch 0/2] [Batch 487/1583] [D loss: 0.576367] [G loss: 0.223568]\n",
            "[Epoch 0/2] [Batch 488/1583] [D loss: 0.590225] [G loss: 0.215741]\n",
            "[Epoch 0/2] [Batch 489/1583] [D loss: 0.600201] [G loss: 0.228832]\n",
            "[Epoch 0/2] [Batch 490/1583] [D loss: 0.531101] [G loss: 0.224261]\n",
            "[Epoch 0/2] [Batch 491/1583] [D loss: 0.554490] [G loss: 0.223677]\n",
            "[Epoch 0/2] [Batch 492/1583] [D loss: 0.519930] [G loss: 0.227634]\n",
            "[Epoch 0/2] [Batch 493/1583] [D loss: 0.583173] [G loss: 0.224543]\n",
            "[Epoch 0/2] [Batch 494/1583] [D loss: 0.547636] [G loss: 0.216748]\n",
            "[Epoch 0/2] [Batch 495/1583] [D loss: 0.593828] [G loss: 0.218938]\n",
            "[Epoch 0/2] [Batch 496/1583] [D loss: 0.543703] [G loss: 0.219076]\n",
            "[Epoch 0/2] [Batch 497/1583] [D loss: 0.547139] [G loss: 0.222071]\n",
            "[Epoch 0/2] [Batch 498/1583] [D loss: 0.600627] [G loss: 0.215725]\n",
            "[Epoch 0/2] [Batch 499/1583] [D loss: 0.577613] [G loss: 0.227733]\n",
            "[Epoch 0/2] [Batch 500/1583] [D loss: 0.557500] [G loss: 0.219233]\n",
            "[Epoch 0/2] [Batch 501/1583] [D loss: 0.566275] [G loss: 0.220340]\n",
            "[Epoch 0/2] [Batch 502/1583] [D loss: 0.546672] [G loss: 0.216353]\n",
            "[Epoch 0/2] [Batch 503/1583] [D loss: 0.569348] [G loss: 0.224811]\n",
            "[Epoch 0/2] [Batch 504/1583] [D loss: 0.575898] [G loss: 0.218302]\n",
            "[Epoch 0/2] [Batch 505/1583] [D loss: 0.563363] [G loss: 0.224637]\n",
            "[Epoch 0/2] [Batch 506/1583] [D loss: 0.559680] [G loss: 0.215074]\n",
            "[Epoch 0/2] [Batch 507/1583] [D loss: 0.591586] [G loss: 0.219267]\n",
            "[Epoch 0/2] [Batch 508/1583] [D loss: 0.561899] [G loss: 0.221658]\n",
            "[Epoch 0/2] [Batch 509/1583] [D loss: 0.567667] [G loss: 0.225130]\n",
            "[Epoch 0/2] [Batch 510/1583] [D loss: 0.551901] [G loss: 0.223933]\n",
            "[Epoch 0/2] [Batch 511/1583] [D loss: 0.589093] [G loss: 0.217587]\n",
            "[Epoch 0/2] [Batch 512/1583] [D loss: 0.561879] [G loss: 0.223143]\n",
            "[Epoch 0/2] [Batch 513/1583] [D loss: 0.563161] [G loss: 0.217615]\n",
            "[Epoch 0/2] [Batch 514/1583] [D loss: 0.562629] [G loss: 0.218769]\n",
            "[Epoch 0/2] [Batch 515/1583] [D loss: 0.555904] [G loss: 0.219223]\n",
            "[Epoch 0/2] [Batch 516/1583] [D loss: 0.548369] [G loss: 0.214335]\n",
            "[Epoch 0/2] [Batch 517/1583] [D loss: 0.583518] [G loss: 0.232760]\n",
            "[Epoch 0/2] [Batch 518/1583] [D loss: 0.565992] [G loss: 0.218329]\n",
            "[Epoch 0/2] [Batch 519/1583] [D loss: 0.561034] [G loss: 0.220385]\n",
            "[Epoch 0/2] [Batch 520/1583] [D loss: 0.555113] [G loss: 0.212211]\n",
            "[Epoch 0/2] [Batch 521/1583] [D loss: 0.563145] [G loss: 0.211627]\n",
            "[Epoch 0/2] [Batch 522/1583] [D loss: 0.564412] [G loss: 0.230864]\n",
            "[Epoch 0/2] [Batch 523/1583] [D loss: 0.578793] [G loss: 0.220501]\n",
            "[Epoch 0/2] [Batch 524/1583] [D loss: 0.570182] [G loss: 0.225646]\n",
            "[Epoch 0/2] [Batch 525/1583] [D loss: 0.562142] [G loss: 0.209403]\n",
            "[Epoch 0/2] [Batch 526/1583] [D loss: 0.553046] [G loss: 0.234537]\n",
            "[Epoch 0/2] [Batch 527/1583] [D loss: 0.578366] [G loss: 0.220550]\n",
            "[Epoch 0/2] [Batch 528/1583] [D loss: 0.591049] [G loss: 0.223445]\n",
            "[Epoch 0/2] [Batch 529/1583] [D loss: 0.567931] [G loss: 0.223874]\n",
            "[Epoch 0/2] [Batch 530/1583] [D loss: 0.564181] [G loss: 0.222031]\n",
            "[Epoch 0/2] [Batch 531/1583] [D loss: 0.536988] [G loss: 0.212504]\n",
            "[Epoch 0/2] [Batch 532/1583] [D loss: 0.602008] [G loss: 0.225909]\n",
            "[Epoch 0/2] [Batch 533/1583] [D loss: 0.626710] [G loss: 0.221743]\n",
            "[Epoch 0/2] [Batch 534/1583] [D loss: 0.593074] [G loss: 0.227148]\n",
            "[Epoch 0/2] [Batch 535/1583] [D loss: 0.568447] [G loss: 0.222681]\n",
            "[Epoch 0/2] [Batch 536/1583] [D loss: 0.589022] [G loss: 0.220075]\n",
            "[Epoch 0/2] [Batch 537/1583] [D loss: 0.559079] [G loss: 0.213824]\n",
            "[Epoch 0/2] [Batch 538/1583] [D loss: 0.605849] [G loss: 0.231206]\n",
            "[Epoch 0/2] [Batch 539/1583] [D loss: 0.557861] [G loss: 0.219356]\n",
            "[Epoch 0/2] [Batch 540/1583] [D loss: 0.557616] [G loss: 0.216292]\n",
            "[Epoch 0/2] [Batch 541/1583] [D loss: 0.563904] [G loss: 0.210946]\n",
            "[Epoch 0/2] [Batch 542/1583] [D loss: 0.570363] [G loss: 0.217676]\n",
            "[Epoch 0/2] [Batch 543/1583] [D loss: 0.520643] [G loss: 0.214407]\n",
            "[Epoch 0/2] [Batch 544/1583] [D loss: 0.578833] [G loss: 0.211017]\n",
            "[Epoch 0/2] [Batch 545/1583] [D loss: 0.574468] [G loss: 0.225349]\n",
            "[Epoch 0/2] [Batch 546/1583] [D loss: 0.581021] [G loss: 0.220873]\n",
            "[Epoch 0/2] [Batch 547/1583] [D loss: 0.600922] [G loss: 0.223488]\n",
            "[Epoch 0/2] [Batch 548/1583] [D loss: 0.581179] [G loss: 0.225164]\n",
            "[Epoch 0/2] [Batch 549/1583] [D loss: 0.569848] [G loss: 0.214181]\n",
            "[Epoch 0/2] [Batch 550/1583] [D loss: 0.555289] [G loss: 0.224531]\n",
            "[Epoch 0/2] [Batch 551/1583] [D loss: 0.569204] [G loss: 0.226448]\n",
            "[Epoch 0/2] [Batch 552/1583] [D loss: 0.571730] [G loss: 0.225358]\n",
            "[Epoch 0/2] [Batch 553/1583] [D loss: 0.565175] [G loss: 0.226242]\n",
            "[Epoch 0/2] [Batch 554/1583] [D loss: 0.598321] [G loss: 0.223736]\n",
            "[Epoch 0/2] [Batch 555/1583] [D loss: 0.555749] [G loss: 0.229116]\n",
            "[Epoch 0/2] [Batch 556/1583] [D loss: 0.575291] [G loss: 0.231934]\n",
            "[Epoch 0/2] [Batch 557/1583] [D loss: 0.555726] [G loss: 0.217971]\n",
            "[Epoch 0/2] [Batch 558/1583] [D loss: 0.540621] [G loss: 0.218665]\n",
            "[Epoch 0/2] [Batch 559/1583] [D loss: 0.593606] [G loss: 0.223139]\n",
            "[Epoch 0/2] [Batch 560/1583] [D loss: 0.573401] [G loss: 0.230732]\n",
            "[Epoch 0/2] [Batch 561/1583] [D loss: 0.597200] [G loss: 0.223869]\n",
            "[Epoch 0/2] [Batch 562/1583] [D loss: 0.584262] [G loss: 0.217242]\n",
            "[Epoch 0/2] [Batch 563/1583] [D loss: 0.599338] [G loss: 0.217706]\n",
            "[Epoch 0/2] [Batch 564/1583] [D loss: 0.569579] [G loss: 0.231416]\n",
            "[Epoch 0/2] [Batch 565/1583] [D loss: 0.581769] [G loss: 0.217681]\n",
            "[Epoch 0/2] [Batch 566/1583] [D loss: 0.564716] [G loss: 0.218317]\n",
            "[Epoch 0/2] [Batch 567/1583] [D loss: 0.561231] [G loss: 0.222817]\n",
            "[Epoch 0/2] [Batch 568/1583] [D loss: 0.569796] [G loss: 0.213876]\n",
            "[Epoch 0/2] [Batch 569/1583] [D loss: 0.568330] [G loss: 0.226176]\n",
            "[Epoch 0/2] [Batch 570/1583] [D loss: 0.541201] [G loss: 0.225445]\n",
            "[Epoch 0/2] [Batch 571/1583] [D loss: 0.613614] [G loss: 0.219350]\n",
            "[Epoch 0/2] [Batch 572/1583] [D loss: 0.593084] [G loss: 0.223837]\n",
            "[Epoch 0/2] [Batch 573/1583] [D loss: 0.568886] [G loss: 0.222664]\n",
            "[Epoch 0/2] [Batch 574/1583] [D loss: 0.561105] [G loss: 0.226880]\n",
            "[Epoch 0/2] [Batch 575/1583] [D loss: 0.554252] [G loss: 0.232410]\n",
            "[Epoch 0/2] [Batch 576/1583] [D loss: 0.618142] [G loss: 0.226407]\n",
            "[Epoch 0/2] [Batch 577/1583] [D loss: 0.576513] [G loss: 0.209669]\n",
            "[Epoch 0/2] [Batch 578/1583] [D loss: 0.568639] [G loss: 0.228207]\n",
            "[Epoch 0/2] [Batch 579/1583] [D loss: 0.562108] [G loss: 0.231286]\n",
            "[Epoch 0/2] [Batch 580/1583] [D loss: 0.589140] [G loss: 0.214586]\n",
            "[Epoch 0/2] [Batch 581/1583] [D loss: 0.571307] [G loss: 0.221349]\n",
            "[Epoch 0/2] [Batch 582/1583] [D loss: 0.569271] [G loss: 0.212146]\n",
            "[Epoch 0/2] [Batch 583/1583] [D loss: 0.586232] [G loss: 0.220773]\n",
            "[Epoch 0/2] [Batch 584/1583] [D loss: 0.583903] [G loss: 0.226716]\n",
            "[Epoch 0/2] [Batch 585/1583] [D loss: 0.584781] [G loss: 0.223665]\n",
            "[Epoch 0/2] [Batch 586/1583] [D loss: 0.539415] [G loss: 0.218578]\n",
            "[Epoch 0/2] [Batch 587/1583] [D loss: 0.575607] [G loss: 0.224657]\n",
            "[Epoch 0/2] [Batch 588/1583] [D loss: 0.564260] [G loss: 0.218910]\n",
            "[Epoch 0/2] [Batch 589/1583] [D loss: 0.586157] [G loss: 0.226964]\n",
            "[Epoch 0/2] [Batch 590/1583] [D loss: 0.589367] [G loss: 0.224517]\n",
            "[Epoch 0/2] [Batch 591/1583] [D loss: 0.545602] [G loss: 0.222757]\n",
            "[Epoch 0/2] [Batch 592/1583] [D loss: 0.560897] [G loss: 0.221866]\n",
            "[Epoch 0/2] [Batch 593/1583] [D loss: 0.586402] [G loss: 0.222035]\n",
            "[Epoch 0/2] [Batch 594/1583] [D loss: 0.577214] [G loss: 0.242938]\n",
            "[Epoch 0/2] [Batch 595/1583] [D loss: 0.573446] [G loss: 0.213120]\n",
            "[Epoch 0/2] [Batch 596/1583] [D loss: 0.627169] [G loss: 0.219208]\n",
            "[Epoch 0/2] [Batch 597/1583] [D loss: 0.535745] [G loss: 0.214599]\n",
            "[Epoch 0/2] [Batch 598/1583] [D loss: 0.561338] [G loss: 0.218052]\n",
            "[Epoch 0/2] [Batch 599/1583] [D loss: 0.579888] [G loss: 0.223111]\n",
            "[Epoch 0/2] [Batch 600/1583] [D loss: 0.558074] [G loss: 0.217900]\n",
            "[Epoch 0/2] [Batch 601/1583] [D loss: 0.601180] [G loss: 0.219623]\n",
            "[Epoch 0/2] [Batch 602/1583] [D loss: 0.593190] [G loss: 0.218390]\n",
            "[Epoch 0/2] [Batch 603/1583] [D loss: 0.571627] [G loss: 0.215011]\n",
            "[Epoch 0/2] [Batch 604/1583] [D loss: 0.550236] [G loss: 0.216845]\n",
            "[Epoch 0/2] [Batch 605/1583] [D loss: 0.580856] [G loss: 0.226379]\n",
            "[Epoch 0/2] [Batch 606/1583] [D loss: 0.581870] [G loss: 0.216203]\n",
            "[Epoch 0/2] [Batch 607/1583] [D loss: 0.580665] [G loss: 0.216152]\n",
            "[Epoch 0/2] [Batch 608/1583] [D loss: 0.573737] [G loss: 0.218570]\n",
            "[Epoch 0/2] [Batch 609/1583] [D loss: 0.617077] [G loss: 0.217150]\n",
            "[Epoch 0/2] [Batch 610/1583] [D loss: 0.574859] [G loss: 0.215319]\n",
            "[Epoch 0/2] [Batch 611/1583] [D loss: 0.568237] [G loss: 0.225199]\n",
            "[Epoch 0/2] [Batch 612/1583] [D loss: 0.564636] [G loss: 0.214850]\n",
            "[Epoch 0/2] [Batch 613/1583] [D loss: 0.569407] [G loss: 0.229476]\n",
            "[Epoch 0/2] [Batch 614/1583] [D loss: 0.598353] [G loss: 0.217079]\n",
            "[Epoch 0/2] [Batch 615/1583] [D loss: 0.570843] [G loss: 0.217384]\n",
            "[Epoch 0/2] [Batch 616/1583] [D loss: 0.557601] [G loss: 0.218940]\n",
            "[Epoch 0/2] [Batch 617/1583] [D loss: 0.585698] [G loss: 0.216824]\n",
            "[Epoch 0/2] [Batch 618/1583] [D loss: 0.566227] [G loss: 0.218652]\n",
            "[Epoch 0/2] [Batch 619/1583] [D loss: 0.552125] [G loss: 0.225696]\n",
            "[Epoch 0/2] [Batch 620/1583] [D loss: 0.581736] [G loss: 0.216352]\n",
            "[Epoch 0/2] [Batch 621/1583] [D loss: 0.580295] [G loss: 0.215481]\n",
            "[Epoch 0/2] [Batch 622/1583] [D loss: 0.580262] [G loss: 0.219462]\n",
            "[Epoch 0/2] [Batch 623/1583] [D loss: 0.543601] [G loss: 0.216372]\n",
            "[Epoch 0/2] [Batch 624/1583] [D loss: 0.597967] [G loss: 0.213828]\n",
            "[Epoch 0/2] [Batch 625/1583] [D loss: 0.583750] [G loss: 0.223541]\n",
            "[Epoch 0/2] [Batch 626/1583] [D loss: 0.587569] [G loss: 0.217063]\n",
            "[Epoch 0/2] [Batch 627/1583] [D loss: 0.593455] [G loss: 0.218092]\n",
            "[Epoch 0/2] [Batch 628/1583] [D loss: 0.555599] [G loss: 0.224019]\n",
            "[Epoch 0/2] [Batch 629/1583] [D loss: 0.602321] [G loss: 0.218646]\n",
            "[Epoch 0/2] [Batch 630/1583] [D loss: 0.547329] [G loss: 0.203499]\n",
            "[Epoch 0/2] [Batch 631/1583] [D loss: 0.575931] [G loss: 0.216156]\n",
            "[Epoch 0/2] [Batch 632/1583] [D loss: 0.602035] [G loss: 0.224406]\n",
            "[Epoch 0/2] [Batch 633/1583] [D loss: 0.564705] [G loss: 0.214331]\n",
            "[Epoch 0/2] [Batch 634/1583] [D loss: 0.585143] [G loss: 0.215350]\n",
            "[Epoch 0/2] [Batch 635/1583] [D loss: 0.550421] [G loss: 0.221281]\n",
            "[Epoch 0/2] [Batch 636/1583] [D loss: 0.609648] [G loss: 0.228577]\n",
            "[Epoch 0/2] [Batch 637/1583] [D loss: 0.590147] [G loss: 0.216315]\n",
            "[Epoch 0/2] [Batch 638/1583] [D loss: 0.567207] [G loss: 0.222258]\n",
            "[Epoch 0/2] [Batch 639/1583] [D loss: 0.609468] [G loss: 0.219185]\n",
            "[Epoch 0/2] [Batch 640/1583] [D loss: 0.591579] [G loss: 0.215226]\n",
            "[Epoch 0/2] [Batch 641/1583] [D loss: 0.604577] [G loss: 0.221081]\n",
            "[Epoch 0/2] [Batch 642/1583] [D loss: 0.557879] [G loss: 0.214485]\n",
            "[Epoch 0/2] [Batch 643/1583] [D loss: 0.547377] [G loss: 0.213243]\n",
            "[Epoch 0/2] [Batch 644/1583] [D loss: 0.575861] [G loss: 0.226019]\n",
            "[Epoch 0/2] [Batch 645/1583] [D loss: 0.577922] [G loss: 0.214103]\n",
            "[Epoch 0/2] [Batch 646/1583] [D loss: 0.570961] [G loss: 0.213358]\n",
            "[Epoch 0/2] [Batch 647/1583] [D loss: 0.580201] [G loss: 0.215205]\n",
            "[Epoch 0/2] [Batch 648/1583] [D loss: 0.595185] [G loss: 0.215614]\n",
            "[Epoch 0/2] [Batch 649/1583] [D loss: 0.571492] [G loss: 0.225327]\n",
            "[Epoch 0/2] [Batch 650/1583] [D loss: 0.587077] [G loss: 0.213631]\n",
            "[Epoch 0/2] [Batch 651/1583] [D loss: 0.596051] [G loss: 0.221570]\n",
            "[Epoch 0/2] [Batch 652/1583] [D loss: 0.571000] [G loss: 0.216571]\n",
            "[Epoch 0/2] [Batch 653/1583] [D loss: 0.546293] [G loss: 0.218903]\n",
            "[Epoch 0/2] [Batch 654/1583] [D loss: 0.593692] [G loss: 0.223353]\n",
            "[Epoch 0/2] [Batch 655/1583] [D loss: 0.567823] [G loss: 0.219735]\n",
            "[Epoch 0/2] [Batch 656/1583] [D loss: 0.528443] [G loss: 0.219207]\n",
            "[Epoch 0/2] [Batch 657/1583] [D loss: 0.582659] [G loss: 0.219075]\n",
            "[Epoch 0/2] [Batch 658/1583] [D loss: 0.579499] [G loss: 0.219127]\n",
            "[Epoch 0/2] [Batch 659/1583] [D loss: 0.609431] [G loss: 0.222928]\n",
            "[Epoch 0/2] [Batch 660/1583] [D loss: 0.602718] [G loss: 0.219373]\n",
            "[Epoch 0/2] [Batch 661/1583] [D loss: 0.558148] [G loss: 0.211049]\n",
            "[Epoch 0/2] [Batch 662/1583] [D loss: 0.555389] [G loss: 0.222727]\n",
            "[Epoch 0/2] [Batch 663/1583] [D loss: 0.623471] [G loss: 0.222880]\n",
            "[Epoch 0/2] [Batch 664/1583] [D loss: 0.586083] [G loss: 0.215764]\n",
            "[Epoch 0/2] [Batch 665/1583] [D loss: 0.597875] [G loss: 0.221347]\n",
            "[Epoch 0/2] [Batch 666/1583] [D loss: 0.549469] [G loss: 0.229147]\n",
            "[Epoch 0/2] [Batch 667/1583] [D loss: 0.588275] [G loss: 0.224127]\n",
            "[Epoch 0/2] [Batch 668/1583] [D loss: 0.603376] [G loss: 0.218951]\n",
            "[Epoch 0/2] [Batch 669/1583] [D loss: 0.541348] [G loss: 0.219242]\n",
            "[Epoch 0/2] [Batch 670/1583] [D loss: 0.560840] [G loss: 0.217605]\n",
            "[Epoch 0/2] [Batch 671/1583] [D loss: 0.583293] [G loss: 0.223189]\n",
            "[Epoch 0/2] [Batch 672/1583] [D loss: 0.590784] [G loss: 0.219292]\n",
            "[Epoch 0/2] [Batch 673/1583] [D loss: 0.573134] [G loss: 0.225159]\n",
            "[Epoch 0/2] [Batch 674/1583] [D loss: 0.587006] [G loss: 0.214224]\n",
            "[Epoch 0/2] [Batch 675/1583] [D loss: 0.569800] [G loss: 0.214754]\n",
            "[Epoch 0/2] [Batch 676/1583] [D loss: 0.531383] [G loss: 0.221138]\n",
            "[Epoch 0/2] [Batch 677/1583] [D loss: 0.593880] [G loss: 0.211352]\n",
            "[Epoch 0/2] [Batch 678/1583] [D loss: 0.566175] [G loss: 0.208129]\n",
            "[Epoch 0/2] [Batch 679/1583] [D loss: 0.568993] [G loss: 0.216413]\n",
            "[Epoch 0/2] [Batch 680/1583] [D loss: 0.580726] [G loss: 0.223170]\n",
            "[Epoch 0/2] [Batch 681/1583] [D loss: 0.562752] [G loss: 0.225040]\n",
            "[Epoch 0/2] [Batch 682/1583] [D loss: 0.570856] [G loss: 0.225862]\n",
            "[Epoch 0/2] [Batch 683/1583] [D loss: 0.622247] [G loss: 0.225649]\n",
            "[Epoch 0/2] [Batch 684/1583] [D loss: 0.613672] [G loss: 0.218793]\n",
            "[Epoch 0/2] [Batch 685/1583] [D loss: 0.561349] [G loss: 0.219009]\n",
            "[Epoch 0/2] [Batch 686/1583] [D loss: 0.613087] [G loss: 0.221176]\n",
            "[Epoch 0/2] [Batch 687/1583] [D loss: 0.577738] [G loss: 0.206440]\n",
            "[Epoch 0/2] [Batch 688/1583] [D loss: 0.584834] [G loss: 0.216924]\n",
            "[Epoch 0/2] [Batch 689/1583] [D loss: 0.552963] [G loss: 0.219849]\n",
            "[Epoch 0/2] [Batch 690/1583] [D loss: 0.609757] [G loss: 0.221652]\n",
            "[Epoch 0/2] [Batch 691/1583] [D loss: 0.582226] [G loss: 0.215446]\n",
            "[Epoch 0/2] [Batch 692/1583] [D loss: 0.586061] [G loss: 0.211089]\n",
            "[Epoch 0/2] [Batch 693/1583] [D loss: 0.584955] [G loss: 0.213500]\n",
            "[Epoch 0/2] [Batch 694/1583] [D loss: 0.598964] [G loss: 0.210948]\n",
            "[Epoch 0/2] [Batch 695/1583] [D loss: 0.554634] [G loss: 0.212364]\n",
            "[Epoch 0/2] [Batch 696/1583] [D loss: 0.588612] [G loss: 0.220963]\n",
            "[Epoch 0/2] [Batch 697/1583] [D loss: 0.591027] [G loss: 0.204181]\n",
            "[Epoch 0/2] [Batch 698/1583] [D loss: 0.574835] [G loss: 0.216703]\n",
            "[Epoch 0/2] [Batch 699/1583] [D loss: 0.595604] [G loss: 0.219712]\n",
            "[Epoch 0/2] [Batch 700/1583] [D loss: 0.585224] [G loss: 0.219526]\n",
            "[Epoch 0/2] [Batch 701/1583] [D loss: 0.573160] [G loss: 0.221133]\n",
            "[Epoch 0/2] [Batch 702/1583] [D loss: 0.583344] [G loss: 0.224191]\n",
            "[Epoch 0/2] [Batch 703/1583] [D loss: 0.593894] [G loss: 0.223109]\n",
            "[Epoch 0/2] [Batch 704/1583] [D loss: 0.601322] [G loss: 0.225933]\n",
            "[Epoch 0/2] [Batch 705/1583] [D loss: 0.541814] [G loss: 0.231673]\n",
            "[Epoch 0/2] [Batch 706/1583] [D loss: 0.596134] [G loss: 0.210955]\n",
            "[Epoch 0/2] [Batch 707/1583] [D loss: 0.549183] [G loss: 0.223217]\n",
            "[Epoch 0/2] [Batch 708/1583] [D loss: 0.585000] [G loss: 0.220801]\n",
            "[Epoch 0/2] [Batch 709/1583] [D loss: 0.577761] [G loss: 0.214120]\n",
            "[Epoch 0/2] [Batch 710/1583] [D loss: 0.596007] [G loss: 0.223502]\n",
            "[Epoch 0/2] [Batch 711/1583] [D loss: 0.559587] [G loss: 0.214103]\n",
            "[Epoch 0/2] [Batch 712/1583] [D loss: 0.558542] [G loss: 0.216278]\n",
            "[Epoch 0/2] [Batch 713/1583] [D loss: 0.567155] [G loss: 0.224564]\n",
            "[Epoch 0/2] [Batch 714/1583] [D loss: 0.571762] [G loss: 0.215600]\n",
            "[Epoch 0/2] [Batch 715/1583] [D loss: 0.606664] [G loss: 0.215333]\n",
            "[Epoch 0/2] [Batch 716/1583] [D loss: 0.594800] [G loss: 0.219834]\n",
            "[Epoch 0/2] [Batch 717/1583] [D loss: 0.582327] [G loss: 0.220414]\n",
            "[Epoch 0/2] [Batch 718/1583] [D loss: 0.580141] [G loss: 0.223461]\n",
            "[Epoch 0/2] [Batch 719/1583] [D loss: 0.558456] [G loss: 0.216648]\n",
            "[Epoch 0/2] [Batch 720/1583] [D loss: 0.603728] [G loss: 0.216967]\n",
            "[Epoch 0/2] [Batch 721/1583] [D loss: 0.606967] [G loss: 0.216688]\n",
            "[Epoch 0/2] [Batch 722/1583] [D loss: 0.588704] [G loss: 0.211019]\n",
            "[Epoch 0/2] [Batch 723/1583] [D loss: 0.599676] [G loss: 0.216666]\n",
            "[Epoch 0/2] [Batch 724/1583] [D loss: 0.591106] [G loss: 0.218042]\n",
            "[Epoch 0/2] [Batch 725/1583] [D loss: 0.617005] [G loss: 0.220281]\n",
            "[Epoch 0/2] [Batch 726/1583] [D loss: 0.591795] [G loss: 0.224576]\n",
            "[Epoch 0/2] [Batch 727/1583] [D loss: 0.574288] [G loss: 0.214064]\n",
            "[Epoch 0/2] [Batch 728/1583] [D loss: 0.573740] [G loss: 0.210320]\n",
            "[Epoch 0/2] [Batch 729/1583] [D loss: 0.584041] [G loss: 0.220391]\n",
            "[Epoch 0/2] [Batch 730/1583] [D loss: 0.592434] [G loss: 0.220401]\n",
            "[Epoch 0/2] [Batch 731/1583] [D loss: 0.618241] [G loss: 0.220718]\n",
            "[Epoch 0/2] [Batch 732/1583] [D loss: 0.588163] [G loss: 0.219008]\n",
            "[Epoch 0/2] [Batch 733/1583] [D loss: 0.566131] [G loss: 0.205878]\n",
            "[Epoch 0/2] [Batch 734/1583] [D loss: 0.572937] [G loss: 0.221212]\n",
            "[Epoch 0/2] [Batch 735/1583] [D loss: 0.573673] [G loss: 0.231252]\n",
            "[Epoch 0/2] [Batch 736/1583] [D loss: 0.553862] [G loss: 0.213888]\n",
            "[Epoch 0/2] [Batch 737/1583] [D loss: 0.625540] [G loss: 0.219526]\n",
            "[Epoch 0/2] [Batch 738/1583] [D loss: 0.584056] [G loss: 0.217873]\n",
            "[Epoch 0/2] [Batch 739/1583] [D loss: 0.599372] [G loss: 0.221462]\n",
            "[Epoch 0/2] [Batch 740/1583] [D loss: 0.626822] [G loss: 0.201839]\n",
            "[Epoch 0/2] [Batch 741/1583] [D loss: 0.590259] [G loss: 0.217657]\n",
            "[Epoch 0/2] [Batch 742/1583] [D loss: 0.593853] [G loss: 0.227795]\n",
            "[Epoch 0/2] [Batch 743/1583] [D loss: 0.600148] [G loss: 0.219960]\n",
            "[Epoch 0/2] [Batch 744/1583] [D loss: 0.629154] [G loss: 0.217982]\n",
            "[Epoch 0/2] [Batch 745/1583] [D loss: 0.586260] [G loss: 0.203808]\n",
            "[Epoch 0/2] [Batch 746/1583] [D loss: 0.585615] [G loss: 0.214116]\n",
            "[Epoch 0/2] [Batch 747/1583] [D loss: 0.554083] [G loss: 0.218983]\n",
            "[Epoch 0/2] [Batch 748/1583] [D loss: 0.604691] [G loss: 0.212792]\n",
            "[Epoch 0/2] [Batch 749/1583] [D loss: 0.573973] [G loss: 0.204427]\n",
            "[Epoch 0/2] [Batch 750/1583] [D loss: 0.551246] [G loss: 0.218304]\n",
            "[Epoch 0/2] [Batch 751/1583] [D loss: 0.607224] [G loss: 0.223882]\n",
            "[Epoch 0/2] [Batch 752/1583] [D loss: 0.570038] [G loss: 0.221987]\n",
            "[Epoch 0/2] [Batch 753/1583] [D loss: 0.561049] [G loss: 0.217075]\n",
            "[Epoch 0/2] [Batch 754/1583] [D loss: 0.542406] [G loss: 0.203890]\n",
            "[Epoch 0/2] [Batch 755/1583] [D loss: 0.594315] [G loss: 0.215736]\n",
            "[Epoch 0/2] [Batch 756/1583] [D loss: 0.582785] [G loss: 0.220458]\n",
            "[Epoch 0/2] [Batch 757/1583] [D loss: 0.576601] [G loss: 0.226551]\n",
            "[Epoch 0/2] [Batch 758/1583] [D loss: 0.644207] [G loss: 0.221917]\n",
            "[Epoch 0/2] [Batch 759/1583] [D loss: 0.588020] [G loss: 0.216336]\n",
            "[Epoch 0/2] [Batch 760/1583] [D loss: 0.582716] [G loss: 0.215011]\n",
            "[Epoch 0/2] [Batch 761/1583] [D loss: 0.592317] [G loss: 0.217727]\n",
            "[Epoch 0/2] [Batch 762/1583] [D loss: 0.585777] [G loss: 0.217918]\n",
            "[Epoch 0/2] [Batch 763/1583] [D loss: 0.588338] [G loss: 0.210184]\n",
            "[Epoch 0/2] [Batch 764/1583] [D loss: 0.586547] [G loss: 0.212033]\n",
            "[Epoch 0/2] [Batch 765/1583] [D loss: 0.621286] [G loss: 0.222287]\n",
            "[Epoch 0/2] [Batch 766/1583] [D loss: 0.584015] [G loss: 0.222915]\n",
            "[Epoch 0/2] [Batch 767/1583] [D loss: 0.578172] [G loss: 0.222747]\n",
            "[Epoch 0/2] [Batch 768/1583] [D loss: 0.616583] [G loss: 0.220630]\n",
            "[Epoch 0/2] [Batch 769/1583] [D loss: 0.620469] [G loss: 0.218707]\n",
            "[Epoch 0/2] [Batch 770/1583] [D loss: 0.604572] [G loss: 0.217535]\n",
            "[Epoch 0/2] [Batch 771/1583] [D loss: 0.577427] [G loss: 0.219665]\n",
            "[Epoch 0/2] [Batch 772/1583] [D loss: 0.582383] [G loss: 0.215239]\n",
            "[Epoch 0/2] [Batch 773/1583] [D loss: 0.583967] [G loss: 0.224017]\n",
            "[Epoch 0/2] [Batch 774/1583] [D loss: 0.594409] [G loss: 0.219839]\n",
            "[Epoch 0/2] [Batch 775/1583] [D loss: 0.564256] [G loss: 0.213749]\n",
            "[Epoch 0/2] [Batch 776/1583] [D loss: 0.610037] [G loss: 0.218485]\n",
            "[Epoch 0/2] [Batch 777/1583] [D loss: 0.584943] [G loss: 0.227824]\n",
            "[Epoch 0/2] [Batch 778/1583] [D loss: 0.586946] [G loss: 0.212177]\n",
            "[Epoch 0/2] [Batch 779/1583] [D loss: 0.586892] [G loss: 0.217888]\n",
            "[Epoch 0/2] [Batch 780/1583] [D loss: 0.579505] [G loss: 0.218323]\n",
            "[Epoch 0/2] [Batch 781/1583] [D loss: 0.585841] [G loss: 0.208713]\n",
            "[Epoch 0/2] [Batch 782/1583] [D loss: 0.580569] [G loss: 0.221953]\n",
            "[Epoch 0/2] [Batch 783/1583] [D loss: 0.602536] [G loss: 0.227196]\n",
            "[Epoch 0/2] [Batch 784/1583] [D loss: 0.562628] [G loss: 0.223446]\n",
            "[Epoch 0/2] [Batch 785/1583] [D loss: 0.599275] [G loss: 0.212844]\n",
            "[Epoch 0/2] [Batch 786/1583] [D loss: 0.585573] [G loss: 0.222940]\n",
            "[Epoch 0/2] [Batch 787/1583] [D loss: 0.586589] [G loss: 0.221801]\n",
            "[Epoch 0/2] [Batch 788/1583] [D loss: 0.633878] [G loss: 0.221259]\n",
            "[Epoch 0/2] [Batch 789/1583] [D loss: 0.588375] [G loss: 0.222281]\n",
            "[Epoch 0/2] [Batch 790/1583] [D loss: 0.558446] [G loss: 0.214204]\n",
            "[Epoch 0/2] [Batch 791/1583] [D loss: 0.566104] [G loss: 0.221613]\n",
            "[Epoch 0/2] [Batch 792/1583] [D loss: 0.575810] [G loss: 0.225360]\n",
            "[Epoch 0/2] [Batch 793/1583] [D loss: 0.571453] [G loss: 0.223418]\n",
            "[Epoch 0/2] [Batch 794/1583] [D loss: 0.576652] [G loss: 0.226585]\n",
            "[Epoch 0/2] [Batch 795/1583] [D loss: 0.604842] [G loss: 0.226077]\n",
            "[Epoch 0/2] [Batch 796/1583] [D loss: 0.588083] [G loss: 0.211811]\n",
            "[Epoch 0/2] [Batch 797/1583] [D loss: 0.580470] [G loss: 0.217364]\n",
            "[Epoch 0/2] [Batch 798/1583] [D loss: 0.567948] [G loss: 0.222184]\n",
            "[Epoch 0/2] [Batch 799/1583] [D loss: 0.590051] [G loss: 0.210343]\n",
            "[Epoch 0/2] [Batch 800/1583] [D loss: 0.586833] [G loss: 0.218848]\n",
            "[Epoch 0/2] [Batch 801/1583] [D loss: 0.562908] [G loss: 0.212579]\n",
            "[Epoch 0/2] [Batch 802/1583] [D loss: 0.567206] [G loss: 0.211289]\n",
            "[Epoch 0/2] [Batch 803/1583] [D loss: 0.606332] [G loss: 0.220793]\n",
            "[Epoch 0/2] [Batch 804/1583] [D loss: 0.601067] [G loss: 0.212326]\n",
            "[Epoch 0/2] [Batch 805/1583] [D loss: 0.562474] [G loss: 0.215687]\n",
            "[Epoch 0/2] [Batch 806/1583] [D loss: 0.583939] [G loss: 0.217152]\n",
            "[Epoch 0/2] [Batch 807/1583] [D loss: 0.573808] [G loss: 0.212499]\n",
            "[Epoch 0/2] [Batch 808/1583] [D loss: 0.576690] [G loss: 0.219243]\n",
            "[Epoch 0/2] [Batch 809/1583] [D loss: 0.577826] [G loss: 0.220686]\n",
            "[Epoch 0/2] [Batch 810/1583] [D loss: 0.568181] [G loss: 0.217406]\n",
            "[Epoch 0/2] [Batch 811/1583] [D loss: 0.562867] [G loss: 0.218347]\n",
            "[Epoch 0/2] [Batch 812/1583] [D loss: 0.584816] [G loss: 0.220025]\n",
            "[Epoch 0/2] [Batch 813/1583] [D loss: 0.596156] [G loss: 0.214584]\n",
            "[Epoch 0/2] [Batch 814/1583] [D loss: 0.607645] [G loss: 0.220000]\n",
            "[Epoch 0/2] [Batch 815/1583] [D loss: 0.568555] [G loss: 0.215248]\n",
            "[Epoch 0/2] [Batch 816/1583] [D loss: 0.612781] [G loss: 0.225231]\n",
            "[Epoch 0/2] [Batch 817/1583] [D loss: 0.566768] [G loss: 0.213352]\n",
            "[Epoch 0/2] [Batch 818/1583] [D loss: 0.525136] [G loss: 0.201967]\n",
            "[Epoch 0/2] [Batch 819/1583] [D loss: 0.568239] [G loss: 0.223220]\n",
            "[Epoch 0/2] [Batch 820/1583] [D loss: 0.579700] [G loss: 0.218574]\n",
            "[Epoch 0/2] [Batch 821/1583] [D loss: 0.551809] [G loss: 0.210347]\n",
            "[Epoch 0/2] [Batch 822/1583] [D loss: 0.560407] [G loss: 0.213387]\n",
            "[Epoch 0/2] [Batch 823/1583] [D loss: 0.579124] [G loss: 0.219082]\n",
            "[Epoch 0/2] [Batch 824/1583] [D loss: 0.562876] [G loss: 0.205017]\n",
            "[Epoch 0/2] [Batch 825/1583] [D loss: 0.560394] [G loss: 0.213535]\n",
            "[Epoch 0/2] [Batch 826/1583] [D loss: 0.586668] [G loss: 0.221217]\n",
            "[Epoch 0/2] [Batch 827/1583] [D loss: 0.552850] [G loss: 0.214351]\n",
            "[Epoch 0/2] [Batch 828/1583] [D loss: 0.549878] [G loss: 0.208802]\n",
            "[Epoch 0/2] [Batch 829/1583] [D loss: 0.597690] [G loss: 0.224096]\n",
            "[Epoch 0/2] [Batch 830/1583] [D loss: 0.571231] [G loss: 0.209332]\n",
            "[Epoch 0/2] [Batch 831/1583] [D loss: 0.555816] [G loss: 0.207156]\n",
            "[Epoch 0/2] [Batch 832/1583] [D loss: 0.575827] [G loss: 0.206397]\n",
            "[Epoch 0/2] [Batch 833/1583] [D loss: 0.575086] [G loss: 0.216403]\n",
            "[Epoch 0/2] [Batch 834/1583] [D loss: 0.561786] [G loss: 0.219191]\n",
            "[Epoch 0/2] [Batch 835/1583] [D loss: 0.569507] [G loss: 0.209876]\n",
            "[Epoch 0/2] [Batch 836/1583] [D loss: 0.623263] [G loss: 0.220268]\n",
            "[Epoch 0/2] [Batch 837/1583] [D loss: 0.589614] [G loss: 0.225412]\n",
            "[Epoch 0/2] [Batch 838/1583] [D loss: 0.561020] [G loss: 0.215894]\n",
            "[Epoch 0/2] [Batch 839/1583] [D loss: 0.582679] [G loss: 0.214957]\n",
            "[Epoch 0/2] [Batch 840/1583] [D loss: 0.603723] [G loss: 0.220494]\n",
            "[Epoch 0/2] [Batch 841/1583] [D loss: 0.610665] [G loss: 0.214500]\n",
            "[Epoch 0/2] [Batch 842/1583] [D loss: 0.587483] [G loss: 0.215403]\n",
            "[Epoch 0/2] [Batch 843/1583] [D loss: 0.588005] [G loss: 0.213307]\n",
            "[Epoch 0/2] [Batch 844/1583] [D loss: 0.585900] [G loss: 0.216584]\n",
            "[Epoch 0/2] [Batch 845/1583] [D loss: 0.589334] [G loss: 0.219415]\n",
            "[Epoch 0/2] [Batch 846/1583] [D loss: 0.579264] [G loss: 0.211396]\n",
            "[Epoch 0/2] [Batch 847/1583] [D loss: 0.586636] [G loss: 0.212662]\n",
            "[Epoch 0/2] [Batch 848/1583] [D loss: 0.610272] [G loss: 0.212631]\n",
            "[Epoch 0/2] [Batch 849/1583] [D loss: 0.575046] [G loss: 0.214189]\n",
            "[Epoch 0/2] [Batch 850/1583] [D loss: 0.607739] [G loss: 0.221741]\n",
            "[Epoch 0/2] [Batch 851/1583] [D loss: 0.585306] [G loss: 0.209717]\n",
            "[Epoch 0/2] [Batch 852/1583] [D loss: 0.549439] [G loss: 0.216909]\n",
            "[Epoch 0/2] [Batch 853/1583] [D loss: 0.565878] [G loss: 0.221955]\n",
            "[Epoch 0/2] [Batch 854/1583] [D loss: 0.610355] [G loss: 0.215307]\n",
            "[Epoch 0/2] [Batch 855/1583] [D loss: 0.559575] [G loss: 0.222832]\n",
            "[Epoch 0/2] [Batch 856/1583] [D loss: 0.569313] [G loss: 0.223958]\n",
            "[Epoch 0/2] [Batch 857/1583] [D loss: 0.574483] [G loss: 0.218647]\n",
            "[Epoch 0/2] [Batch 858/1583] [D loss: 0.571598] [G loss: 0.228420]\n",
            "[Epoch 0/2] [Batch 859/1583] [D loss: 0.582290] [G loss: 0.213913]\n",
            "[Epoch 0/2] [Batch 860/1583] [D loss: 0.586484] [G loss: 0.228110]\n",
            "[Epoch 0/2] [Batch 861/1583] [D loss: 0.574096] [G loss: 0.218983]\n",
            "[Epoch 0/2] [Batch 862/1583] [D loss: 0.600463] [G loss: 0.217479]\n",
            "[Epoch 0/2] [Batch 863/1583] [D loss: 0.594926] [G loss: 0.214440]\n",
            "[Epoch 0/2] [Batch 864/1583] [D loss: 0.609375] [G loss: 0.216992]\n",
            "[Epoch 0/2] [Batch 865/1583] [D loss: 0.577010] [G loss: 0.218299]\n",
            "[Epoch 0/2] [Batch 866/1583] [D loss: 0.608543] [G loss: 0.221162]\n",
            "[Epoch 0/2] [Batch 867/1583] [D loss: 0.572630] [G loss: 0.219757]\n",
            "[Epoch 0/2] [Batch 868/1583] [D loss: 0.573130] [G loss: 0.213899]\n",
            "[Epoch 0/2] [Batch 869/1583] [D loss: 0.585189] [G loss: 0.227219]\n",
            "[Epoch 0/2] [Batch 870/1583] [D loss: 0.589022] [G loss: 0.224641]\n",
            "[Epoch 0/2] [Batch 871/1583] [D loss: 0.565259] [G loss: 0.215047]\n",
            "[Epoch 0/2] [Batch 872/1583] [D loss: 0.613200] [G loss: 0.212975]\n",
            "[Epoch 0/2] [Batch 873/1583] [D loss: 0.604023] [G loss: 0.209657]\n",
            "[Epoch 0/2] [Batch 874/1583] [D loss: 0.594671] [G loss: 0.227059]\n",
            "[Epoch 0/2] [Batch 875/1583] [D loss: 0.585671] [G loss: 0.213230]\n",
            "[Epoch 0/2] [Batch 876/1583] [D loss: 0.557815] [G loss: 0.213478]\n",
            "[Epoch 0/2] [Batch 877/1583] [D loss: 0.591998] [G loss: 0.217858]\n",
            "[Epoch 0/2] [Batch 878/1583] [D loss: 0.571823] [G loss: 0.215688]\n",
            "[Epoch 0/2] [Batch 879/1583] [D loss: 0.612323] [G loss: 0.211605]\n",
            "[Epoch 0/2] [Batch 880/1583] [D loss: 0.563312] [G loss: 0.210335]\n",
            "[Epoch 0/2] [Batch 881/1583] [D loss: 0.569617] [G loss: 0.228519]\n",
            "[Epoch 0/2] [Batch 882/1583] [D loss: 0.578890] [G loss: 0.211339]\n",
            "[Epoch 0/2] [Batch 883/1583] [D loss: 0.589398] [G loss: 0.208504]\n",
            "[Epoch 0/2] [Batch 884/1583] [D loss: 0.554523] [G loss: 0.216968]\n",
            "[Epoch 0/2] [Batch 885/1583] [D loss: 0.571112] [G loss: 0.217285]\n",
            "[Epoch 0/2] [Batch 886/1583] [D loss: 0.582715] [G loss: 0.219340]\n",
            "[Epoch 0/2] [Batch 887/1583] [D loss: 0.551092] [G loss: 0.214653]\n",
            "[Epoch 0/2] [Batch 888/1583] [D loss: 0.572967] [G loss: 0.214449]\n",
            "[Epoch 0/2] [Batch 889/1583] [D loss: 0.584473] [G loss: 0.218524]\n",
            "[Epoch 0/2] [Batch 890/1583] [D loss: 0.551073] [G loss: 0.213453]\n",
            "[Epoch 0/2] [Batch 891/1583] [D loss: 0.585222] [G loss: 0.214547]\n",
            "[Epoch 0/2] [Batch 892/1583] [D loss: 0.574987] [G loss: 0.235994]\n",
            "[Epoch 0/2] [Batch 893/1583] [D loss: 0.566943] [G loss: 0.216643]\n",
            "[Epoch 0/2] [Batch 894/1583] [D loss: 0.580305] [G loss: 0.218006]\n",
            "[Epoch 0/2] [Batch 895/1583] [D loss: 0.592113] [G loss: 0.218494]\n",
            "[Epoch 0/2] [Batch 896/1583] [D loss: 0.565431] [G loss: 0.221318]\n",
            "[Epoch 0/2] [Batch 897/1583] [D loss: 0.566566] [G loss: 0.211552]\n",
            "[Epoch 0/2] [Batch 898/1583] [D loss: 0.605055] [G loss: 0.221935]\n",
            "[Epoch 0/2] [Batch 899/1583] [D loss: 0.545806] [G loss: 0.214413]\n",
            "[Epoch 0/2] [Batch 900/1583] [D loss: 0.591602] [G loss: 0.216821]\n",
            "[Epoch 0/2] [Batch 901/1583] [D loss: 0.594172] [G loss: 0.216707]\n",
            "[Epoch 0/2] [Batch 902/1583] [D loss: 0.547507] [G loss: 0.213545]\n",
            "[Epoch 0/2] [Batch 903/1583] [D loss: 0.575597] [G loss: 0.226726]\n",
            "[Epoch 0/2] [Batch 904/1583] [D loss: 0.553348] [G loss: 0.217986]\n",
            "[Epoch 0/2] [Batch 905/1583] [D loss: 0.587785] [G loss: 0.224832]\n",
            "[Epoch 0/2] [Batch 906/1583] [D loss: 0.560120] [G loss: 0.222688]\n",
            "[Epoch 0/2] [Batch 907/1583] [D loss: 0.604325] [G loss: 0.214820]\n",
            "[Epoch 0/2] [Batch 908/1583] [D loss: 0.562148] [G loss: 0.212133]\n",
            "[Epoch 0/2] [Batch 909/1583] [D loss: 0.583971] [G loss: 0.212476]\n",
            "[Epoch 0/2] [Batch 910/1583] [D loss: 0.582762] [G loss: 0.233474]\n",
            "[Epoch 0/2] [Batch 911/1583] [D loss: 0.573622] [G loss: 0.210876]\n",
            "[Epoch 0/2] [Batch 912/1583] [D loss: 0.619951] [G loss: 0.222312]\n",
            "[Epoch 0/2] [Batch 913/1583] [D loss: 0.602643] [G loss: 0.217727]\n",
            "[Epoch 0/2] [Batch 914/1583] [D loss: 0.598097] [G loss: 0.218238]\n",
            "[Epoch 0/2] [Batch 915/1583] [D loss: 0.586125] [G loss: 0.220342]\n",
            "[Epoch 0/2] [Batch 916/1583] [D loss: 0.599698] [G loss: 0.221215]\n",
            "[Epoch 0/2] [Batch 917/1583] [D loss: 0.582475] [G loss: 0.213086]\n",
            "[Epoch 0/2] [Batch 918/1583] [D loss: 0.557539] [G loss: 0.219549]\n",
            "[Epoch 0/2] [Batch 919/1583] [D loss: 0.565746] [G loss: 0.212434]\n",
            "[Epoch 0/2] [Batch 920/1583] [D loss: 0.543544] [G loss: 0.214859]\n",
            "[Epoch 0/2] [Batch 921/1583] [D loss: 0.563902] [G loss: 0.219858]\n",
            "[Epoch 0/2] [Batch 922/1583] [D loss: 0.617390] [G loss: 0.218109]\n",
            "[Epoch 0/2] [Batch 923/1583] [D loss: 0.604602] [G loss: 0.217436]\n",
            "[Epoch 0/2] [Batch 924/1583] [D loss: 0.607877] [G loss: 0.207483]\n",
            "[Epoch 0/2] [Batch 925/1583] [D loss: 0.593655] [G loss: 0.218968]\n",
            "[Epoch 0/2] [Batch 926/1583] [D loss: 0.603340] [G loss: 0.225209]\n",
            "[Epoch 0/2] [Batch 927/1583] [D loss: 0.596379] [G loss: 0.215116]\n",
            "[Epoch 0/2] [Batch 928/1583] [D loss: 0.591136] [G loss: 0.214186]\n",
            "[Epoch 0/2] [Batch 929/1583] [D loss: 0.603647] [G loss: 0.221549]\n",
            "[Epoch 0/2] [Batch 930/1583] [D loss: 0.546300] [G loss: 0.217166]\n",
            "[Epoch 0/2] [Batch 931/1583] [D loss: 0.562377] [G loss: 0.216558]\n",
            "[Epoch 0/2] [Batch 932/1583] [D loss: 0.575886] [G loss: 0.216785]\n",
            "[Epoch 0/2] [Batch 933/1583] [D loss: 0.580244] [G loss: 0.216946]\n",
            "[Epoch 0/2] [Batch 934/1583] [D loss: 0.601864] [G loss: 0.215891]\n",
            "[Epoch 0/2] [Batch 935/1583] [D loss: 0.563349] [G loss: 0.215066]\n",
            "[Epoch 0/2] [Batch 936/1583] [D loss: 0.548832] [G loss: 0.228627]\n",
            "[Epoch 0/2] [Batch 937/1583] [D loss: 0.587483] [G loss: 0.221464]\n",
            "[Epoch 0/2] [Batch 938/1583] [D loss: 0.581017] [G loss: 0.210892]\n",
            "[Epoch 0/2] [Batch 939/1583] [D loss: 0.577540] [G loss: 0.221258]\n",
            "[Epoch 0/2] [Batch 940/1583] [D loss: 0.558374] [G loss: 0.218414]\n",
            "[Epoch 0/2] [Batch 941/1583] [D loss: 0.590992] [G loss: 0.216171]\n",
            "[Epoch 0/2] [Batch 942/1583] [D loss: 0.628270] [G loss: 0.217019]\n",
            "[Epoch 0/2] [Batch 943/1583] [D loss: 0.550546] [G loss: 0.213362]\n",
            "[Epoch 0/2] [Batch 944/1583] [D loss: 0.605779] [G loss: 0.210908]\n",
            "[Epoch 0/2] [Batch 945/1583] [D loss: 0.569377] [G loss: 0.218629]\n",
            "[Epoch 0/2] [Batch 946/1583] [D loss: 0.572479] [G loss: 0.221793]\n",
            "[Epoch 0/2] [Batch 947/1583] [D loss: 0.584010] [G loss: 0.223615]\n",
            "[Epoch 0/2] [Batch 948/1583] [D loss: 0.576781] [G loss: 0.208335]\n",
            "[Epoch 0/2] [Batch 949/1583] [D loss: 0.619332] [G loss: 0.213157]\n",
            "[Epoch 0/2] [Batch 950/1583] [D loss: 0.579057] [G loss: 0.213803]\n",
            "[Epoch 0/2] [Batch 951/1583] [D loss: 0.559037] [G loss: 0.221087]\n",
            "[Epoch 0/2] [Batch 952/1583] [D loss: 0.609832] [G loss: 0.227275]\n",
            "[Epoch 0/2] [Batch 953/1583] [D loss: 0.594053] [G loss: 0.210518]\n",
            "[Epoch 0/2] [Batch 954/1583] [D loss: 0.580441] [G loss: 0.221922]\n",
            "[Epoch 0/2] [Batch 955/1583] [D loss: 0.562884] [G loss: 0.215990]\n",
            "[Epoch 0/2] [Batch 956/1583] [D loss: 0.584939] [G loss: 0.216960]\n",
            "[Epoch 0/2] [Batch 957/1583] [D loss: 0.599254] [G loss: 0.212938]\n",
            "[Epoch 0/2] [Batch 958/1583] [D loss: 0.567633] [G loss: 0.220095]\n",
            "[Epoch 0/2] [Batch 959/1583] [D loss: 0.622275] [G loss: 0.217918]\n",
            "[Epoch 0/2] [Batch 960/1583] [D loss: 0.607052] [G loss: 0.217302]\n",
            "[Epoch 0/2] [Batch 961/1583] [D loss: 0.561319] [G loss: 0.216968]\n",
            "[Epoch 0/2] [Batch 962/1583] [D loss: 0.567214] [G loss: 0.213548]\n",
            "[Epoch 0/2] [Batch 963/1583] [D loss: 0.565161] [G loss: 0.213183]\n",
            "[Epoch 0/2] [Batch 964/1583] [D loss: 0.573466] [G loss: 0.209749]\n",
            "[Epoch 0/2] [Batch 965/1583] [D loss: 0.583061] [G loss: 0.215349]\n",
            "[Epoch 0/2] [Batch 966/1583] [D loss: 0.601818] [G loss: 0.219271]\n",
            "[Epoch 0/2] [Batch 967/1583] [D loss: 0.575417] [G loss: 0.212577]\n",
            "[Epoch 0/2] [Batch 968/1583] [D loss: 0.550847] [G loss: 0.215446]\n",
            "[Epoch 0/2] [Batch 969/1583] [D loss: 0.587554] [G loss: 0.210619]\n",
            "[Epoch 0/2] [Batch 970/1583] [D loss: 0.587880] [G loss: 0.224145]\n",
            "[Epoch 0/2] [Batch 971/1583] [D loss: 0.617737] [G loss: 0.214740]\n",
            "[Epoch 0/2] [Batch 972/1583] [D loss: 0.618829] [G loss: 0.208683]\n",
            "[Epoch 0/2] [Batch 973/1583] [D loss: 0.597569] [G loss: 0.217249]\n",
            "[Epoch 0/2] [Batch 974/1583] [D loss: 0.565653] [G loss: 0.216201]\n",
            "[Epoch 0/2] [Batch 975/1583] [D loss: 0.571921] [G loss: 0.212557]\n",
            "[Epoch 0/2] [Batch 976/1583] [D loss: 0.542823] [G loss: 0.208964]\n",
            "[Epoch 0/2] [Batch 977/1583] [D loss: 0.615747] [G loss: 0.227892]\n",
            "[Epoch 0/2] [Batch 978/1583] [D loss: 0.591660] [G loss: 0.210090]\n",
            "[Epoch 0/2] [Batch 979/1583] [D loss: 0.565441] [G loss: 0.212246]\n",
            "[Epoch 0/2] [Batch 980/1583] [D loss: 0.569033] [G loss: 0.222664]\n",
            "[Epoch 0/2] [Batch 981/1583] [D loss: 0.566309] [G loss: 0.214677]\n",
            "[Epoch 0/2] [Batch 982/1583] [D loss: 0.545359] [G loss: 0.219091]\n",
            "[Epoch 0/2] [Batch 983/1583] [D loss: 0.592662] [G loss: 0.217455]\n",
            "[Epoch 0/2] [Batch 984/1583] [D loss: 0.593841] [G loss: 0.211598]\n",
            "[Epoch 0/2] [Batch 985/1583] [D loss: 0.560566] [G loss: 0.217922]\n",
            "[Epoch 0/2] [Batch 986/1583] [D loss: 0.564405] [G loss: 0.209102]\n",
            "[Epoch 0/2] [Batch 987/1583] [D loss: 0.572156] [G loss: 0.210689]\n",
            "[Epoch 0/2] [Batch 988/1583] [D loss: 0.580433] [G loss: 0.212580]\n",
            "[Epoch 0/2] [Batch 989/1583] [D loss: 0.577290] [G loss: 0.217381]\n",
            "[Epoch 0/2] [Batch 990/1583] [D loss: 0.570088] [G loss: 0.209327]\n",
            "[Epoch 0/2] [Batch 991/1583] [D loss: 0.570305] [G loss: 0.211188]\n",
            "[Epoch 0/2] [Batch 992/1583] [D loss: 0.554147] [G loss: 0.217586]\n",
            "[Epoch 0/2] [Batch 993/1583] [D loss: 0.610947] [G loss: 0.219723]\n",
            "[Epoch 0/2] [Batch 994/1583] [D loss: 0.605410] [G loss: 0.217771]\n",
            "[Epoch 0/2] [Batch 995/1583] [D loss: 0.602047] [G loss: 0.217290]\n",
            "[Epoch 0/2] [Batch 996/1583] [D loss: 0.612511] [G loss: 0.220109]\n",
            "[Epoch 0/2] [Batch 997/1583] [D loss: 0.580208] [G loss: 0.213687]\n",
            "[Epoch 0/2] [Batch 998/1583] [D loss: 0.590916] [G loss: 0.211540]\n",
            "[Epoch 0/2] [Batch 999/1583] [D loss: 0.594269] [G loss: 0.211113]\n",
            "[Epoch 0/2] [Batch 1000/1583] [D loss: 0.556633] [G loss: 0.216100]\n",
            "[Epoch 0/2] [Batch 1001/1583] [D loss: 0.593731] [G loss: 0.218028]\n",
            "[Epoch 0/2] [Batch 1002/1583] [D loss: 0.615506] [G loss: 0.222744]\n",
            "[Epoch 0/2] [Batch 1003/1583] [D loss: 0.606959] [G loss: 0.215049]\n",
            "[Epoch 0/2] [Batch 1004/1583] [D loss: 0.587222] [G loss: 0.208901]\n",
            "[Epoch 0/2] [Batch 1005/1583] [D loss: 0.576663] [G loss: 0.216758]\n",
            "[Epoch 0/2] [Batch 1006/1583] [D loss: 0.610934] [G loss: 0.224008]\n",
            "[Epoch 0/2] [Batch 1007/1583] [D loss: 0.582328] [G loss: 0.215106]\n",
            "[Epoch 0/2] [Batch 1008/1583] [D loss: 0.571256] [G loss: 0.221976]\n",
            "[Epoch 0/2] [Batch 1009/1583] [D loss: 0.574514] [G loss: 0.222001]\n",
            "[Epoch 0/2] [Batch 1010/1583] [D loss: 0.595998] [G loss: 0.214562]\n",
            "[Epoch 0/2] [Batch 1011/1583] [D loss: 0.598235] [G loss: 0.213870]\n",
            "[Epoch 0/2] [Batch 1012/1583] [D loss: 0.596767] [G loss: 0.217408]\n",
            "[Epoch 0/2] [Batch 1013/1583] [D loss: 0.602365] [G loss: 0.222449]\n",
            "[Epoch 0/2] [Batch 1014/1583] [D loss: 0.610778] [G loss: 0.214042]\n",
            "[Epoch 0/2] [Batch 1015/1583] [D loss: 0.597411] [G loss: 0.215040]\n",
            "[Epoch 0/2] [Batch 1016/1583] [D loss: 0.571869] [G loss: 0.210111]\n",
            "[Epoch 0/2] [Batch 1017/1583] [D loss: 0.560493] [G loss: 0.219201]\n",
            "[Epoch 0/2] [Batch 1018/1583] [D loss: 0.591676] [G loss: 0.219865]\n",
            "[Epoch 0/2] [Batch 1019/1583] [D loss: 0.593909] [G loss: 0.214551]\n",
            "[Epoch 0/2] [Batch 1020/1583] [D loss: 0.583935] [G loss: 0.211921]\n",
            "[Epoch 0/2] [Batch 1021/1583] [D loss: 0.568623] [G loss: 0.212422]\n",
            "[Epoch 0/2] [Batch 1022/1583] [D loss: 0.552974] [G loss: 0.213367]\n",
            "[Epoch 0/2] [Batch 1023/1583] [D loss: 0.570746] [G loss: 0.224961]\n",
            "[Epoch 0/2] [Batch 1024/1583] [D loss: 0.575438] [G loss: 0.217111]\n",
            "[Epoch 0/2] [Batch 1025/1583] [D loss: 0.570007] [G loss: 0.210104]\n",
            "[Epoch 0/2] [Batch 1026/1583] [D loss: 0.561396] [G loss: 0.214969]\n",
            "[Epoch 0/2] [Batch 1027/1583] [D loss: 0.588492] [G loss: 0.213213]\n",
            "[Epoch 0/2] [Batch 1028/1583] [D loss: 0.560880] [G loss: 0.218637]\n",
            "[Epoch 0/2] [Batch 1029/1583] [D loss: 0.606574] [G loss: 0.218144]\n",
            "[Epoch 0/2] [Batch 1030/1583] [D loss: 0.592069] [G loss: 0.208603]\n",
            "[Epoch 0/2] [Batch 1031/1583] [D loss: 0.572117] [G loss: 0.210046]\n",
            "[Epoch 0/2] [Batch 1032/1583] [D loss: 0.584862] [G loss: 0.222394]\n",
            "[Epoch 0/2] [Batch 1033/1583] [D loss: 0.594349] [G loss: 0.213180]\n",
            "[Epoch 0/2] [Batch 1034/1583] [D loss: 0.560982] [G loss: 0.204785]\n",
            "[Epoch 0/2] [Batch 1035/1583] [D loss: 0.535673] [G loss: 0.218837]\n",
            "[Epoch 0/2] [Batch 1036/1583] [D loss: 0.567624] [G loss: 0.215382]\n",
            "[Epoch 0/2] [Batch 1037/1583] [D loss: 0.598465] [G loss: 0.215495]\n",
            "[Epoch 0/2] [Batch 1038/1583] [D loss: 0.572954] [G loss: 0.215395]\n",
            "[Epoch 0/2] [Batch 1039/1583] [D loss: 0.568391] [G loss: 0.212057]\n",
            "[Epoch 0/2] [Batch 1040/1583] [D loss: 0.579561] [G loss: 0.216225]\n",
            "[Epoch 0/2] [Batch 1041/1583] [D loss: 0.576859] [G loss: 0.206359]\n",
            "[Epoch 0/2] [Batch 1042/1583] [D loss: 0.589085] [G loss: 0.207261]\n",
            "[Epoch 0/2] [Batch 1043/1583] [D loss: 0.619452] [G loss: 0.218153]\n",
            "[Epoch 0/2] [Batch 1044/1583] [D loss: 0.601874] [G loss: 0.209261]\n",
            "[Epoch 0/2] [Batch 1045/1583] [D loss: 0.608947] [G loss: 0.200834]\n",
            "[Epoch 0/2] [Batch 1046/1583] [D loss: 0.579178] [G loss: 0.216817]\n",
            "[Epoch 0/2] [Batch 1047/1583] [D loss: 0.567695] [G loss: 0.214184]\n",
            "[Epoch 0/2] [Batch 1048/1583] [D loss: 0.567967] [G loss: 0.204213]\n",
            "[Epoch 0/2] [Batch 1049/1583] [D loss: 0.562572] [G loss: 0.217749]\n",
            "[Epoch 0/2] [Batch 1050/1583] [D loss: 0.589215] [G loss: 0.215978]\n",
            "[Epoch 0/2] [Batch 1051/1583] [D loss: 0.602963] [G loss: 0.218103]\n",
            "[Epoch 0/2] [Batch 1052/1583] [D loss: 0.594911] [G loss: 0.226864]\n",
            "[Epoch 0/2] [Batch 1053/1583] [D loss: 0.612015] [G loss: 0.209984]\n",
            "[Epoch 0/2] [Batch 1054/1583] [D loss: 0.607681] [G loss: 0.216847]\n",
            "[Epoch 0/2] [Batch 1055/1583] [D loss: 0.598364] [G loss: 0.218023]\n",
            "[Epoch 0/2] [Batch 1056/1583] [D loss: 0.524811] [G loss: 0.215386]\n",
            "[Epoch 0/2] [Batch 1057/1583] [D loss: 0.583325] [G loss: 0.211536]\n",
            "[Epoch 0/2] [Batch 1058/1583] [D loss: 0.588383] [G loss: 0.212892]\n",
            "[Epoch 0/2] [Batch 1059/1583] [D loss: 0.571710] [G loss: 0.219420]\n",
            "[Epoch 0/2] [Batch 1060/1583] [D loss: 0.578036] [G loss: 0.215398]\n",
            "[Epoch 0/2] [Batch 1061/1583] [D loss: 0.575932] [G loss: 0.211822]\n",
            "[Epoch 0/2] [Batch 1062/1583] [D loss: 0.583504] [G loss: 0.211150]\n",
            "[Epoch 0/2] [Batch 1063/1583] [D loss: 0.570849] [G loss: 0.222032]\n",
            "[Epoch 0/2] [Batch 1064/1583] [D loss: 0.606307] [G loss: 0.215275]\n",
            "[Epoch 0/2] [Batch 1065/1583] [D loss: 0.574206] [G loss: 0.223525]\n",
            "[Epoch 0/2] [Batch 1066/1583] [D loss: 0.539568] [G loss: 0.207154]\n",
            "[Epoch 0/2] [Batch 1067/1583] [D loss: 0.552880] [G loss: 0.213974]\n",
            "[Epoch 0/2] [Batch 1068/1583] [D loss: 0.574408] [G loss: 0.218410]\n",
            "[Epoch 0/2] [Batch 1069/1583] [D loss: 0.561736] [G loss: 0.213711]\n",
            "[Epoch 0/2] [Batch 1070/1583] [D loss: 0.587295] [G loss: 0.217659]\n",
            "[Epoch 0/2] [Batch 1071/1583] [D loss: 0.570724] [G loss: 0.216700]\n",
            "[Epoch 0/2] [Batch 1072/1583] [D loss: 0.601619] [G loss: 0.214995]\n",
            "[Epoch 0/2] [Batch 1073/1583] [D loss: 0.579643] [G loss: 0.217865]\n",
            "[Epoch 0/2] [Batch 1074/1583] [D loss: 0.616253] [G loss: 0.219050]\n",
            "[Epoch 0/2] [Batch 1075/1583] [D loss: 0.586370] [G loss: 0.217761]\n",
            "[Epoch 0/2] [Batch 1076/1583] [D loss: 0.582108] [G loss: 0.216699]\n",
            "[Epoch 0/2] [Batch 1077/1583] [D loss: 0.586096] [G loss: 0.221236]\n",
            "[Epoch 0/2] [Batch 1078/1583] [D loss: 0.576789] [G loss: 0.215461]\n",
            "[Epoch 0/2] [Batch 1079/1583] [D loss: 0.606465] [G loss: 0.219896]\n",
            "[Epoch 0/2] [Batch 1080/1583] [D loss: 0.571853] [G loss: 0.223299]\n",
            "[Epoch 0/2] [Batch 1081/1583] [D loss: 0.570556] [G loss: 0.209439]\n",
            "[Epoch 0/2] [Batch 1082/1583] [D loss: 0.572153] [G loss: 0.217820]\n",
            "[Epoch 0/2] [Batch 1083/1583] [D loss: 0.574800] [G loss: 0.223651]\n",
            "[Epoch 0/2] [Batch 1084/1583] [D loss: 0.596306] [G loss: 0.227985]\n",
            "[Epoch 0/2] [Batch 1085/1583] [D loss: 0.569298] [G loss: 0.215714]\n",
            "[Epoch 0/2] [Batch 1086/1583] [D loss: 0.587003] [G loss: 0.220452]\n",
            "[Epoch 0/2] [Batch 1087/1583] [D loss: 0.615879] [G loss: 0.212047]\n",
            "[Epoch 0/2] [Batch 1088/1583] [D loss: 0.564642] [G loss: 0.217618]\n",
            "[Epoch 0/2] [Batch 1089/1583] [D loss: 0.566395] [G loss: 0.214600]\n",
            "[Epoch 0/2] [Batch 1090/1583] [D loss: 0.570097] [G loss: 0.213695]\n",
            "[Epoch 0/2] [Batch 1091/1583] [D loss: 0.577791] [G loss: 0.216979]\n",
            "[Epoch 0/2] [Batch 1092/1583] [D loss: 0.561749] [G loss: 0.209054]\n",
            "[Epoch 0/2] [Batch 1093/1583] [D loss: 0.579872] [G loss: 0.215162]\n",
            "[Epoch 0/2] [Batch 1094/1583] [D loss: 0.572508] [G loss: 0.215947]\n",
            "[Epoch 0/2] [Batch 1095/1583] [D loss: 0.600910] [G loss: 0.213931]\n",
            "[Epoch 0/2] [Batch 1096/1583] [D loss: 0.604012] [G loss: 0.218656]\n",
            "[Epoch 0/2] [Batch 1097/1583] [D loss: 0.576560] [G loss: 0.209132]\n",
            "[Epoch 0/2] [Batch 1098/1583] [D loss: 0.594808] [G loss: 0.217602]\n",
            "[Epoch 0/2] [Batch 1099/1583] [D loss: 0.590616] [G loss: 0.214907]\n",
            "[Epoch 0/2] [Batch 1100/1583] [D loss: 0.531997] [G loss: 0.208247]\n",
            "[Epoch 0/2] [Batch 1101/1583] [D loss: 0.578425] [G loss: 0.210827]\n",
            "[Epoch 0/2] [Batch 1102/1583] [D loss: 0.584919] [G loss: 0.222891]\n",
            "[Epoch 0/2] [Batch 1103/1583] [D loss: 0.577909] [G loss: 0.206833]\n",
            "[Epoch 0/2] [Batch 1104/1583] [D loss: 0.576595] [G loss: 0.219287]\n",
            "[Epoch 0/2] [Batch 1105/1583] [D loss: 0.560670] [G loss: 0.208870]\n",
            "[Epoch 0/2] [Batch 1106/1583] [D loss: 0.535524] [G loss: 0.217160]\n",
            "[Epoch 0/2] [Batch 1107/1583] [D loss: 0.571697] [G loss: 0.204740]\n",
            "[Epoch 0/2] [Batch 1108/1583] [D loss: 0.585067] [G loss: 0.226580]\n",
            "[Epoch 0/2] [Batch 1109/1583] [D loss: 0.573903] [G loss: 0.218920]\n",
            "[Epoch 0/2] [Batch 1110/1583] [D loss: 0.595361] [G loss: 0.214386]\n",
            "[Epoch 0/2] [Batch 1111/1583] [D loss: 0.592417] [G loss: 0.217938]\n",
            "[Epoch 0/2] [Batch 1112/1583] [D loss: 0.563388] [G loss: 0.214138]\n",
            "[Epoch 0/2] [Batch 1113/1583] [D loss: 0.601223] [G loss: 0.223128]\n",
            "[Epoch 0/2] [Batch 1114/1583] [D loss: 0.580565] [G loss: 0.213845]\n",
            "[Epoch 0/2] [Batch 1115/1583] [D loss: 0.580507] [G loss: 0.219672]\n",
            "[Epoch 0/2] [Batch 1116/1583] [D loss: 0.585811] [G loss: 0.210661]\n",
            "[Epoch 0/2] [Batch 1117/1583] [D loss: 0.593838] [G loss: 0.218703]\n",
            "[Epoch 0/2] [Batch 1118/1583] [D loss: 0.595730] [G loss: 0.217996]\n",
            "[Epoch 0/2] [Batch 1119/1583] [D loss: 0.580346] [G loss: 0.211892]\n",
            "[Epoch 0/2] [Batch 1120/1583] [D loss: 0.581571] [G loss: 0.217167]\n",
            "[Epoch 0/2] [Batch 1121/1583] [D loss: 0.560621] [G loss: 0.208369]\n",
            "[Epoch 0/2] [Batch 1122/1583] [D loss: 0.593852] [G loss: 0.215426]\n",
            "[Epoch 0/2] [Batch 1123/1583] [D loss: 0.604675] [G loss: 0.217390]\n",
            "[Epoch 0/2] [Batch 1124/1583] [D loss: 0.585629] [G loss: 0.208742]\n",
            "[Epoch 0/2] [Batch 1125/1583] [D loss: 0.609990] [G loss: 0.215018]\n",
            "[Epoch 0/2] [Batch 1126/1583] [D loss: 0.612718] [G loss: 0.221806]\n",
            "[Epoch 0/2] [Batch 1127/1583] [D loss: 0.572514] [G loss: 0.209954]\n",
            "[Epoch 0/2] [Batch 1128/1583] [D loss: 0.589013] [G loss: 0.208980]\n",
            "[Epoch 0/2] [Batch 1129/1583] [D loss: 0.597765] [G loss: 0.216712]\n",
            "[Epoch 0/2] [Batch 1130/1583] [D loss: 0.556567] [G loss: 0.212504]\n",
            "[Epoch 0/2] [Batch 1131/1583] [D loss: 0.552756] [G loss: 0.213257]\n",
            "[Epoch 0/2] [Batch 1132/1583] [D loss: 0.581387] [G loss: 0.221334]\n",
            "[Epoch 0/2] [Batch 1133/1583] [D loss: 0.573698] [G loss: 0.222105]\n",
            "[Epoch 0/2] [Batch 1134/1583] [D loss: 0.568668] [G loss: 0.220000]\n",
            "[Epoch 0/2] [Batch 1135/1583] [D loss: 0.587359] [G loss: 0.217606]\n",
            "[Epoch 0/2] [Batch 1136/1583] [D loss: 0.547326] [G loss: 0.213409]\n",
            "[Epoch 0/2] [Batch 1137/1583] [D loss: 0.582439] [G loss: 0.222125]\n",
            "[Epoch 0/2] [Batch 1138/1583] [D loss: 0.574673] [G loss: 0.214018]\n",
            "[Epoch 0/2] [Batch 1139/1583] [D loss: 0.545069] [G loss: 0.214293]\n",
            "[Epoch 0/2] [Batch 1140/1583] [D loss: 0.582864] [G loss: 0.213527]\n",
            "[Epoch 0/2] [Batch 1141/1583] [D loss: 0.593632] [G loss: 0.215891]\n",
            "[Epoch 0/2] [Batch 1142/1583] [D loss: 0.603350] [G loss: 0.218053]\n",
            "[Epoch 0/2] [Batch 1143/1583] [D loss: 0.569217] [G loss: 0.210393]\n",
            "[Epoch 0/2] [Batch 1144/1583] [D loss: 0.587350] [G loss: 0.216868]\n",
            "[Epoch 0/2] [Batch 1145/1583] [D loss: 0.582694] [G loss: 0.213947]\n",
            "[Epoch 0/2] [Batch 1146/1583] [D loss: 0.590409] [G loss: 0.214517]\n",
            "[Epoch 0/2] [Batch 1147/1583] [D loss: 0.566666] [G loss: 0.212049]\n",
            "[Epoch 0/2] [Batch 1148/1583] [D loss: 0.585416] [G loss: 0.221684]\n",
            "[Epoch 0/2] [Batch 1149/1583] [D loss: 0.579415] [G loss: 0.213584]\n",
            "[Epoch 0/2] [Batch 1150/1583] [D loss: 0.579983] [G loss: 0.210984]\n",
            "[Epoch 0/2] [Batch 1151/1583] [D loss: 0.583060] [G loss: 0.211588]\n",
            "[Epoch 0/2] [Batch 1152/1583] [D loss: 0.554435] [G loss: 0.209518]\n",
            "[Epoch 0/2] [Batch 1153/1583] [D loss: 0.584297] [G loss: 0.218030]\n",
            "[Epoch 0/2] [Batch 1154/1583] [D loss: 0.602070] [G loss: 0.214211]\n",
            "[Epoch 0/2] [Batch 1155/1583] [D loss: 0.589452] [G loss: 0.215928]\n",
            "[Epoch 0/2] [Batch 1156/1583] [D loss: 0.580290] [G loss: 0.215643]\n",
            "[Epoch 0/2] [Batch 1157/1583] [D loss: 0.564326] [G loss: 0.207670]\n",
            "[Epoch 0/2] [Batch 1158/1583] [D loss: 0.565947] [G loss: 0.212377]\n",
            "[Epoch 0/2] [Batch 1159/1583] [D loss: 0.561540] [G loss: 0.214767]\n",
            "[Epoch 0/2] [Batch 1160/1583] [D loss: 0.597029] [G loss: 0.220802]\n",
            "[Epoch 0/2] [Batch 1161/1583] [D loss: 0.616825] [G loss: 0.216106]\n",
            "[Epoch 0/2] [Batch 1162/1583] [D loss: 0.596569] [G loss: 0.208802]\n",
            "[Epoch 0/2] [Batch 1163/1583] [D loss: 0.585326] [G loss: 0.216327]\n",
            "[Epoch 0/2] [Batch 1164/1583] [D loss: 0.601485] [G loss: 0.216936]\n",
            "[Epoch 0/2] [Batch 1165/1583] [D loss: 0.572986] [G loss: 0.216458]\n",
            "[Epoch 0/2] [Batch 1166/1583] [D loss: 0.576966] [G loss: 0.217474]\n",
            "[Epoch 0/2] [Batch 1167/1583] [D loss: 0.562706] [G loss: 0.211888]\n",
            "[Epoch 0/2] [Batch 1168/1583] [D loss: 0.565611] [G loss: 0.211195]\n",
            "[Epoch 0/2] [Batch 1169/1583] [D loss: 0.603266] [G loss: 0.221574]\n",
            "[Epoch 0/2] [Batch 1170/1583] [D loss: 0.572975] [G loss: 0.218182]\n",
            "[Epoch 0/2] [Batch 1171/1583] [D loss: 0.578905] [G loss: 0.205946]\n",
            "[Epoch 0/2] [Batch 1172/1583] [D loss: 0.546064] [G loss: 0.211508]\n",
            "[Epoch 0/2] [Batch 1173/1583] [D loss: 0.579686] [G loss: 0.220920]\n",
            "[Epoch 0/2] [Batch 1174/1583] [D loss: 0.601757] [G loss: 0.211993]\n",
            "[Epoch 0/2] [Batch 1175/1583] [D loss: 0.520718] [G loss: 0.207089]\n",
            "[Epoch 0/2] [Batch 1176/1583] [D loss: 0.541216] [G loss: 0.205753]\n",
            "[Epoch 0/2] [Batch 1177/1583] [D loss: 0.568122] [G loss: 0.205581]\n",
            "[Epoch 0/2] [Batch 1178/1583] [D loss: 0.585752] [G loss: 0.219706]\n",
            "[Epoch 0/2] [Batch 1179/1583] [D loss: 0.588385] [G loss: 0.209844]\n",
            "[Epoch 0/2] [Batch 1180/1583] [D loss: 0.561469] [G loss: 0.210093]\n",
            "[Epoch 0/2] [Batch 1181/1583] [D loss: 0.601476] [G loss: 0.216483]\n",
            "[Epoch 0/2] [Batch 1182/1583] [D loss: 0.581502] [G loss: 0.216071]\n",
            "[Epoch 0/2] [Batch 1183/1583] [D loss: 0.580163] [G loss: 0.217054]\n",
            "[Epoch 0/2] [Batch 1184/1583] [D loss: 0.590388] [G loss: 0.217549]\n",
            "[Epoch 0/2] [Batch 1185/1583] [D loss: 0.571973] [G loss: 0.224729]\n",
            "[Epoch 0/2] [Batch 1186/1583] [D loss: 0.603443] [G loss: 0.219137]\n",
            "[Epoch 0/2] [Batch 1187/1583] [D loss: 0.581416] [G loss: 0.211709]\n",
            "[Epoch 0/2] [Batch 1188/1583] [D loss: 0.580666] [G loss: 0.211244]\n",
            "[Epoch 0/2] [Batch 1189/1583] [D loss: 0.546939] [G loss: 0.216039]\n",
            "[Epoch 0/2] [Batch 1190/1583] [D loss: 0.555087] [G loss: 0.214122]\n",
            "[Epoch 0/2] [Batch 1191/1583] [D loss: 0.562205] [G loss: 0.211528]\n",
            "[Epoch 0/2] [Batch 1192/1583] [D loss: 0.588788] [G loss: 0.216137]\n",
            "[Epoch 0/2] [Batch 1193/1583] [D loss: 0.590974] [G loss: 0.222492]\n",
            "[Epoch 0/2] [Batch 1194/1583] [D loss: 0.619995] [G loss: 0.219286]\n",
            "[Epoch 0/2] [Batch 1195/1583] [D loss: 0.606449] [G loss: 0.218507]\n",
            "[Epoch 0/2] [Batch 1196/1583] [D loss: 0.563236] [G loss: 0.212346]\n",
            "[Epoch 0/2] [Batch 1197/1583] [D loss: 0.586565] [G loss: 0.210444]\n",
            "[Epoch 0/2] [Batch 1198/1583] [D loss: 0.576112] [G loss: 0.213076]\n",
            "[Epoch 0/2] [Batch 1199/1583] [D loss: 0.582204] [G loss: 0.205965]\n",
            "[Epoch 0/2] [Batch 1200/1583] [D loss: 0.582150] [G loss: 0.213701]\n",
            "[Epoch 0/2] [Batch 1201/1583] [D loss: 0.569242] [G loss: 0.208061]\n",
            "[Epoch 0/2] [Batch 1202/1583] [D loss: 0.561869] [G loss: 0.215125]\n",
            "[Epoch 0/2] [Batch 1203/1583] [D loss: 0.620950] [G loss: 0.207075]\n",
            "[Epoch 0/2] [Batch 1204/1583] [D loss: 0.607475] [G loss: 0.217484]\n",
            "[Epoch 0/2] [Batch 1205/1583] [D loss: 0.583925] [G loss: 0.209527]\n",
            "[Epoch 0/2] [Batch 1206/1583] [D loss: 0.578968] [G loss: 0.219648]\n",
            "[Epoch 0/2] [Batch 1207/1583] [D loss: 0.557838] [G loss: 0.211222]\n",
            "[Epoch 0/2] [Batch 1208/1583] [D loss: 0.609463] [G loss: 0.216799]\n",
            "[Epoch 0/2] [Batch 1209/1583] [D loss: 0.588295] [G loss: 0.212073]\n",
            "[Epoch 0/2] [Batch 1210/1583] [D loss: 0.569860] [G loss: 0.216136]\n",
            "[Epoch 0/2] [Batch 1211/1583] [D loss: 0.580197] [G loss: 0.216733]\n",
            "[Epoch 0/2] [Batch 1212/1583] [D loss: 0.570525] [G loss: 0.210139]\n",
            "[Epoch 0/2] [Batch 1213/1583] [D loss: 0.564317] [G loss: 0.211645]\n",
            "[Epoch 0/2] [Batch 1214/1583] [D loss: 0.554384] [G loss: 0.213442]\n",
            "[Epoch 0/2] [Batch 1215/1583] [D loss: 0.596824] [G loss: 0.209094]\n",
            "[Epoch 0/2] [Batch 1216/1583] [D loss: 0.579931] [G loss: 0.205810]\n",
            "[Epoch 0/2] [Batch 1217/1583] [D loss: 0.623647] [G loss: 0.215286]\n",
            "[Epoch 0/2] [Batch 1218/1583] [D loss: 0.562618] [G loss: 0.224221]\n",
            "[Epoch 0/2] [Batch 1219/1583] [D loss: 0.600139] [G loss: 0.210628]\n",
            "[Epoch 0/2] [Batch 1220/1583] [D loss: 0.564816] [G loss: 0.221004]\n",
            "[Epoch 0/2] [Batch 1221/1583] [D loss: 0.569733] [G loss: 0.212861]\n",
            "[Epoch 0/2] [Batch 1222/1583] [D loss: 0.638109] [G loss: 0.215502]\n",
            "[Epoch 0/2] [Batch 1223/1583] [D loss: 0.555521] [G loss: 0.214296]\n",
            "[Epoch 0/2] [Batch 1224/1583] [D loss: 0.534754] [G loss: 0.207561]\n",
            "[Epoch 0/2] [Batch 1225/1583] [D loss: 0.576842] [G loss: 0.214501]\n",
            "[Epoch 0/2] [Batch 1226/1583] [D loss: 0.616655] [G loss: 0.218788]\n",
            "[Epoch 0/2] [Batch 1227/1583] [D loss: 0.564056] [G loss: 0.214179]\n",
            "[Epoch 0/2] [Batch 1228/1583] [D loss: 0.555771] [G loss: 0.214258]\n",
            "[Epoch 0/2] [Batch 1229/1583] [D loss: 0.543835] [G loss: 0.213560]\n",
            "[Epoch 0/2] [Batch 1230/1583] [D loss: 0.589461] [G loss: 0.204305]\n",
            "[Epoch 0/2] [Batch 1231/1583] [D loss: 0.580788] [G loss: 0.214676]\n",
            "[Epoch 0/2] [Batch 1232/1583] [D loss: 0.557059] [G loss: 0.213521]\n",
            "[Epoch 0/2] [Batch 1233/1583] [D loss: 0.570367] [G loss: 0.213127]\n",
            "[Epoch 0/2] [Batch 1234/1583] [D loss: 0.593851] [G loss: 0.211757]\n",
            "[Epoch 0/2] [Batch 1235/1583] [D loss: 0.552299] [G loss: 0.212687]\n",
            "[Epoch 0/2] [Batch 1236/1583] [D loss: 0.559736] [G loss: 0.211121]\n",
            "[Epoch 0/2] [Batch 1237/1583] [D loss: 0.617923] [G loss: 0.211954]\n",
            "[Epoch 0/2] [Batch 1238/1583] [D loss: 0.577150] [G loss: 0.224227]\n",
            "[Epoch 0/2] [Batch 1239/1583] [D loss: 0.565691] [G loss: 0.204782]\n",
            "[Epoch 0/2] [Batch 1240/1583] [D loss: 0.561390] [G loss: 0.216484]\n",
            "[Epoch 0/2] [Batch 1241/1583] [D loss: 0.611944] [G loss: 0.212203]\n",
            "[Epoch 0/2] [Batch 1242/1583] [D loss: 0.599804] [G loss: 0.214311]\n",
            "[Epoch 0/2] [Batch 1243/1583] [D loss: 0.618289] [G loss: 0.216619]\n",
            "[Epoch 0/2] [Batch 1244/1583] [D loss: 0.551418] [G loss: 0.206684]\n",
            "[Epoch 0/2] [Batch 1245/1583] [D loss: 0.579202] [G loss: 0.222699]\n",
            "[Epoch 0/2] [Batch 1246/1583] [D loss: 0.585605] [G loss: 0.221620]\n",
            "[Epoch 0/2] [Batch 1247/1583] [D loss: 0.593056] [G loss: 0.214538]\n",
            "[Epoch 0/2] [Batch 1248/1583] [D loss: 0.587770] [G loss: 0.216594]\n",
            "[Epoch 0/2] [Batch 1249/1583] [D loss: 0.585650] [G loss: 0.226230]\n",
            "[Epoch 0/2] [Batch 1250/1583] [D loss: 0.585946] [G loss: 0.212790]\n",
            "[Epoch 0/2] [Batch 1251/1583] [D loss: 0.617769] [G loss: 0.212443]\n",
            "[Epoch 0/2] [Batch 1252/1583] [D loss: 0.556427] [G loss: 0.218133]\n",
            "[Epoch 0/2] [Batch 1253/1583] [D loss: 0.564636] [G loss: 0.223219]\n",
            "[Epoch 0/2] [Batch 1254/1583] [D loss: 0.576197] [G loss: 0.223710]\n",
            "[Epoch 0/2] [Batch 1255/1583] [D loss: 0.578571] [G loss: 0.218337]\n",
            "[Epoch 0/2] [Batch 1256/1583] [D loss: 0.581105] [G loss: 0.211818]\n",
            "[Epoch 0/2] [Batch 1257/1583] [D loss: 0.567300] [G loss: 0.215348]\n",
            "[Epoch 0/2] [Batch 1258/1583] [D loss: 0.596304] [G loss: 0.223719]\n",
            "[Epoch 0/2] [Batch 1259/1583] [D loss: 0.559997] [G loss: 0.218674]\n",
            "[Epoch 0/2] [Batch 1260/1583] [D loss: 0.570492] [G loss: 0.206035]\n",
            "[Epoch 0/2] [Batch 1261/1583] [D loss: 0.571277] [G loss: 0.212510]\n",
            "[Epoch 0/2] [Batch 1262/1583] [D loss: 0.568680] [G loss: 0.214489]\n",
            "[Epoch 0/2] [Batch 1263/1583] [D loss: 0.612390] [G loss: 0.221349]\n",
            "[Epoch 0/2] [Batch 1264/1583] [D loss: 0.552252] [G loss: 0.216376]\n",
            "[Epoch 0/2] [Batch 1265/1583] [D loss: 0.550423] [G loss: 0.207618]\n",
            "[Epoch 0/2] [Batch 1266/1583] [D loss: 0.568935] [G loss: 0.212127]\n",
            "[Epoch 0/2] [Batch 1267/1583] [D loss: 0.560581] [G loss: 0.221046]\n",
            "[Epoch 0/2] [Batch 1268/1583] [D loss: 0.582868] [G loss: 0.216181]\n",
            "[Epoch 0/2] [Batch 1269/1583] [D loss: 0.564181] [G loss: 0.207380]\n",
            "[Epoch 0/2] [Batch 1270/1583] [D loss: 0.586377] [G loss: 0.216532]\n",
            "[Epoch 0/2] [Batch 1271/1583] [D loss: 0.603610] [G loss: 0.215400]\n",
            "[Epoch 0/2] [Batch 1272/1583] [D loss: 0.562723] [G loss: 0.211884]\n",
            "[Epoch 0/2] [Batch 1273/1583] [D loss: 0.551422] [G loss: 0.216926]\n",
            "[Epoch 0/2] [Batch 1274/1583] [D loss: 0.528662] [G loss: 0.208296]\n",
            "[Epoch 0/2] [Batch 1275/1583] [D loss: 0.578075] [G loss: 0.215794]\n",
            "[Epoch 0/2] [Batch 1276/1583] [D loss: 0.552679] [G loss: 0.208659]\n",
            "[Epoch 0/2] [Batch 1277/1583] [D loss: 0.610088] [G loss: 0.208402]\n",
            "[Epoch 0/2] [Batch 1278/1583] [D loss: 0.572075] [G loss: 0.207648]\n",
            "[Epoch 0/2] [Batch 1279/1583] [D loss: 0.572641] [G loss: 0.213173]\n",
            "[Epoch 0/2] [Batch 1280/1583] [D loss: 0.596918] [G loss: 0.211373]\n",
            "[Epoch 0/2] [Batch 1281/1583] [D loss: 0.587244] [G loss: 0.214950]\n",
            "[Epoch 0/2] [Batch 1282/1583] [D loss: 0.579172] [G loss: 0.215358]\n",
            "[Epoch 0/2] [Batch 1283/1583] [D loss: 0.550883] [G loss: 0.211318]\n",
            "[Epoch 0/2] [Batch 1284/1583] [D loss: 0.601552] [G loss: 0.225251]\n",
            "[Epoch 0/2] [Batch 1285/1583] [D loss: 0.570821] [G loss: 0.206145]\n",
            "[Epoch 0/2] [Batch 1286/1583] [D loss: 0.574854] [G loss: 0.215474]\n",
            "[Epoch 0/2] [Batch 1287/1583] [D loss: 0.586849] [G loss: 0.213248]\n",
            "[Epoch 0/2] [Batch 1288/1583] [D loss: 0.591619] [G loss: 0.209145]\n",
            "[Epoch 0/2] [Batch 1289/1583] [D loss: 0.544005] [G loss: 0.216144]\n",
            "[Epoch 0/2] [Batch 1290/1583] [D loss: 0.544543] [G loss: 0.219240]\n",
            "[Epoch 0/2] [Batch 1291/1583] [D loss: 0.586329] [G loss: 0.209563]\n",
            "[Epoch 0/2] [Batch 1292/1583] [D loss: 0.631891] [G loss: 0.217352]\n",
            "[Epoch 0/2] [Batch 1293/1583] [D loss: 0.589465] [G loss: 0.212572]\n",
            "[Epoch 0/2] [Batch 1294/1583] [D loss: 0.586175] [G loss: 0.203727]\n",
            "[Epoch 0/2] [Batch 1295/1583] [D loss: 0.544224] [G loss: 0.212676]\n",
            "[Epoch 0/2] [Batch 1296/1583] [D loss: 0.560582] [G loss: 0.209272]\n",
            "[Epoch 0/2] [Batch 1297/1583] [D loss: 0.587302] [G loss: 0.214852]\n",
            "[Epoch 0/2] [Batch 1298/1583] [D loss: 0.599436] [G loss: 0.210263]\n",
            "[Epoch 0/2] [Batch 1299/1583] [D loss: 0.593551] [G loss: 0.213416]\n",
            "[Epoch 0/2] [Batch 1300/1583] [D loss: 0.572386] [G loss: 0.214257]\n",
            "[Epoch 0/2] [Batch 1301/1583] [D loss: 0.558504] [G loss: 0.211263]\n",
            "[Epoch 0/2] [Batch 1302/1583] [D loss: 0.579108] [G loss: 0.213733]\n",
            "[Epoch 0/2] [Batch 1303/1583] [D loss: 0.568354] [G loss: 0.215060]\n",
            "[Epoch 0/2] [Batch 1304/1583] [D loss: 0.606871] [G loss: 0.206402]\n",
            "[Epoch 0/2] [Batch 1305/1583] [D loss: 0.600171] [G loss: 0.214624]\n",
            "[Epoch 0/2] [Batch 1306/1583] [D loss: 0.598991] [G loss: 0.217969]\n",
            "[Epoch 0/2] [Batch 1307/1583] [D loss: 0.579800] [G loss: 0.208836]\n",
            "[Epoch 0/2] [Batch 1308/1583] [D loss: 0.586481] [G loss: 0.210642]\n",
            "[Epoch 0/2] [Batch 1309/1583] [D loss: 0.568798] [G loss: 0.213428]\n",
            "[Epoch 0/2] [Batch 1310/1583] [D loss: 0.573555] [G loss: 0.218343]\n",
            "[Epoch 0/2] [Batch 1311/1583] [D loss: 0.559371] [G loss: 0.213098]\n",
            "[Epoch 0/2] [Batch 1312/1583] [D loss: 0.571912] [G loss: 0.218306]\n",
            "[Epoch 0/2] [Batch 1313/1583] [D loss: 0.575852] [G loss: 0.214532]\n",
            "[Epoch 0/2] [Batch 1314/1583] [D loss: 0.548308] [G loss: 0.207666]\n",
            "[Epoch 0/2] [Batch 1315/1583] [D loss: 0.606840] [G loss: 0.214645]\n",
            "[Epoch 0/2] [Batch 1316/1583] [D loss: 0.548585] [G loss: 0.210619]\n",
            "[Epoch 0/2] [Batch 1317/1583] [D loss: 0.615980] [G loss: 0.208342]\n",
            "[Epoch 0/2] [Batch 1318/1583] [D loss: 0.543808] [G loss: 0.211081]\n",
            "[Epoch 0/2] [Batch 1319/1583] [D loss: 0.597488] [G loss: 0.224257]\n",
            "[Epoch 0/2] [Batch 1320/1583] [D loss: 0.620280] [G loss: 0.220156]\n",
            "[Epoch 0/2] [Batch 1321/1583] [D loss: 0.601122] [G loss: 0.215743]\n",
            "[Epoch 0/2] [Batch 1322/1583] [D loss: 0.554624] [G loss: 0.213796]\n",
            "[Epoch 0/2] [Batch 1323/1583] [D loss: 0.584290] [G loss: 0.211947]\n",
            "[Epoch 0/2] [Batch 1324/1583] [D loss: 0.598447] [G loss: 0.214514]\n",
            "[Epoch 0/2] [Batch 1325/1583] [D loss: 0.603525] [G loss: 0.215606]\n",
            "[Epoch 0/2] [Batch 1326/1583] [D loss: 0.585794] [G loss: 0.213764]\n",
            "[Epoch 0/2] [Batch 1327/1583] [D loss: 0.555668] [G loss: 0.211163]\n",
            "[Epoch 0/2] [Batch 1328/1583] [D loss: 0.548037] [G loss: 0.206406]\n",
            "[Epoch 0/2] [Batch 1329/1583] [D loss: 0.591468] [G loss: 0.219440]\n",
            "[Epoch 0/2] [Batch 1330/1583] [D loss: 0.598596] [G loss: 0.214783]\n",
            "[Epoch 0/2] [Batch 1331/1583] [D loss: 0.597136] [G loss: 0.211964]\n",
            "[Epoch 0/2] [Batch 1332/1583] [D loss: 0.559635] [G loss: 0.210808]\n",
            "[Epoch 0/2] [Batch 1333/1583] [D loss: 0.545544] [G loss: 0.217393]\n",
            "[Epoch 0/2] [Batch 1334/1583] [D loss: 0.554951] [G loss: 0.214921]\n",
            "[Epoch 0/2] [Batch 1335/1583] [D loss: 0.582026] [G loss: 0.213859]\n",
            "[Epoch 0/2] [Batch 1336/1583] [D loss: 0.605827] [G loss: 0.213072]\n",
            "[Epoch 0/2] [Batch 1337/1583] [D loss: 0.540216] [G loss: 0.212405]\n",
            "[Epoch 0/2] [Batch 1338/1583] [D loss: 0.553686] [G loss: 0.214285]\n",
            "[Epoch 0/2] [Batch 1339/1583] [D loss: 0.591241] [G loss: 0.212997]\n",
            "[Epoch 0/2] [Batch 1340/1583] [D loss: 0.565232] [G loss: 0.212065]\n",
            "[Epoch 0/2] [Batch 1341/1583] [D loss: 0.575177] [G loss: 0.215050]\n",
            "[Epoch 0/2] [Batch 1342/1583] [D loss: 0.587394] [G loss: 0.216921]\n",
            "[Epoch 0/2] [Batch 1343/1583] [D loss: 0.519247] [G loss: 0.220385]\n",
            "[Epoch 0/2] [Batch 1344/1583] [D loss: 0.579001] [G loss: 0.210260]\n",
            "[Epoch 0/2] [Batch 1345/1583] [D loss: 0.552828] [G loss: 0.218121]\n",
            "[Epoch 0/2] [Batch 1346/1583] [D loss: 0.550562] [G loss: 0.210489]\n",
            "[Epoch 0/2] [Batch 1347/1583] [D loss: 0.585150] [G loss: 0.206398]\n",
            "[Epoch 0/2] [Batch 1348/1583] [D loss: 0.613660] [G loss: 0.210598]\n",
            "[Epoch 0/2] [Batch 1349/1583] [D loss: 0.568985] [G loss: 0.204516]\n",
            "[Epoch 0/2] [Batch 1350/1583] [D loss: 0.547373] [G loss: 0.212244]\n",
            "[Epoch 0/2] [Batch 1351/1583] [D loss: 0.606372] [G loss: 0.217798]\n",
            "[Epoch 0/2] [Batch 1352/1583] [D loss: 0.575993] [G loss: 0.212009]\n",
            "[Epoch 0/2] [Batch 1353/1583] [D loss: 0.535564] [G loss: 0.208615]\n",
            "[Epoch 0/2] [Batch 1354/1583] [D loss: 0.602676] [G loss: 0.213047]\n",
            "[Epoch 0/2] [Batch 1355/1583] [D loss: 0.562328] [G loss: 0.213986]\n",
            "[Epoch 0/2] [Batch 1356/1583] [D loss: 0.566989] [G loss: 0.208495]\n",
            "[Epoch 0/2] [Batch 1357/1583] [D loss: 0.558587] [G loss: 0.207373]\n",
            "[Epoch 0/2] [Batch 1358/1583] [D loss: 0.571216] [G loss: 0.214823]\n",
            "[Epoch 0/2] [Batch 1359/1583] [D loss: 0.547905] [G loss: 0.216808]\n",
            "[Epoch 0/2] [Batch 1360/1583] [D loss: 0.584232] [G loss: 0.214340]\n",
            "[Epoch 0/2] [Batch 1361/1583] [D loss: 0.630607] [G loss: 0.210649]\n",
            "[Epoch 0/2] [Batch 1362/1583] [D loss: 0.590175] [G loss: 0.210312]\n",
            "[Epoch 0/2] [Batch 1363/1583] [D loss: 0.558181] [G loss: 0.208348]\n",
            "[Epoch 0/2] [Batch 1364/1583] [D loss: 0.537903] [G loss: 0.217196]\n",
            "[Epoch 0/2] [Batch 1365/1583] [D loss: 0.570486] [G loss: 0.208822]\n",
            "[Epoch 0/2] [Batch 1366/1583] [D loss: 0.589428] [G loss: 0.210416]\n",
            "[Epoch 0/2] [Batch 1367/1583] [D loss: 0.551953] [G loss: 0.209301]\n",
            "[Epoch 0/2] [Batch 1368/1583] [D loss: 0.580356] [G loss: 0.214606]\n",
            "[Epoch 0/2] [Batch 1369/1583] [D loss: 0.603036] [G loss: 0.213334]\n",
            "[Epoch 0/2] [Batch 1370/1583] [D loss: 0.550575] [G loss: 0.214018]\n",
            "[Epoch 0/2] [Batch 1371/1583] [D loss: 0.590778] [G loss: 0.206856]\n",
            "[Epoch 0/2] [Batch 1372/1583] [D loss: 0.572031] [G loss: 0.214128]\n",
            "[Epoch 0/2] [Batch 1373/1583] [D loss: 0.551965] [G loss: 0.219394]\n",
            "[Epoch 0/2] [Batch 1374/1583] [D loss: 0.564060] [G loss: 0.212557]\n",
            "[Epoch 0/2] [Batch 1375/1583] [D loss: 0.592415] [G loss: 0.213423]\n",
            "[Epoch 0/2] [Batch 1376/1583] [D loss: 0.576829] [G loss: 0.207830]\n",
            "[Epoch 0/2] [Batch 1377/1583] [D loss: 0.539854] [G loss: 0.213866]\n",
            "[Epoch 0/2] [Batch 1378/1583] [D loss: 0.575028] [G loss: 0.216578]\n",
            "[Epoch 0/2] [Batch 1379/1583] [D loss: 0.601048] [G loss: 0.213235]\n",
            "[Epoch 0/2] [Batch 1380/1583] [D loss: 0.582139] [G loss: 0.215569]\n",
            "[Epoch 0/2] [Batch 1381/1583] [D loss: 0.590447] [G loss: 0.206562]\n",
            "[Epoch 0/2] [Batch 1382/1583] [D loss: 0.542397] [G loss: 0.220271]\n",
            "[Epoch 0/2] [Batch 1383/1583] [D loss: 0.577119] [G loss: 0.212910]\n",
            "[Epoch 0/2] [Batch 1384/1583] [D loss: 0.572079] [G loss: 0.210392]\n",
            "[Epoch 0/2] [Batch 1385/1583] [D loss: 0.549477] [G loss: 0.212497]\n",
            "[Epoch 0/2] [Batch 1386/1583] [D loss: 0.535504] [G loss: 0.203573]\n",
            "[Epoch 0/2] [Batch 1387/1583] [D loss: 0.578902] [G loss: 0.221648]\n",
            "[Epoch 0/2] [Batch 1388/1583] [D loss: 0.573785] [G loss: 0.217715]\n",
            "[Epoch 0/2] [Batch 1389/1583] [D loss: 0.578149] [G loss: 0.206184]\n",
            "[Epoch 0/2] [Batch 1390/1583] [D loss: 0.577349] [G loss: 0.210033]\n",
            "[Epoch 0/2] [Batch 1391/1583] [D loss: 0.548166] [G loss: 0.214600]\n",
            "[Epoch 0/2] [Batch 1392/1583] [D loss: 0.593557] [G loss: 0.219969]\n",
            "[Epoch 0/2] [Batch 1393/1583] [D loss: 0.551771] [G loss: 0.213803]\n",
            "[Epoch 0/2] [Batch 1394/1583] [D loss: 0.586353] [G loss: 0.205016]\n",
            "[Epoch 0/2] [Batch 1395/1583] [D loss: 0.577712] [G loss: 0.212987]\n",
            "[Epoch 0/2] [Batch 1396/1583] [D loss: 0.559431] [G loss: 0.216007]\n",
            "[Epoch 0/2] [Batch 1397/1583] [D loss: 0.614156] [G loss: 0.203699]\n",
            "[Epoch 0/2] [Batch 1398/1583] [D loss: 0.565428] [G loss: 0.203819]\n",
            "[Epoch 0/2] [Batch 1399/1583] [D loss: 0.561758] [G loss: 0.215146]\n",
            "[Epoch 0/2] [Batch 1400/1583] [D loss: 0.565632] [G loss: 0.210537]\n",
            "[Epoch 0/2] [Batch 1401/1583] [D loss: 0.582908] [G loss: 0.216424]\n",
            "[Epoch 0/2] [Batch 1402/1583] [D loss: 0.590422] [G loss: 0.203220]\n",
            "[Epoch 0/2] [Batch 1403/1583] [D loss: 0.563443] [G loss: 0.215704]\n",
            "[Epoch 0/2] [Batch 1404/1583] [D loss: 0.579520] [G loss: 0.211738]\n",
            "[Epoch 0/2] [Batch 1405/1583] [D loss: 0.546010] [G loss: 0.212717]\n",
            "[Epoch 0/2] [Batch 1406/1583] [D loss: 0.554146] [G loss: 0.208074]\n",
            "[Epoch 0/2] [Batch 1407/1583] [D loss: 0.575293] [G loss: 0.217776]\n",
            "[Epoch 0/2] [Batch 1408/1583] [D loss: 0.571926] [G loss: 0.211915]\n",
            "[Epoch 0/2] [Batch 1409/1583] [D loss: 0.598208] [G loss: 0.213588]\n",
            "[Epoch 0/2] [Batch 1410/1583] [D loss: 0.588108] [G loss: 0.215062]\n",
            "[Epoch 0/2] [Batch 1411/1583] [D loss: 0.550067] [G loss: 0.210917]\n",
            "[Epoch 0/2] [Batch 1412/1583] [D loss: 0.558552] [G loss: 0.208276]\n",
            "[Epoch 0/2] [Batch 1413/1583] [D loss: 0.574796] [G loss: 0.217671]\n",
            "[Epoch 0/2] [Batch 1414/1583] [D loss: 0.572240] [G loss: 0.219212]\n",
            "[Epoch 0/2] [Batch 1415/1583] [D loss: 0.565909] [G loss: 0.211121]\n",
            "[Epoch 0/2] [Batch 1416/1583] [D loss: 0.573458] [G loss: 0.206864]\n",
            "[Epoch 0/2] [Batch 1417/1583] [D loss: 0.549485] [G loss: 0.215536]\n",
            "[Epoch 0/2] [Batch 1418/1583] [D loss: 0.559214] [G loss: 0.204890]\n",
            "[Epoch 0/2] [Batch 1419/1583] [D loss: 0.585721] [G loss: 0.221873]\n",
            "[Epoch 0/2] [Batch 1420/1583] [D loss: 0.578638] [G loss: 0.215536]\n",
            "[Epoch 0/2] [Batch 1421/1583] [D loss: 0.608891] [G loss: 0.215453]\n",
            "[Epoch 0/2] [Batch 1422/1583] [D loss: 0.575501] [G loss: 0.214170]\n",
            "[Epoch 0/2] [Batch 1423/1583] [D loss: 0.553051] [G loss: 0.207643]\n",
            "[Epoch 0/2] [Batch 1424/1583] [D loss: 0.606938] [G loss: 0.217495]\n",
            "[Epoch 0/2] [Batch 1425/1583] [D loss: 0.564050] [G loss: 0.211668]\n",
            "[Epoch 0/2] [Batch 1426/1583] [D loss: 0.577384] [G loss: 0.208838]\n",
            "[Epoch 0/2] [Batch 1427/1583] [D loss: 0.541705] [G loss: 0.209950]\n",
            "[Epoch 0/2] [Batch 1428/1583] [D loss: 0.562788] [G loss: 0.214461]\n",
            "[Epoch 0/2] [Batch 1429/1583] [D loss: 0.549874] [G loss: 0.207696]\n",
            "[Epoch 0/2] [Batch 1430/1583] [D loss: 0.537686] [G loss: 0.214186]\n",
            "[Epoch 0/2] [Batch 1431/1583] [D loss: 0.554446] [G loss: 0.221354]\n",
            "[Epoch 0/2] [Batch 1432/1583] [D loss: 0.571217] [G loss: 0.216690]\n",
            "[Epoch 0/2] [Batch 1433/1583] [D loss: 0.611350] [G loss: 0.217371]\n",
            "[Epoch 0/2] [Batch 1434/1583] [D loss: 0.576653] [G loss: 0.215860]\n",
            "[Epoch 0/2] [Batch 1435/1583] [D loss: 0.599298] [G loss: 0.213783]\n",
            "[Epoch 0/2] [Batch 1436/1583] [D loss: 0.551941] [G loss: 0.212344]\n",
            "[Epoch 0/2] [Batch 1437/1583] [D loss: 0.531535] [G loss: 0.202514]\n",
            "[Epoch 0/2] [Batch 1438/1583] [D loss: 0.557131] [G loss: 0.218379]\n",
            "[Epoch 0/2] [Batch 1439/1583] [D loss: 0.567741] [G loss: 0.207252]\n",
            "[Epoch 0/2] [Batch 1440/1583] [D loss: 0.571361] [G loss: 0.211371]\n",
            "[Epoch 0/2] [Batch 1441/1583] [D loss: 0.583039] [G loss: 0.220429]\n",
            "[Epoch 0/2] [Batch 1442/1583] [D loss: 0.584996] [G loss: 0.216650]\n",
            "[Epoch 0/2] [Batch 1443/1583] [D loss: 0.538990] [G loss: 0.206279]\n",
            "[Epoch 0/2] [Batch 1444/1583] [D loss: 0.557555] [G loss: 0.215975]\n",
            "[Epoch 0/2] [Batch 1445/1583] [D loss: 0.550499] [G loss: 0.213794]\n",
            "[Epoch 0/2] [Batch 1446/1583] [D loss: 0.563073] [G loss: 0.209099]\n",
            "[Epoch 0/2] [Batch 1447/1583] [D loss: 0.581935] [G loss: 0.216113]\n",
            "[Epoch 0/2] [Batch 1448/1583] [D loss: 0.585244] [G loss: 0.209726]\n",
            "[Epoch 0/2] [Batch 1449/1583] [D loss: 0.539249] [G loss: 0.206965]\n",
            "[Epoch 0/2] [Batch 1450/1583] [D loss: 0.561149] [G loss: 0.214712]\n",
            "[Epoch 0/2] [Batch 1451/1583] [D loss: 0.540412] [G loss: 0.211659]\n",
            "[Epoch 0/2] [Batch 1452/1583] [D loss: 0.592591] [G loss: 0.204216]\n",
            "[Epoch 0/2] [Batch 1453/1583] [D loss: 0.563942] [G loss: 0.210749]\n",
            "[Epoch 0/2] [Batch 1454/1583] [D loss: 0.535417] [G loss: 0.209009]\n",
            "[Epoch 0/2] [Batch 1455/1583] [D loss: 0.561817] [G loss: 0.213033]\n",
            "[Epoch 0/2] [Batch 1456/1583] [D loss: 0.552106] [G loss: 0.216742]\n",
            "[Epoch 0/2] [Batch 1457/1583] [D loss: 0.564083] [G loss: 0.215311]\n",
            "[Epoch 0/2] [Batch 1458/1583] [D loss: 0.585670] [G loss: 0.222296]\n",
            "[Epoch 0/2] [Batch 1459/1583] [D loss: 0.595814] [G loss: 0.213828]\n",
            "[Epoch 0/2] [Batch 1460/1583] [D loss: 0.559083] [G loss: 0.218767]\n",
            "[Epoch 0/2] [Batch 1461/1583] [D loss: 0.555490] [G loss: 0.202896]\n",
            "[Epoch 0/2] [Batch 1462/1583] [D loss: 0.596275] [G loss: 0.214310]\n",
            "[Epoch 0/2] [Batch 1463/1583] [D loss: 0.571330] [G loss: 0.211872]\n",
            "[Epoch 0/2] [Batch 1464/1583] [D loss: 0.580783] [G loss: 0.202946]\n",
            "[Epoch 0/2] [Batch 1465/1583] [D loss: 0.581778] [G loss: 0.210125]\n",
            "[Epoch 0/2] [Batch 1466/1583] [D loss: 0.548855] [G loss: 0.208711]\n",
            "[Epoch 0/2] [Batch 1467/1583] [D loss: 0.572470] [G loss: 0.211006]\n",
            "[Epoch 0/2] [Batch 1468/1583] [D loss: 0.582047] [G loss: 0.223361]\n",
            "[Epoch 0/2] [Batch 1469/1583] [D loss: 0.585281] [G loss: 0.211361]\n",
            "[Epoch 0/2] [Batch 1470/1583] [D loss: 0.569112] [G loss: 0.213939]\n",
            "[Epoch 0/2] [Batch 1471/1583] [D loss: 0.576138] [G loss: 0.213830]\n",
            "[Epoch 0/2] [Batch 1472/1583] [D loss: 0.586074] [G loss: 0.213771]\n",
            "[Epoch 0/2] [Batch 1473/1583] [D loss: 0.564740] [G loss: 0.215247]\n",
            "[Epoch 0/2] [Batch 1474/1583] [D loss: 0.622070] [G loss: 0.208258]\n",
            "[Epoch 0/2] [Batch 1475/1583] [D loss: 0.548693] [G loss: 0.211558]\n",
            "[Epoch 0/2] [Batch 1476/1583] [D loss: 0.552879] [G loss: 0.211527]\n",
            "[Epoch 0/2] [Batch 1477/1583] [D loss: 0.582777] [G loss: 0.210083]\n",
            "[Epoch 0/2] [Batch 1478/1583] [D loss: 0.577550] [G loss: 0.211828]\n",
            "[Epoch 0/2] [Batch 1479/1583] [D loss: 0.620357] [G loss: 0.211756]\n",
            "[Epoch 0/2] [Batch 1480/1583] [D loss: 0.575232] [G loss: 0.218217]\n",
            "[Epoch 0/2] [Batch 1481/1583] [D loss: 0.589714] [G loss: 0.212446]\n",
            "[Epoch 0/2] [Batch 1482/1583] [D loss: 0.587207] [G loss: 0.215294]\n",
            "[Epoch 0/2] [Batch 1483/1583] [D loss: 0.624742] [G loss: 0.221740]\n",
            "[Epoch 0/2] [Batch 1484/1583] [D loss: 0.607073] [G loss: 0.219266]\n",
            "[Epoch 0/2] [Batch 1485/1583] [D loss: 0.566321] [G loss: 0.217368]\n",
            "[Epoch 0/2] [Batch 1486/1583] [D loss: 0.594395] [G loss: 0.218539]\n",
            "[Epoch 0/2] [Batch 1487/1583] [D loss: 0.626903] [G loss: 0.209762]\n",
            "[Epoch 0/2] [Batch 1488/1583] [D loss: 0.603408] [G loss: 0.216522]\n",
            "[Epoch 0/2] [Batch 1489/1583] [D loss: 0.605564] [G loss: 0.210585]\n",
            "[Epoch 0/2] [Batch 1490/1583] [D loss: 0.580822] [G loss: 0.218930]\n",
            "[Epoch 0/2] [Batch 1491/1583] [D loss: 0.582931] [G loss: 0.207888]\n",
            "[Epoch 0/2] [Batch 1492/1583] [D loss: 0.576364] [G loss: 0.212803]\n",
            "[Epoch 0/2] [Batch 1493/1583] [D loss: 0.581148] [G loss: 0.215625]\n",
            "[Epoch 0/2] [Batch 1494/1583] [D loss: 0.540954] [G loss: 0.208878]\n",
            "[Epoch 0/2] [Batch 1495/1583] [D loss: 0.615686] [G loss: 0.223919]\n",
            "[Epoch 0/2] [Batch 1496/1583] [D loss: 0.599944] [G loss: 0.216754]\n",
            "[Epoch 0/2] [Batch 1497/1583] [D loss: 0.556424] [G loss: 0.215702]\n",
            "[Epoch 0/2] [Batch 1498/1583] [D loss: 0.556709] [G loss: 0.210758]\n",
            "[Epoch 0/2] [Batch 1499/1583] [D loss: 0.571800] [G loss: 0.210348]\n",
            "[Epoch 0/2] [Batch 1500/1583] [D loss: 0.590259] [G loss: 0.214462]\n",
            "[Epoch 0/2] [Batch 1501/1583] [D loss: 0.599238] [G loss: 0.212791]\n",
            "[Epoch 0/2] [Batch 1502/1583] [D loss: 0.568590] [G loss: 0.215147]\n",
            "[Epoch 0/2] [Batch 1503/1583] [D loss: 0.577806] [G loss: 0.213496]\n",
            "[Epoch 0/2] [Batch 1504/1583] [D loss: 0.558519] [G loss: 0.227358]\n",
            "[Epoch 0/2] [Batch 1505/1583] [D loss: 0.567582] [G loss: 0.215504]\n",
            "[Epoch 0/2] [Batch 1506/1583] [D loss: 0.564492] [G loss: 0.206478]\n",
            "[Epoch 0/2] [Batch 1507/1583] [D loss: 0.548312] [G loss: 0.218500]\n",
            "[Epoch 0/2] [Batch 1508/1583] [D loss: 0.550443] [G loss: 0.207669]\n",
            "[Epoch 0/2] [Batch 1509/1583] [D loss: 0.556612] [G loss: 0.206241]\n",
            "[Epoch 0/2] [Batch 1510/1583] [D loss: 0.549311] [G loss: 0.204925]\n",
            "[Epoch 0/2] [Batch 1511/1583] [D loss: 0.572543] [G loss: 0.205762]\n",
            "[Epoch 0/2] [Batch 1512/1583] [D loss: 0.574187] [G loss: 0.218115]\n",
            "[Epoch 0/2] [Batch 1513/1583] [D loss: 0.575607] [G loss: 0.218943]\n",
            "[Epoch 0/2] [Batch 1514/1583] [D loss: 0.586173] [G loss: 0.211437]\n",
            "[Epoch 0/2] [Batch 1515/1583] [D loss: 0.588640] [G loss: 0.208690]\n",
            "[Epoch 0/2] [Batch 1516/1583] [D loss: 0.563118] [G loss: 0.218963]\n",
            "[Epoch 0/2] [Batch 1517/1583] [D loss: 0.549424] [G loss: 0.212566]\n",
            "[Epoch 0/2] [Batch 1518/1583] [D loss: 0.540696] [G loss: 0.209573]\n",
            "[Epoch 0/2] [Batch 1519/1583] [D loss: 0.643105] [G loss: 0.220060]\n",
            "[Epoch 0/2] [Batch 1520/1583] [D loss: 0.571036] [G loss: 0.206753]\n",
            "[Epoch 0/2] [Batch 1521/1583] [D loss: 0.550106] [G loss: 0.217197]\n",
            "[Epoch 0/2] [Batch 1522/1583] [D loss: 0.631129] [G loss: 0.231731]\n",
            "[Epoch 0/2] [Batch 1523/1583] [D loss: 0.567633] [G loss: 0.208069]\n",
            "[Epoch 0/2] [Batch 1524/1583] [D loss: 0.563192] [G loss: 0.221906]\n",
            "[Epoch 0/2] [Batch 1525/1583] [D loss: 0.559299] [G loss: 0.210314]\n",
            "[Epoch 0/2] [Batch 1526/1583] [D loss: 0.575538] [G loss: 0.213757]\n",
            "[Epoch 0/2] [Batch 1527/1583] [D loss: 0.556166] [G loss: 0.205802]\n",
            "[Epoch 0/2] [Batch 1528/1583] [D loss: 0.567317] [G loss: 0.221766]\n",
            "[Epoch 0/2] [Batch 1529/1583] [D loss: 0.579526] [G loss: 0.212408]\n",
            "[Epoch 0/2] [Batch 1530/1583] [D loss: 0.587998] [G loss: 0.228597]\n",
            "[Epoch 0/2] [Batch 1531/1583] [D loss: 0.610973] [G loss: 0.218695]\n",
            "[Epoch 0/2] [Batch 1532/1583] [D loss: 0.548670] [G loss: 0.207053]\n",
            "[Epoch 0/2] [Batch 1533/1583] [D loss: 0.597746] [G loss: 0.217298]\n",
            "[Epoch 0/2] [Batch 1534/1583] [D loss: 0.547468] [G loss: 0.205770]\n",
            "[Epoch 0/2] [Batch 1535/1583] [D loss: 0.594806] [G loss: 0.214832]\n",
            "[Epoch 0/2] [Batch 1536/1583] [D loss: 0.578962] [G loss: 0.216868]\n",
            "[Epoch 0/2] [Batch 1537/1583] [D loss: 0.573916] [G loss: 0.216136]\n",
            "[Epoch 0/2] [Batch 1538/1583] [D loss: 0.602007] [G loss: 0.208114]\n",
            "[Epoch 0/2] [Batch 1539/1583] [D loss: 0.569410] [G loss: 0.207184]\n",
            "[Epoch 0/2] [Batch 1540/1583] [D loss: 0.574537] [G loss: 0.204197]\n",
            "[Epoch 0/2] [Batch 1541/1583] [D loss: 0.565786] [G loss: 0.210330]\n",
            "[Epoch 0/2] [Batch 1542/1583] [D loss: 0.578714] [G loss: 0.214965]\n",
            "[Epoch 0/2] [Batch 1543/1583] [D loss: 0.613691] [G loss: 0.217276]\n",
            "[Epoch 0/2] [Batch 1544/1583] [D loss: 0.617989] [G loss: 0.215689]\n",
            "[Epoch 0/2] [Batch 1545/1583] [D loss: 0.598584] [G loss: 0.215746]\n",
            "[Epoch 0/2] [Batch 1546/1583] [D loss: 0.589346] [G loss: 0.214259]\n",
            "[Epoch 0/2] [Batch 1547/1583] [D loss: 0.598813] [G loss: 0.208056]\n",
            "[Epoch 0/2] [Batch 1548/1583] [D loss: 0.560002] [G loss: 0.213853]\n",
            "[Epoch 0/2] [Batch 1549/1583] [D loss: 0.590746] [G loss: 0.213197]\n",
            "[Epoch 0/2] [Batch 1550/1583] [D loss: 0.585795] [G loss: 0.212425]\n",
            "[Epoch 0/2] [Batch 1551/1583] [D loss: 0.584329] [G loss: 0.218603]\n",
            "[Epoch 0/2] [Batch 1552/1583] [D loss: 0.538622] [G loss: 0.202617]\n",
            "[Epoch 0/2] [Batch 1553/1583] [D loss: 0.581894] [G loss: 0.212403]\n",
            "[Epoch 0/2] [Batch 1554/1583] [D loss: 0.579621] [G loss: 0.207715]\n",
            "[Epoch 0/2] [Batch 1555/1583] [D loss: 0.570445] [G loss: 0.223699]\n",
            "[Epoch 0/2] [Batch 1556/1583] [D loss: 0.588709] [G loss: 0.214936]\n",
            "[Epoch 0/2] [Batch 1557/1583] [D loss: 0.570879] [G loss: 0.205023]\n",
            "[Epoch 0/2] [Batch 1558/1583] [D loss: 0.568022] [G loss: 0.220359]\n",
            "[Epoch 0/2] [Batch 1559/1583] [D loss: 0.582770] [G loss: 0.221952]\n",
            "[Epoch 0/2] [Batch 1560/1583] [D loss: 0.609992] [G loss: 0.222267]\n",
            "[Epoch 0/2] [Batch 1561/1583] [D loss: 0.558979] [G loss: 0.214798]\n",
            "[Epoch 0/2] [Batch 1562/1583] [D loss: 0.566961] [G loss: 0.214544]\n",
            "[Epoch 0/2] [Batch 1563/1583] [D loss: 0.629585] [G loss: 0.213864]\n",
            "[Epoch 0/2] [Batch 1564/1583] [D loss: 0.574617] [G loss: 0.206441]\n",
            "[Epoch 0/2] [Batch 1565/1583] [D loss: 0.559633] [G loss: 0.218078]\n",
            "[Epoch 0/2] [Batch 1566/1583] [D loss: 0.545780] [G loss: 0.214468]\n",
            "[Epoch 0/2] [Batch 1567/1583] [D loss: 0.601305] [G loss: 0.212120]\n",
            "[Epoch 0/2] [Batch 1568/1583] [D loss: 0.545294] [G loss: 0.212868]\n",
            "[Epoch 0/2] [Batch 1569/1583] [D loss: 0.577402] [G loss: 0.213057]\n",
            "[Epoch 0/2] [Batch 1570/1583] [D loss: 0.563566] [G loss: 0.220061]\n",
            "[Epoch 0/2] [Batch 1571/1583] [D loss: 0.560953] [G loss: 0.209499]\n",
            "[Epoch 0/2] [Batch 1572/1583] [D loss: 0.579672] [G loss: 0.218569]\n",
            "[Epoch 0/2] [Batch 1573/1583] [D loss: 0.582582] [G loss: 0.215704]\n",
            "[Epoch 0/2] [Batch 1574/1583] [D loss: 0.578742] [G loss: 0.205611]\n",
            "[Epoch 0/2] [Batch 1575/1583] [D loss: 0.583415] [G loss: 0.220572]\n",
            "[Epoch 0/2] [Batch 1576/1583] [D loss: 0.588277] [G loss: 0.209963]\n",
            "[Epoch 0/2] [Batch 1577/1583] [D loss: 0.596350] [G loss: 0.217889]\n",
            "[Epoch 0/2] [Batch 1578/1583] [D loss: 0.558458] [G loss: 0.212940]\n",
            "[Epoch 0/2] [Batch 1579/1583] [D loss: 0.574557] [G loss: 0.212930]\n",
            "[Epoch 0/2] [Batch 1580/1583] [D loss: 0.569143] [G loss: 0.213017]\n",
            "[Epoch 0/2] [Batch 1581/1583] [D loss: 0.571131] [G loss: 0.210731]\n",
            "[Epoch 0/2] [Batch 1582/1583] [D loss: 0.614163] [G loss: 0.213782]\n",
            "[Epoch 1/2] [Batch 0/1583] [D loss: 0.605626] [G loss: 0.218761]\n",
            "[Epoch 1/2] [Batch 1/1583] [D loss: 0.566457] [G loss: 0.205653]\n",
            "[Epoch 1/2] [Batch 2/1583] [D loss: 0.575855] [G loss: 0.215347]\n",
            "[Epoch 1/2] [Batch 3/1583] [D loss: 0.557076] [G loss: 0.209079]\n",
            "[Epoch 1/2] [Batch 4/1583] [D loss: 0.582383] [G loss: 0.220152]\n",
            "[Epoch 1/2] [Batch 5/1583] [D loss: 0.593306] [G loss: 0.221570]\n",
            "[Epoch 1/2] [Batch 6/1583] [D loss: 0.572501] [G loss: 0.211690]\n",
            "[Epoch 1/2] [Batch 7/1583] [D loss: 0.561955] [G loss: 0.211055]\n",
            "[Epoch 1/2] [Batch 8/1583] [D loss: 0.556650] [G loss: 0.214489]\n",
            "[Epoch 1/2] [Batch 9/1583] [D loss: 0.550513] [G loss: 0.204423]\n",
            "[Epoch 1/2] [Batch 10/1583] [D loss: 0.572688] [G loss: 0.216613]\n",
            "[Epoch 1/2] [Batch 11/1583] [D loss: 0.584182] [G loss: 0.211508]\n",
            "[Epoch 1/2] [Batch 12/1583] [D loss: 0.580617] [G loss: 0.209518]\n",
            "[Epoch 1/2] [Batch 13/1583] [D loss: 0.565707] [G loss: 0.210473]\n",
            "[Epoch 1/2] [Batch 14/1583] [D loss: 0.581462] [G loss: 0.211868]\n",
            "[Epoch 1/2] [Batch 15/1583] [D loss: 0.572491] [G loss: 0.214980]\n",
            "[Epoch 1/2] [Batch 16/1583] [D loss: 0.582008] [G loss: 0.216344]\n",
            "[Epoch 1/2] [Batch 17/1583] [D loss: 0.578433] [G loss: 0.207557]\n",
            "[Epoch 1/2] [Batch 18/1583] [D loss: 0.568060] [G loss: 0.208212]\n",
            "[Epoch 1/2] [Batch 19/1583] [D loss: 0.617108] [G loss: 0.215469]\n",
            "[Epoch 1/2] [Batch 20/1583] [D loss: 0.575991] [G loss: 0.214921]\n",
            "[Epoch 1/2] [Batch 21/1583] [D loss: 0.583559] [G loss: 0.213005]\n",
            "[Epoch 1/2] [Batch 22/1583] [D loss: 0.553576] [G loss: 0.206915]\n",
            "[Epoch 1/2] [Batch 23/1583] [D loss: 0.552889] [G loss: 0.216441]\n",
            "[Epoch 1/2] [Batch 24/1583] [D loss: 0.572813] [G loss: 0.212350]\n",
            "[Epoch 1/2] [Batch 25/1583] [D loss: 0.581697] [G loss: 0.207893]\n",
            "[Epoch 1/2] [Batch 26/1583] [D loss: 0.559102] [G loss: 0.212647]\n",
            "[Epoch 1/2] [Batch 27/1583] [D loss: 0.551605] [G loss: 0.208013]\n",
            "[Epoch 1/2] [Batch 28/1583] [D loss: 0.573934] [G loss: 0.209112]\n",
            "[Epoch 1/2] [Batch 29/1583] [D loss: 0.563770] [G loss: 0.211662]\n",
            "[Epoch 1/2] [Batch 30/1583] [D loss: 0.617235] [G loss: 0.221151]\n",
            "[Epoch 1/2] [Batch 31/1583] [D loss: 0.571632] [G loss: 0.208595]\n",
            "[Epoch 1/2] [Batch 32/1583] [D loss: 0.591662] [G loss: 0.206211]\n",
            "[Epoch 1/2] [Batch 33/1583] [D loss: 0.545125] [G loss: 0.212221]\n",
            "[Epoch 1/2] [Batch 34/1583] [D loss: 0.609285] [G loss: 0.212987]\n",
            "[Epoch 1/2] [Batch 35/1583] [D loss: 0.594797] [G loss: 0.212095]\n",
            "[Epoch 1/2] [Batch 36/1583] [D loss: 0.562720] [G loss: 0.210975]\n",
            "[Epoch 1/2] [Batch 37/1583] [D loss: 0.579582] [G loss: 0.213658]\n",
            "[Epoch 1/2] [Batch 38/1583] [D loss: 0.590967] [G loss: 0.211585]\n",
            "[Epoch 1/2] [Batch 39/1583] [D loss: 0.614351] [G loss: 0.215327]\n",
            "[Epoch 1/2] [Batch 40/1583] [D loss: 0.572814] [G loss: 0.217911]\n",
            "[Epoch 1/2] [Batch 41/1583] [D loss: 0.537934] [G loss: 0.212082]\n",
            "[Epoch 1/2] [Batch 42/1583] [D loss: 0.558479] [G loss: 0.210533]\n",
            "[Epoch 1/2] [Batch 43/1583] [D loss: 0.580209] [G loss: 0.210280]\n",
            "[Epoch 1/2] [Batch 44/1583] [D loss: 0.597083] [G loss: 0.211330]\n",
            "[Epoch 1/2] [Batch 45/1583] [D loss: 0.531470] [G loss: 0.210897]\n",
            "[Epoch 1/2] [Batch 46/1583] [D loss: 0.548825] [G loss: 0.216434]\n",
            "[Epoch 1/2] [Batch 47/1583] [D loss: 0.569548] [G loss: 0.204294]\n",
            "[Epoch 1/2] [Batch 48/1583] [D loss: 0.591546] [G loss: 0.207431]\n",
            "[Epoch 1/2] [Batch 49/1583] [D loss: 0.560349] [G loss: 0.212992]\n",
            "[Epoch 1/2] [Batch 50/1583] [D loss: 0.572367] [G loss: 0.215045]\n",
            "[Epoch 1/2] [Batch 51/1583] [D loss: 0.566050] [G loss: 0.208193]\n",
            "[Epoch 1/2] [Batch 52/1583] [D loss: 0.593328] [G loss: 0.209797]\n",
            "[Epoch 1/2] [Batch 53/1583] [D loss: 0.574104] [G loss: 0.213622]\n",
            "[Epoch 1/2] [Batch 54/1583] [D loss: 0.615932] [G loss: 0.216124]\n",
            "[Epoch 1/2] [Batch 55/1583] [D loss: 0.569484] [G loss: 0.216826]\n",
            "[Epoch 1/2] [Batch 56/1583] [D loss: 0.565672] [G loss: 0.211049]\n",
            "[Epoch 1/2] [Batch 57/1583] [D loss: 0.547353] [G loss: 0.201372]\n",
            "[Epoch 1/2] [Batch 58/1583] [D loss: 0.611858] [G loss: 0.224565]\n",
            "[Epoch 1/2] [Batch 59/1583] [D loss: 0.530882] [G loss: 0.213009]\n",
            "[Epoch 1/2] [Batch 60/1583] [D loss: 0.570199] [G loss: 0.210382]\n",
            "[Epoch 1/2] [Batch 61/1583] [D loss: 0.589600] [G loss: 0.225733]\n",
            "[Epoch 1/2] [Batch 62/1583] [D loss: 0.615918] [G loss: 0.216078]\n",
            "[Epoch 1/2] [Batch 63/1583] [D loss: 0.552269] [G loss: 0.217229]\n",
            "[Epoch 1/2] [Batch 64/1583] [D loss: 0.567737] [G loss: 0.208154]\n",
            "[Epoch 1/2] [Batch 65/1583] [D loss: 0.560005] [G loss: 0.211596]\n",
            "[Epoch 1/2] [Batch 66/1583] [D loss: 0.531372] [G loss: 0.205969]\n",
            "[Epoch 1/2] [Batch 67/1583] [D loss: 0.561174] [G loss: 0.213504]\n",
            "[Epoch 1/2] [Batch 68/1583] [D loss: 0.573198] [G loss: 0.211615]\n",
            "[Epoch 1/2] [Batch 69/1583] [D loss: 0.580462] [G loss: 0.210487]\n",
            "[Epoch 1/2] [Batch 70/1583] [D loss: 0.578780] [G loss: 0.207620]\n",
            "[Epoch 1/2] [Batch 71/1583] [D loss: 0.541586] [G loss: 0.209877]\n",
            "[Epoch 1/2] [Batch 72/1583] [D loss: 0.548236] [G loss: 0.208408]\n",
            "[Epoch 1/2] [Batch 73/1583] [D loss: 0.588163] [G loss: 0.210504]\n",
            "[Epoch 1/2] [Batch 74/1583] [D loss: 0.549842] [G loss: 0.219964]\n",
            "[Epoch 1/2] [Batch 75/1583] [D loss: 0.567117] [G loss: 0.204612]\n",
            "[Epoch 1/2] [Batch 76/1583] [D loss: 0.578039] [G loss: 0.208014]\n",
            "[Epoch 1/2] [Batch 77/1583] [D loss: 0.551418] [G loss: 0.209832]\n",
            "[Epoch 1/2] [Batch 78/1583] [D loss: 0.570988] [G loss: 0.215751]\n",
            "[Epoch 1/2] [Batch 79/1583] [D loss: 0.562084] [G loss: 0.215473]\n",
            "[Epoch 1/2] [Batch 80/1583] [D loss: 0.553290] [G loss: 0.213819]\n",
            "[Epoch 1/2] [Batch 81/1583] [D loss: 0.530457] [G loss: 0.213608]\n",
            "[Epoch 1/2] [Batch 82/1583] [D loss: 0.577392] [G loss: 0.200221]\n",
            "[Epoch 1/2] [Batch 83/1583] [D loss: 0.603736] [G loss: 0.212884]\n",
            "[Epoch 1/2] [Batch 84/1583] [D loss: 0.544853] [G loss: 0.208973]\n",
            "[Epoch 1/2] [Batch 85/1583] [D loss: 0.566617] [G loss: 0.209111]\n",
            "[Epoch 1/2] [Batch 86/1583] [D loss: 0.602845] [G loss: 0.218315]\n",
            "[Epoch 1/2] [Batch 87/1583] [D loss: 0.579872] [G loss: 0.208943]\n",
            "[Epoch 1/2] [Batch 88/1583] [D loss: 0.539138] [G loss: 0.209747]\n",
            "[Epoch 1/2] [Batch 89/1583] [D loss: 0.587810] [G loss: 0.212117]\n",
            "[Epoch 1/2] [Batch 90/1583] [D loss: 0.536228] [G loss: 0.204329]\n",
            "[Epoch 1/2] [Batch 91/1583] [D loss: 0.557548] [G loss: 0.209448]\n",
            "[Epoch 1/2] [Batch 92/1583] [D loss: 0.638418] [G loss: 0.212799]\n",
            "[Epoch 1/2] [Batch 93/1583] [D loss: 0.565541] [G loss: 0.207310]\n",
            "[Epoch 1/2] [Batch 94/1583] [D loss: 0.548386] [G loss: 0.210961]\n",
            "[Epoch 1/2] [Batch 95/1583] [D loss: 0.563215] [G loss: 0.212294]\n",
            "[Epoch 1/2] [Batch 96/1583] [D loss: 0.586858] [G loss: 0.218849]\n",
            "[Epoch 1/2] [Batch 97/1583] [D loss: 0.579294] [G loss: 0.213970]\n",
            "[Epoch 1/2] [Batch 98/1583] [D loss: 0.569393] [G loss: 0.213361]\n",
            "[Epoch 1/2] [Batch 99/1583] [D loss: 0.534498] [G loss: 0.201846]\n",
            "[Epoch 1/2] [Batch 100/1583] [D loss: 0.600806] [G loss: 0.209159]\n",
            "[Epoch 1/2] [Batch 101/1583] [D loss: 0.611155] [G loss: 0.217499]\n",
            "[Epoch 1/2] [Batch 102/1583] [D loss: 0.547300] [G loss: 0.211688]\n",
            "[Epoch 1/2] [Batch 103/1583] [D loss: 0.571367] [G loss: 0.216044]\n",
            "[Epoch 1/2] [Batch 104/1583] [D loss: 0.543276] [G loss: 0.211895]\n",
            "[Epoch 1/2] [Batch 105/1583] [D loss: 0.575703] [G loss: 0.220399]\n",
            "[Epoch 1/2] [Batch 106/1583] [D loss: 0.563454] [G loss: 0.205355]\n",
            "[Epoch 1/2] [Batch 107/1583] [D loss: 0.595322] [G loss: 0.217406]\n",
            "[Epoch 1/2] [Batch 108/1583] [D loss: 0.557921] [G loss: 0.213838]\n",
            "[Epoch 1/2] [Batch 109/1583] [D loss: 0.566049] [G loss: 0.212853]\n",
            "[Epoch 1/2] [Batch 110/1583] [D loss: 0.608241] [G loss: 0.215410]\n",
            "[Epoch 1/2] [Batch 111/1583] [D loss: 0.539208] [G loss: 0.204493]\n",
            "[Epoch 1/2] [Batch 112/1583] [D loss: 0.593791] [G loss: 0.215161]\n",
            "[Epoch 1/2] [Batch 113/1583] [D loss: 0.595743] [G loss: 0.216223]\n",
            "[Epoch 1/2] [Batch 114/1583] [D loss: 0.627001] [G loss: 0.224278]\n",
            "[Epoch 1/2] [Batch 115/1583] [D loss: 0.566488] [G loss: 0.216231]\n",
            "[Epoch 1/2] [Batch 116/1583] [D loss: 0.575835] [G loss: 0.218788]\n",
            "[Epoch 1/2] [Batch 117/1583] [D loss: 0.587162] [G loss: 0.214038]\n",
            "[Epoch 1/2] [Batch 118/1583] [D loss: 0.560047] [G loss: 0.212614]\n",
            "[Epoch 1/2] [Batch 119/1583] [D loss: 0.564231] [G loss: 0.212990]\n",
            "[Epoch 1/2] [Batch 120/1583] [D loss: 0.563873] [G loss: 0.214897]\n",
            "[Epoch 1/2] [Batch 121/1583] [D loss: 0.560527] [G loss: 0.212358]\n",
            "[Epoch 1/2] [Batch 122/1583] [D loss: 0.552968] [G loss: 0.217890]\n",
            "[Epoch 1/2] [Batch 123/1583] [D loss: 0.552601] [G loss: 0.214210]\n",
            "[Epoch 1/2] [Batch 124/1583] [D loss: 0.572594] [G loss: 0.226158]\n",
            "[Epoch 1/2] [Batch 125/1583] [D loss: 0.530179] [G loss: 0.205088]\n",
            "[Epoch 1/2] [Batch 126/1583] [D loss: 0.569429] [G loss: 0.208971]\n",
            "[Epoch 1/2] [Batch 127/1583] [D loss: 0.607786] [G loss: 0.212008]\n",
            "[Epoch 1/2] [Batch 128/1583] [D loss: 0.555251] [G loss: 0.212425]\n",
            "[Epoch 1/2] [Batch 129/1583] [D loss: 0.573178] [G loss: 0.215859]\n",
            "[Epoch 1/2] [Batch 130/1583] [D loss: 0.577783] [G loss: 0.209774]\n",
            "[Epoch 1/2] [Batch 131/1583] [D loss: 0.575631] [G loss: 0.209976]\n",
            "[Epoch 1/2] [Batch 132/1583] [D loss: 0.584978] [G loss: 0.209430]\n",
            "[Epoch 1/2] [Batch 133/1583] [D loss: 0.536987] [G loss: 0.206697]\n",
            "[Epoch 1/2] [Batch 134/1583] [D loss: 0.550452] [G loss: 0.205062]\n",
            "[Epoch 1/2] [Batch 135/1583] [D loss: 0.561528] [G loss: 0.206509]\n",
            "[Epoch 1/2] [Batch 136/1583] [D loss: 0.590578] [G loss: 0.210409]\n",
            "[Epoch 1/2] [Batch 137/1583] [D loss: 0.557330] [G loss: 0.212741]\n",
            "[Epoch 1/2] [Batch 138/1583] [D loss: 0.549938] [G loss: 0.211883]\n",
            "[Epoch 1/2] [Batch 139/1583] [D loss: 0.585486] [G loss: 0.214242]\n",
            "[Epoch 1/2] [Batch 140/1583] [D loss: 0.567700] [G loss: 0.215949]\n",
            "[Epoch 1/2] [Batch 141/1583] [D loss: 0.539565] [G loss: 0.210888]\n",
            "[Epoch 1/2] [Batch 142/1583] [D loss: 0.571536] [G loss: 0.213054]\n",
            "[Epoch 1/2] [Batch 143/1583] [D loss: 0.554839] [G loss: 0.211027]\n",
            "[Epoch 1/2] [Batch 144/1583] [D loss: 0.537544] [G loss: 0.207962]\n",
            "[Epoch 1/2] [Batch 145/1583] [D loss: 0.537397] [G loss: 0.204169]\n",
            "[Epoch 1/2] [Batch 146/1583] [D loss: 0.600939] [G loss: 0.214208]\n",
            "[Epoch 1/2] [Batch 147/1583] [D loss: 0.621311] [G loss: 0.213381]\n",
            "[Epoch 1/2] [Batch 148/1583] [D loss: 0.612372] [G loss: 0.214137]\n",
            "[Epoch 1/2] [Batch 149/1583] [D loss: 0.586644] [G loss: 0.208415]\n",
            "[Epoch 1/2] [Batch 150/1583] [D loss: 0.595470] [G loss: 0.212147]\n",
            "[Epoch 1/2] [Batch 151/1583] [D loss: 0.569908] [G loss: 0.225978]\n",
            "[Epoch 1/2] [Batch 152/1583] [D loss: 0.637539] [G loss: 0.216142]\n",
            "[Epoch 1/2] [Batch 153/1583] [D loss: 0.575123] [G loss: 0.211409]\n",
            "[Epoch 1/2] [Batch 154/1583] [D loss: 0.572464] [G loss: 0.202740]\n",
            "[Epoch 1/2] [Batch 155/1583] [D loss: 0.543021] [G loss: 0.210743]\n",
            "[Epoch 1/2] [Batch 156/1583] [D loss: 0.589445] [G loss: 0.216974]\n",
            "[Epoch 1/2] [Batch 157/1583] [D loss: 0.571506] [G loss: 0.208861]\n",
            "[Epoch 1/2] [Batch 158/1583] [D loss: 0.585117] [G loss: 0.206613]\n",
            "[Epoch 1/2] [Batch 159/1583] [D loss: 0.560960] [G loss: 0.218676]\n",
            "[Epoch 1/2] [Batch 160/1583] [D loss: 0.571647] [G loss: 0.205262]\n",
            "[Epoch 1/2] [Batch 161/1583] [D loss: 0.549162] [G loss: 0.207848]\n",
            "[Epoch 1/2] [Batch 162/1583] [D loss: 0.563214] [G loss: 0.216799]\n",
            "[Epoch 1/2] [Batch 163/1583] [D loss: 0.568752] [G loss: 0.209241]\n",
            "[Epoch 1/2] [Batch 164/1583] [D loss: 0.529573] [G loss: 0.204211]\n",
            "[Epoch 1/2] [Batch 165/1583] [D loss: 0.599680] [G loss: 0.217936]\n",
            "[Epoch 1/2] [Batch 166/1583] [D loss: 0.564822] [G loss: 0.220941]\n",
            "[Epoch 1/2] [Batch 167/1583] [D loss: 0.544577] [G loss: 0.219902]\n",
            "[Epoch 1/2] [Batch 168/1583] [D loss: 0.567753] [G loss: 0.220357]\n",
            "[Epoch 1/2] [Batch 169/1583] [D loss: 0.584531] [G loss: 0.211142]\n",
            "[Epoch 1/2] [Batch 170/1583] [D loss: 0.554629] [G loss: 0.212092]\n",
            "[Epoch 1/2] [Batch 171/1583] [D loss: 0.565614] [G loss: 0.216470]\n",
            "[Epoch 1/2] [Batch 172/1583] [D loss: 0.561186] [G loss: 0.216420]\n",
            "[Epoch 1/2] [Batch 173/1583] [D loss: 0.565393] [G loss: 0.207601]\n",
            "[Epoch 1/2] [Batch 174/1583] [D loss: 0.559821] [G loss: 0.212882]\n",
            "[Epoch 1/2] [Batch 175/1583] [D loss: 0.587051] [G loss: 0.203154]\n",
            "[Epoch 1/2] [Batch 176/1583] [D loss: 0.590603] [G loss: 0.213804]\n",
            "[Epoch 1/2] [Batch 177/1583] [D loss: 0.595910] [G loss: 0.213509]\n",
            "[Epoch 1/2] [Batch 178/1583] [D loss: 0.562368] [G loss: 0.207668]\n",
            "[Epoch 1/2] [Batch 179/1583] [D loss: 0.582179] [G loss: 0.212434]\n",
            "[Epoch 1/2] [Batch 180/1583] [D loss: 0.564894] [G loss: 0.225745]\n",
            "[Epoch 1/2] [Batch 181/1583] [D loss: 0.616639] [G loss: 0.210365]\n",
            "[Epoch 1/2] [Batch 182/1583] [D loss: 0.574064] [G loss: 0.216382]\n",
            "[Epoch 1/2] [Batch 183/1583] [D loss: 0.594815] [G loss: 0.210989]\n",
            "[Epoch 1/2] [Batch 184/1583] [D loss: 0.596888] [G loss: 0.213892]\n",
            "[Epoch 1/2] [Batch 185/1583] [D loss: 0.564631] [G loss: 0.214407]\n",
            "[Epoch 1/2] [Batch 186/1583] [D loss: 0.561731] [G loss: 0.209800]\n",
            "[Epoch 1/2] [Batch 187/1583] [D loss: 0.560666] [G loss: 0.210785]\n",
            "[Epoch 1/2] [Batch 188/1583] [D loss: 0.570042] [G loss: 0.208630]\n",
            "[Epoch 1/2] [Batch 189/1583] [D loss: 0.581180] [G loss: 0.204230]\n",
            "[Epoch 1/2] [Batch 190/1583] [D loss: 0.613791] [G loss: 0.207517]\n",
            "[Epoch 1/2] [Batch 191/1583] [D loss: 0.554483] [G loss: 0.211912]\n",
            "[Epoch 1/2] [Batch 192/1583] [D loss: 0.573525] [G loss: 0.208369]\n",
            "[Epoch 1/2] [Batch 193/1583] [D loss: 0.545698] [G loss: 0.202343]\n",
            "[Epoch 1/2] [Batch 194/1583] [D loss: 0.567833] [G loss: 0.206684]\n",
            "[Epoch 1/2] [Batch 195/1583] [D loss: 0.589817] [G loss: 0.209010]\n",
            "[Epoch 1/2] [Batch 196/1583] [D loss: 0.660093] [G loss: 0.218083]\n",
            "[Epoch 1/2] [Batch 197/1583] [D loss: 0.590119] [G loss: 0.213461]\n",
            "[Epoch 1/2] [Batch 198/1583] [D loss: 0.571098] [G loss: 0.215399]\n",
            "[Epoch 1/2] [Batch 199/1583] [D loss: 0.547312] [G loss: 0.215978]\n",
            "[Epoch 1/2] [Batch 200/1583] [D loss: 0.573236] [G loss: 0.207803]\n",
            "[Epoch 1/2] [Batch 201/1583] [D loss: 0.564613] [G loss: 0.217011]\n",
            "[Epoch 1/2] [Batch 202/1583] [D loss: 0.517587] [G loss: 0.207398]\n",
            "[Epoch 1/2] [Batch 203/1583] [D loss: 0.599192] [G loss: 0.215058]\n",
            "[Epoch 1/2] [Batch 204/1583] [D loss: 0.571120] [G loss: 0.211567]\n",
            "[Epoch 1/2] [Batch 205/1583] [D loss: 0.588415] [G loss: 0.212456]\n",
            "[Epoch 1/2] [Batch 206/1583] [D loss: 0.582548] [G loss: 0.216838]\n",
            "[Epoch 1/2] [Batch 207/1583] [D loss: 0.567861] [G loss: 0.217666]\n",
            "[Epoch 1/2] [Batch 208/1583] [D loss: 0.555829] [G loss: 0.213109]\n",
            "[Epoch 1/2] [Batch 209/1583] [D loss: 0.606809] [G loss: 0.222182]\n",
            "[Epoch 1/2] [Batch 210/1583] [D loss: 0.525915] [G loss: 0.206499]\n",
            "[Epoch 1/2] [Batch 211/1583] [D loss: 0.546814] [G loss: 0.208645]\n",
            "[Epoch 1/2] [Batch 212/1583] [D loss: 0.565311] [G loss: 0.211737]\n",
            "[Epoch 1/2] [Batch 213/1583] [D loss: 0.580741] [G loss: 0.207402]\n",
            "[Epoch 1/2] [Batch 214/1583] [D loss: 0.561495] [G loss: 0.213641]\n",
            "[Epoch 1/2] [Batch 215/1583] [D loss: 0.562488] [G loss: 0.207931]\n",
            "[Epoch 1/2] [Batch 216/1583] [D loss: 0.586069] [G loss: 0.215400]\n",
            "[Epoch 1/2] [Batch 217/1583] [D loss: 0.512464] [G loss: 0.211057]\n",
            "[Epoch 1/2] [Batch 218/1583] [D loss: 0.544995] [G loss: 0.205141]\n",
            "[Epoch 1/2] [Batch 219/1583] [D loss: 0.586601] [G loss: 0.216023]\n",
            "[Epoch 1/2] [Batch 220/1583] [D loss: 0.566588] [G loss: 0.218922]\n",
            "[Epoch 1/2] [Batch 221/1583] [D loss: 0.574853] [G loss: 0.217832]\n",
            "[Epoch 1/2] [Batch 222/1583] [D loss: 0.571765] [G loss: 0.202403]\n",
            "[Epoch 1/2] [Batch 223/1583] [D loss: 0.541377] [G loss: 0.208830]\n",
            "[Epoch 1/2] [Batch 224/1583] [D loss: 0.567096] [G loss: 0.209872]\n",
            "[Epoch 1/2] [Batch 225/1583] [D loss: 0.595600] [G loss: 0.207467]\n",
            "[Epoch 1/2] [Batch 226/1583] [D loss: 0.572136] [G loss: 0.214163]\n",
            "[Epoch 1/2] [Batch 227/1583] [D loss: 0.510261] [G loss: 0.212818]\n",
            "[Epoch 1/2] [Batch 228/1583] [D loss: 0.577905] [G loss: 0.224092]\n",
            "[Epoch 1/2] [Batch 229/1583] [D loss: 0.569417] [G loss: 0.216260]\n",
            "[Epoch 1/2] [Batch 230/1583] [D loss: 0.575059] [G loss: 0.216904]\n",
            "[Epoch 1/2] [Batch 231/1583] [D loss: 0.616131] [G loss: 0.210204]\n",
            "[Epoch 1/2] [Batch 232/1583] [D loss: 0.604679] [G loss: 0.221142]\n",
            "[Epoch 1/2] [Batch 233/1583] [D loss: 0.531434] [G loss: 0.215500]\n",
            "[Epoch 1/2] [Batch 234/1583] [D loss: 0.558018] [G loss: 0.206932]\n",
            "[Epoch 1/2] [Batch 235/1583] [D loss: 0.533500] [G loss: 0.211888]\n",
            "[Epoch 1/2] [Batch 236/1583] [D loss: 0.573338] [G loss: 0.219234]\n",
            "[Epoch 1/2] [Batch 237/1583] [D loss: 0.609047] [G loss: 0.226019]\n",
            "[Epoch 1/2] [Batch 238/1583] [D loss: 0.586855] [G loss: 0.218006]\n",
            "[Epoch 1/2] [Batch 239/1583] [D loss: 0.534788] [G loss: 0.209765]\n",
            "[Epoch 1/2] [Batch 240/1583] [D loss: 0.597974] [G loss: 0.219609]\n",
            "[Epoch 1/2] [Batch 241/1583] [D loss: 0.552068] [G loss: 0.203708]\n",
            "[Epoch 1/2] [Batch 242/1583] [D loss: 0.585340] [G loss: 0.206260]\n",
            "[Epoch 1/2] [Batch 243/1583] [D loss: 0.591522] [G loss: 0.213977]\n",
            "[Epoch 1/2] [Batch 244/1583] [D loss: 0.571503] [G loss: 0.212685]\n",
            "[Epoch 1/2] [Batch 245/1583] [D loss: 0.576089] [G loss: 0.215608]\n",
            "[Epoch 1/2] [Batch 246/1583] [D loss: 0.588906] [G loss: 0.217094]\n",
            "[Epoch 1/2] [Batch 247/1583] [D loss: 0.581894] [G loss: 0.212169]\n",
            "[Epoch 1/2] [Batch 248/1583] [D loss: 0.556994] [G loss: 0.212416]\n",
            "[Epoch 1/2] [Batch 249/1583] [D loss: 0.553655] [G loss: 0.207990]\n",
            "[Epoch 1/2] [Batch 250/1583] [D loss: 0.561087] [G loss: 0.223952]\n",
            "[Epoch 1/2] [Batch 251/1583] [D loss: 0.610143] [G loss: 0.217507]\n",
            "[Epoch 1/2] [Batch 252/1583] [D loss: 0.574282] [G loss: 0.207560]\n",
            "[Epoch 1/2] [Batch 253/1583] [D loss: 0.605384] [G loss: 0.215962]\n",
            "[Epoch 1/2] [Batch 254/1583] [D loss: 0.565162] [G loss: 0.204854]\n",
            "[Epoch 1/2] [Batch 255/1583] [D loss: 0.560400] [G loss: 0.221012]\n",
            "[Epoch 1/2] [Batch 256/1583] [D loss: 0.569819] [G loss: 0.213079]\n",
            "[Epoch 1/2] [Batch 257/1583] [D loss: 0.529688] [G loss: 0.206044]\n",
            "[Epoch 1/2] [Batch 258/1583] [D loss: 0.609095] [G loss: 0.209682]\n",
            "[Epoch 1/2] [Batch 259/1583] [D loss: 0.564336] [G loss: 0.210538]\n",
            "[Epoch 1/2] [Batch 260/1583] [D loss: 0.600516] [G loss: 0.204018]\n",
            "[Epoch 1/2] [Batch 261/1583] [D loss: 0.507855] [G loss: 0.207520]\n",
            "[Epoch 1/2] [Batch 262/1583] [D loss: 0.548940] [G loss: 0.213447]\n",
            "[Epoch 1/2] [Batch 263/1583] [D loss: 0.576911] [G loss: 0.215649]\n",
            "[Epoch 1/2] [Batch 264/1583] [D loss: 0.556811] [G loss: 0.210226]\n",
            "[Epoch 1/2] [Batch 265/1583] [D loss: 0.613512] [G loss: 0.215180]\n",
            "[Epoch 1/2] [Batch 266/1583] [D loss: 0.591028] [G loss: 0.213039]\n",
            "[Epoch 1/2] [Batch 267/1583] [D loss: 0.558563] [G loss: 0.217803]\n",
            "[Epoch 1/2] [Batch 268/1583] [D loss: 0.591936] [G loss: 0.214198]\n",
            "[Epoch 1/2] [Batch 269/1583] [D loss: 0.566594] [G loss: 0.210072]\n",
            "[Epoch 1/2] [Batch 270/1583] [D loss: 0.535163] [G loss: 0.212260]\n",
            "[Epoch 1/2] [Batch 271/1583] [D loss: 0.556330] [G loss: 0.211773]\n",
            "[Epoch 1/2] [Batch 272/1583] [D loss: 0.525889] [G loss: 0.213120]\n",
            "[Epoch 1/2] [Batch 273/1583] [D loss: 0.555096] [G loss: 0.219594]\n",
            "[Epoch 1/2] [Batch 274/1583] [D loss: 0.595526] [G loss: 0.206649]\n",
            "[Epoch 1/2] [Batch 275/1583] [D loss: 0.578252] [G loss: 0.212556]\n",
            "[Epoch 1/2] [Batch 276/1583] [D loss: 0.547620] [G loss: 0.209992]\n",
            "[Epoch 1/2] [Batch 277/1583] [D loss: 0.528617] [G loss: 0.212408]\n",
            "[Epoch 1/2] [Batch 278/1583] [D loss: 0.577401] [G loss: 0.215168]\n",
            "[Epoch 1/2] [Batch 279/1583] [D loss: 0.557474] [G loss: 0.203914]\n",
            "[Epoch 1/2] [Batch 280/1583] [D loss: 0.534869] [G loss: 0.211978]\n",
            "[Epoch 1/2] [Batch 281/1583] [D loss: 0.585877] [G loss: 0.208205]\n",
            "[Epoch 1/2] [Batch 282/1583] [D loss: 0.577952] [G loss: 0.211502]\n",
            "[Epoch 1/2] [Batch 283/1583] [D loss: 0.569559] [G loss: 0.205260]\n",
            "[Epoch 1/2] [Batch 284/1583] [D loss: 0.573802] [G loss: 0.213965]\n",
            "[Epoch 1/2] [Batch 285/1583] [D loss: 0.575776] [G loss: 0.210600]\n",
            "[Epoch 1/2] [Batch 286/1583] [D loss: 0.566607] [G loss: 0.213792]\n",
            "[Epoch 1/2] [Batch 287/1583] [D loss: 0.615467] [G loss: 0.216459]\n",
            "[Epoch 1/2] [Batch 288/1583] [D loss: 0.570904] [G loss: 0.214494]\n",
            "[Epoch 1/2] [Batch 289/1583] [D loss: 0.566322] [G loss: 0.211333]\n",
            "[Epoch 1/2] [Batch 290/1583] [D loss: 0.623110] [G loss: 0.217363]\n",
            "[Epoch 1/2] [Batch 291/1583] [D loss: 0.580035] [G loss: 0.208022]\n",
            "[Epoch 1/2] [Batch 292/1583] [D loss: 0.585881] [G loss: 0.214998]\n",
            "[Epoch 1/2] [Batch 293/1583] [D loss: 0.580726] [G loss: 0.210044]\n",
            "[Epoch 1/2] [Batch 294/1583] [D loss: 0.561835] [G loss: 0.214083]\n",
            "[Epoch 1/2] [Batch 295/1583] [D loss: 0.618418] [G loss: 0.209291]\n",
            "[Epoch 1/2] [Batch 296/1583] [D loss: 0.539044] [G loss: 0.205356]\n",
            "[Epoch 1/2] [Batch 297/1583] [D loss: 0.574754] [G loss: 0.209859]\n",
            "[Epoch 1/2] [Batch 298/1583] [D loss: 0.523168] [G loss: 0.208903]\n",
            "[Epoch 1/2] [Batch 299/1583] [D loss: 0.536239] [G loss: 0.208785]\n",
            "[Epoch 1/2] [Batch 300/1583] [D loss: 0.570048] [G loss: 0.218481]\n",
            "[Epoch 1/2] [Batch 301/1583] [D loss: 0.596570] [G loss: 0.206163]\n",
            "[Epoch 1/2] [Batch 302/1583] [D loss: 0.566879] [G loss: 0.209505]\n",
            "[Epoch 1/2] [Batch 303/1583] [D loss: 0.591192] [G loss: 0.208012]\n",
            "[Epoch 1/2] [Batch 304/1583] [D loss: 0.569386] [G loss: 0.214196]\n",
            "[Epoch 1/2] [Batch 305/1583] [D loss: 0.600382] [G loss: 0.215254]\n",
            "[Epoch 1/2] [Batch 306/1583] [D loss: 0.578664] [G loss: 0.215956]\n",
            "[Epoch 1/2] [Batch 307/1583] [D loss: 0.570920] [G loss: 0.209857]\n",
            "[Epoch 1/2] [Batch 308/1583] [D loss: 0.578024] [G loss: 0.205705]\n",
            "[Epoch 1/2] [Batch 309/1583] [D loss: 0.587328] [G loss: 0.216816]\n",
            "[Epoch 1/2] [Batch 310/1583] [D loss: 0.590975] [G loss: 0.208520]\n",
            "[Epoch 1/2] [Batch 311/1583] [D loss: 0.577371] [G loss: 0.222613]\n",
            "[Epoch 1/2] [Batch 312/1583] [D loss: 0.562005] [G loss: 0.204739]\n",
            "[Epoch 1/2] [Batch 313/1583] [D loss: 0.551972] [G loss: 0.206947]\n",
            "[Epoch 1/2] [Batch 314/1583] [D loss: 0.573616] [G loss: 0.208849]\n",
            "[Epoch 1/2] [Batch 315/1583] [D loss: 0.553380] [G loss: 0.208821]\n",
            "[Epoch 1/2] [Batch 316/1583] [D loss: 0.561055] [G loss: 0.198594]\n",
            "[Epoch 1/2] [Batch 317/1583] [D loss: 0.546374] [G loss: 0.208427]\n",
            "[Epoch 1/2] [Batch 318/1583] [D loss: 0.563955] [G loss: 0.216789]\n",
            "[Epoch 1/2] [Batch 319/1583] [D loss: 0.597178] [G loss: 0.214691]\n",
            "[Epoch 1/2] [Batch 320/1583] [D loss: 0.597448] [G loss: 0.214151]\n",
            "[Epoch 1/2] [Batch 321/1583] [D loss: 0.600652] [G loss: 0.217747]\n",
            "[Epoch 1/2] [Batch 322/1583] [D loss: 0.594549] [G loss: 0.217455]\n",
            "[Epoch 1/2] [Batch 323/1583] [D loss: 0.628874] [G loss: 0.217804]\n",
            "[Epoch 1/2] [Batch 324/1583] [D loss: 0.589005] [G loss: 0.209325]\n",
            "[Epoch 1/2] [Batch 325/1583] [D loss: 0.595673] [G loss: 0.214752]\n",
            "[Epoch 1/2] [Batch 326/1583] [D loss: 0.589777] [G loss: 0.211174]\n",
            "[Epoch 1/2] [Batch 327/1583] [D loss: 0.567658] [G loss: 0.203611]\n",
            "[Epoch 1/2] [Batch 328/1583] [D loss: 0.552652] [G loss: 0.200520]\n",
            "[Epoch 1/2] [Batch 329/1583] [D loss: 0.564560] [G loss: 0.208024]\n",
            "[Epoch 1/2] [Batch 330/1583] [D loss: 0.559375] [G loss: 0.220094]\n",
            "[Epoch 1/2] [Batch 331/1583] [D loss: 0.565019] [G loss: 0.219559]\n",
            "[Epoch 1/2] [Batch 332/1583] [D loss: 0.561634] [G loss: 0.204424]\n",
            "[Epoch 1/2] [Batch 333/1583] [D loss: 0.578071] [G loss: 0.201773]\n",
            "[Epoch 1/2] [Batch 334/1583] [D loss: 0.557056] [G loss: 0.214708]\n",
            "[Epoch 1/2] [Batch 335/1583] [D loss: 0.571265] [G loss: 0.210512]\n",
            "[Epoch 1/2] [Batch 336/1583] [D loss: 0.573720] [G loss: 0.215428]\n",
            "[Epoch 1/2] [Batch 337/1583] [D loss: 0.593233] [G loss: 0.214546]\n",
            "[Epoch 1/2] [Batch 338/1583] [D loss: 0.544582] [G loss: 0.207011]\n",
            "[Epoch 1/2] [Batch 339/1583] [D loss: 0.603521] [G loss: 0.216821]\n",
            "[Epoch 1/2] [Batch 340/1583] [D loss: 0.601915] [G loss: 0.204274]\n",
            "[Epoch 1/2] [Batch 341/1583] [D loss: 0.596274] [G loss: 0.208211]\n",
            "[Epoch 1/2] [Batch 342/1583] [D loss: 0.587097] [G loss: 0.204244]\n",
            "[Epoch 1/2] [Batch 343/1583] [D loss: 0.574973] [G loss: 0.209910]\n",
            "[Epoch 1/2] [Batch 344/1583] [D loss: 0.505128] [G loss: 0.209189]\n",
            "[Epoch 1/2] [Batch 345/1583] [D loss: 0.561905] [G loss: 0.208236]\n",
            "[Epoch 1/2] [Batch 346/1583] [D loss: 0.565786] [G loss: 0.209414]\n",
            "[Epoch 1/2] [Batch 347/1583] [D loss: 0.538321] [G loss: 0.206914]\n",
            "[Epoch 1/2] [Batch 348/1583] [D loss: 0.563000] [G loss: 0.218850]\n",
            "[Epoch 1/2] [Batch 349/1583] [D loss: 0.552166] [G loss: 0.219495]\n",
            "[Epoch 1/2] [Batch 350/1583] [D loss: 0.564572] [G loss: 0.211660]\n",
            "[Epoch 1/2] [Batch 351/1583] [D loss: 0.586294] [G loss: 0.211708]\n",
            "[Epoch 1/2] [Batch 352/1583] [D loss: 0.596134] [G loss: 0.208570]\n",
            "[Epoch 1/2] [Batch 353/1583] [D loss: 0.585336] [G loss: 0.207650]\n",
            "[Epoch 1/2] [Batch 354/1583] [D loss: 0.541521] [G loss: 0.205774]\n",
            "[Epoch 1/2] [Batch 355/1583] [D loss: 0.546686] [G loss: 0.211354]\n",
            "[Epoch 1/2] [Batch 356/1583] [D loss: 0.585642] [G loss: 0.217215]\n",
            "[Epoch 1/2] [Batch 357/1583] [D loss: 0.589246] [G loss: 0.212974]\n",
            "[Epoch 1/2] [Batch 358/1583] [D loss: 0.560985] [G loss: 0.213274]\n",
            "[Epoch 1/2] [Batch 359/1583] [D loss: 0.566855] [G loss: 0.212153]\n",
            "[Epoch 1/2] [Batch 360/1583] [D loss: 0.550748] [G loss: 0.212664]\n",
            "[Epoch 1/2] [Batch 361/1583] [D loss: 0.621149] [G loss: 0.221043]\n",
            "[Epoch 1/2] [Batch 362/1583] [D loss: 0.554441] [G loss: 0.216846]\n",
            "[Epoch 1/2] [Batch 363/1583] [D loss: 0.614173] [G loss: 0.218570]\n",
            "[Epoch 1/2] [Batch 364/1583] [D loss: 0.599765] [G loss: 0.213110]\n",
            "[Epoch 1/2] [Batch 365/1583] [D loss: 0.596666] [G loss: 0.212765]\n",
            "[Epoch 1/2] [Batch 366/1583] [D loss: 0.608783] [G loss: 0.202545]\n",
            "[Epoch 1/2] [Batch 367/1583] [D loss: 0.573175] [G loss: 0.206651]\n",
            "[Epoch 1/2] [Batch 368/1583] [D loss: 0.567982] [G loss: 0.206267]\n",
            "[Epoch 1/2] [Batch 369/1583] [D loss: 0.576007] [G loss: 0.210913]\n",
            "[Epoch 1/2] [Batch 370/1583] [D loss: 0.539940] [G loss: 0.203715]\n",
            "[Epoch 1/2] [Batch 371/1583] [D loss: 0.579219] [G loss: 0.215424]\n",
            "[Epoch 1/2] [Batch 372/1583] [D loss: 0.536384] [G loss: 0.208992]\n",
            "[Epoch 1/2] [Batch 373/1583] [D loss: 0.572122] [G loss: 0.213242]\n",
            "[Epoch 1/2] [Batch 374/1583] [D loss: 0.556210] [G loss: 0.202697]\n",
            "[Epoch 1/2] [Batch 375/1583] [D loss: 0.604128] [G loss: 0.219822]\n",
            "[Epoch 1/2] [Batch 376/1583] [D loss: 0.559737] [G loss: 0.206081]\n",
            "[Epoch 1/2] [Batch 377/1583] [D loss: 0.535852] [G loss: 0.210484]\n",
            "[Epoch 1/2] [Batch 378/1583] [D loss: 0.547459] [G loss: 0.216314]\n",
            "[Epoch 1/2] [Batch 379/1583] [D loss: 0.569323] [G loss: 0.220589]\n",
            "[Epoch 1/2] [Batch 380/1583] [D loss: 0.600688] [G loss: 0.215774]\n",
            "[Epoch 1/2] [Batch 381/1583] [D loss: 0.557693] [G loss: 0.208858]\n",
            "[Epoch 1/2] [Batch 382/1583] [D loss: 0.570089] [G loss: 0.207341]\n",
            "[Epoch 1/2] [Batch 383/1583] [D loss: 0.544369] [G loss: 0.214729]\n",
            "[Epoch 1/2] [Batch 384/1583] [D loss: 0.541637] [G loss: 0.208934]\n",
            "[Epoch 1/2] [Batch 385/1583] [D loss: 0.569587] [G loss: 0.207784]\n",
            "[Epoch 1/2] [Batch 386/1583] [D loss: 0.566536] [G loss: 0.199351]\n",
            "[Epoch 1/2] [Batch 387/1583] [D loss: 0.567642] [G loss: 0.207378]\n",
            "[Epoch 1/2] [Batch 388/1583] [D loss: 0.594510] [G loss: 0.220319]\n",
            "[Epoch 1/2] [Batch 389/1583] [D loss: 0.588146] [G loss: 0.212873]\n",
            "[Epoch 1/2] [Batch 390/1583] [D loss: 0.530917] [G loss: 0.209942]\n",
            "[Epoch 1/2] [Batch 391/1583] [D loss: 0.565427] [G loss: 0.211168]\n",
            "[Epoch 1/2] [Batch 392/1583] [D loss: 0.579764] [G loss: 0.209218]\n",
            "[Epoch 1/2] [Batch 393/1583] [D loss: 0.578815] [G loss: 0.213587]\n",
            "[Epoch 1/2] [Batch 394/1583] [D loss: 0.579018] [G loss: 0.217955]\n",
            "[Epoch 1/2] [Batch 395/1583] [D loss: 0.575543] [G loss: 0.218131]\n",
            "[Epoch 1/2] [Batch 396/1583] [D loss: 0.551635] [G loss: 0.219226]\n",
            "[Epoch 1/2] [Batch 397/1583] [D loss: 0.547694] [G loss: 0.219783]\n",
            "[Epoch 1/2] [Batch 398/1583] [D loss: 0.597171] [G loss: 0.214797]\n",
            "[Epoch 1/2] [Batch 399/1583] [D loss: 0.548690] [G loss: 0.212255]\n",
            "[Epoch 1/2] [Batch 400/1583] [D loss: 0.554730] [G loss: 0.216604]\n",
            "[Epoch 1/2] [Batch 401/1583] [D loss: 0.550088] [G loss: 0.209461]\n",
            "[Epoch 1/2] [Batch 402/1583] [D loss: 0.576465] [G loss: 0.210634]\n",
            "[Epoch 1/2] [Batch 403/1583] [D loss: 0.532035] [G loss: 0.208107]\n",
            "[Epoch 1/2] [Batch 404/1583] [D loss: 0.539476] [G loss: 0.207061]\n",
            "[Epoch 1/2] [Batch 405/1583] [D loss: 0.548794] [G loss: 0.211048]\n",
            "[Epoch 1/2] [Batch 406/1583] [D loss: 0.575556] [G loss: 0.212146]\n",
            "[Epoch 1/2] [Batch 407/1583] [D loss: 0.527464] [G loss: 0.204211]\n",
            "[Epoch 1/2] [Batch 408/1583] [D loss: 0.608604] [G loss: 0.208787]\n",
            "[Epoch 1/2] [Batch 409/1583] [D loss: 0.601632] [G loss: 0.213280]\n",
            "[Epoch 1/2] [Batch 410/1583] [D loss: 0.546976] [G loss: 0.200864]\n",
            "[Epoch 1/2] [Batch 411/1583] [D loss: 0.544284] [G loss: 0.200998]\n",
            "[Epoch 1/2] [Batch 412/1583] [D loss: 0.583386] [G loss: 0.207356]\n",
            "[Epoch 1/2] [Batch 413/1583] [D loss: 0.545695] [G loss: 0.207030]\n",
            "[Epoch 1/2] [Batch 414/1583] [D loss: 0.573242] [G loss: 0.211780]\n",
            "[Epoch 1/2] [Batch 415/1583] [D loss: 0.561788] [G loss: 0.211266]\n",
            "[Epoch 1/2] [Batch 416/1583] [D loss: 0.597474] [G loss: 0.221932]\n",
            "[Epoch 1/2] [Batch 417/1583] [D loss: 0.545115] [G loss: 0.214368]\n",
            "[Epoch 1/2] [Batch 418/1583] [D loss: 0.563864] [G loss: 0.216361]\n",
            "[Epoch 1/2] [Batch 419/1583] [D loss: 0.566624] [G loss: 0.219308]\n",
            "[Epoch 1/2] [Batch 420/1583] [D loss: 0.613355] [G loss: 0.209116]\n",
            "[Epoch 1/2] [Batch 421/1583] [D loss: 0.555649] [G loss: 0.211615]\n",
            "[Epoch 1/2] [Batch 422/1583] [D loss: 0.572137] [G loss: 0.206614]\n",
            "[Epoch 1/2] [Batch 423/1583] [D loss: 0.580360] [G loss: 0.216321]\n",
            "[Epoch 1/2] [Batch 424/1583] [D loss: 0.575890] [G loss: 0.210749]\n",
            "[Epoch 1/2] [Batch 425/1583] [D loss: 0.615877] [G loss: 0.208194]\n",
            "[Epoch 1/2] [Batch 426/1583] [D loss: 0.558897] [G loss: 0.209551]\n",
            "[Epoch 1/2] [Batch 427/1583] [D loss: 0.565611] [G loss: 0.197988]\n",
            "[Epoch 1/2] [Batch 428/1583] [D loss: 0.562388] [G loss: 0.218784]\n",
            "[Epoch 1/2] [Batch 429/1583] [D loss: 0.609108] [G loss: 0.205321]\n",
            "[Epoch 1/2] [Batch 430/1583] [D loss: 0.561000] [G loss: 0.212653]\n",
            "[Epoch 1/2] [Batch 431/1583] [D loss: 0.578810] [G loss: 0.212264]\n",
            "[Epoch 1/2] [Batch 432/1583] [D loss: 0.552869] [G loss: 0.208534]\n",
            "[Epoch 1/2] [Batch 433/1583] [D loss: 0.560436] [G loss: 0.209013]\n",
            "[Epoch 1/2] [Batch 434/1583] [D loss: 0.586750] [G loss: 0.211728]\n",
            "[Epoch 1/2] [Batch 435/1583] [D loss: 0.582590] [G loss: 0.212901]\n",
            "[Epoch 1/2] [Batch 436/1583] [D loss: 0.566858] [G loss: 0.207776]\n",
            "[Epoch 1/2] [Batch 437/1583] [D loss: 0.539171] [G loss: 0.213531]\n",
            "[Epoch 1/2] [Batch 438/1583] [D loss: 0.531859] [G loss: 0.208495]\n",
            "[Epoch 1/2] [Batch 439/1583] [D loss: 0.592130] [G loss: 0.210824]\n",
            "[Epoch 1/2] [Batch 440/1583] [D loss: 0.586603] [G loss: 0.210792]\n",
            "[Epoch 1/2] [Batch 441/1583] [D loss: 0.558705] [G loss: 0.214014]\n",
            "[Epoch 1/2] [Batch 442/1583] [D loss: 0.580902] [G loss: 0.206837]\n",
            "[Epoch 1/2] [Batch 443/1583] [D loss: 0.549706] [G loss: 0.222804]\n",
            "[Epoch 1/2] [Batch 444/1583] [D loss: 0.567021] [G loss: 0.208812]\n",
            "[Epoch 1/2] [Batch 445/1583] [D loss: 0.578945] [G loss: 0.217803]\n",
            "[Epoch 1/2] [Batch 446/1583] [D loss: 0.583661] [G loss: 0.216044]\n",
            "[Epoch 1/2] [Batch 447/1583] [D loss: 0.565117] [G loss: 0.215936]\n",
            "[Epoch 1/2] [Batch 448/1583] [D loss: 0.592977] [G loss: 0.219499]\n",
            "[Epoch 1/2] [Batch 449/1583] [D loss: 0.570891] [G loss: 0.205035]\n",
            "[Epoch 1/2] [Batch 450/1583] [D loss: 0.594876] [G loss: 0.217499]\n",
            "[Epoch 1/2] [Batch 451/1583] [D loss: 0.567118] [G loss: 0.205592]\n",
            "[Epoch 1/2] [Batch 452/1583] [D loss: 0.540887] [G loss: 0.221643]\n",
            "[Epoch 1/2] [Batch 453/1583] [D loss: 0.521458] [G loss: 0.213577]\n",
            "[Epoch 1/2] [Batch 454/1583] [D loss: 0.587629] [G loss: 0.208801]\n",
            "[Epoch 1/2] [Batch 455/1583] [D loss: 0.605752] [G loss: 0.222905]\n",
            "[Epoch 1/2] [Batch 456/1583] [D loss: 0.605921] [G loss: 0.220832]\n",
            "[Epoch 1/2] [Batch 457/1583] [D loss: 0.605986] [G loss: 0.202798]\n",
            "[Epoch 1/2] [Batch 458/1583] [D loss: 0.576713] [G loss: 0.217374]\n",
            "[Epoch 1/2] [Batch 459/1583] [D loss: 0.547117] [G loss: 0.214529]\n",
            "[Epoch 1/2] [Batch 460/1583] [D loss: 0.574555] [G loss: 0.203203]\n",
            "[Epoch 1/2] [Batch 461/1583] [D loss: 0.525795] [G loss: 0.211343]\n",
            "[Epoch 1/2] [Batch 462/1583] [D loss: 0.562042] [G loss: 0.212822]\n",
            "[Epoch 1/2] [Batch 463/1583] [D loss: 0.519186] [G loss: 0.214774]\n",
            "[Epoch 1/2] [Batch 464/1583] [D loss: 0.553737] [G loss: 0.212754]\n",
            "[Epoch 1/2] [Batch 465/1583] [D loss: 0.571866] [G loss: 0.214491]\n",
            "[Epoch 1/2] [Batch 466/1583] [D loss: 0.547130] [G loss: 0.208200]\n",
            "[Epoch 1/2] [Batch 467/1583] [D loss: 0.582963] [G loss: 0.215037]\n",
            "[Epoch 1/2] [Batch 468/1583] [D loss: 0.547890] [G loss: 0.212275]\n",
            "[Epoch 1/2] [Batch 469/1583] [D loss: 0.526773] [G loss: 0.204975]\n",
            "[Epoch 1/2] [Batch 470/1583] [D loss: 0.581988] [G loss: 0.215890]\n",
            "[Epoch 1/2] [Batch 471/1583] [D loss: 0.573702] [G loss: 0.209445]\n",
            "[Epoch 1/2] [Batch 472/1583] [D loss: 0.581487] [G loss: 0.218489]\n",
            "[Epoch 1/2] [Batch 473/1583] [D loss: 0.566312] [G loss: 0.209876]\n",
            "[Epoch 1/2] [Batch 474/1583] [D loss: 0.596975] [G loss: 0.209992]\n",
            "[Epoch 1/2] [Batch 475/1583] [D loss: 0.517449] [G loss: 0.209811]\n",
            "[Epoch 1/2] [Batch 476/1583] [D loss: 0.599609] [G loss: 0.219201]\n",
            "[Epoch 1/2] [Batch 477/1583] [D loss: 0.585826] [G loss: 0.214505]\n",
            "[Epoch 1/2] [Batch 478/1583] [D loss: 0.570216] [G loss: 0.210609]\n",
            "[Epoch 1/2] [Batch 479/1583] [D loss: 0.546081] [G loss: 0.202078]\n",
            "[Epoch 1/2] [Batch 480/1583] [D loss: 0.593118] [G loss: 0.209669]\n",
            "[Epoch 1/2] [Batch 481/1583] [D loss: 0.568422] [G loss: 0.212047]\n",
            "[Epoch 1/2] [Batch 482/1583] [D loss: 0.553427] [G loss: 0.209995]\n",
            "[Epoch 1/2] [Batch 483/1583] [D loss: 0.588410] [G loss: 0.218101]\n",
            "[Epoch 1/2] [Batch 484/1583] [D loss: 0.573947] [G loss: 0.214027]\n",
            "[Epoch 1/2] [Batch 485/1583] [D loss: 0.558008] [G loss: 0.206441]\n",
            "[Epoch 1/2] [Batch 486/1583] [D loss: 0.568736] [G loss: 0.208294]\n",
            "[Epoch 1/2] [Batch 487/1583] [D loss: 0.520404] [G loss: 0.220576]\n",
            "[Epoch 1/2] [Batch 488/1583] [D loss: 0.557017] [G loss: 0.210893]\n",
            "[Epoch 1/2] [Batch 489/1583] [D loss: 0.579153] [G loss: 0.207498]\n",
            "[Epoch 1/2] [Batch 490/1583] [D loss: 0.553037] [G loss: 0.208171]\n",
            "[Epoch 1/2] [Batch 491/1583] [D loss: 0.525073] [G loss: 0.205321]\n",
            "[Epoch 1/2] [Batch 492/1583] [D loss: 0.576370] [G loss: 0.203272]\n",
            "[Epoch 1/2] [Batch 493/1583] [D loss: 0.596515] [G loss: 0.212224]\n",
            "[Epoch 1/2] [Batch 494/1583] [D loss: 0.536973] [G loss: 0.204315]\n",
            "[Epoch 1/2] [Batch 495/1583] [D loss: 0.581699] [G loss: 0.217003]\n",
            "[Epoch 1/2] [Batch 496/1583] [D loss: 0.565437] [G loss: 0.211008]\n",
            "[Epoch 1/2] [Batch 497/1583] [D loss: 0.591039] [G loss: 0.210309]\n",
            "[Epoch 1/2] [Batch 498/1583] [D loss: 0.554505] [G loss: 0.210758]\n",
            "[Epoch 1/2] [Batch 499/1583] [D loss: 0.579731] [G loss: 0.211325]\n",
            "[Epoch 1/2] [Batch 500/1583] [D loss: 0.559368] [G loss: 0.206357]\n",
            "[Epoch 1/2] [Batch 501/1583] [D loss: 0.545413] [G loss: 0.211762]\n",
            "[Epoch 1/2] [Batch 502/1583] [D loss: 0.563223] [G loss: 0.209278]\n",
            "[Epoch 1/2] [Batch 503/1583] [D loss: 0.591233] [G loss: 0.206108]\n",
            "[Epoch 1/2] [Batch 504/1583] [D loss: 0.544801] [G loss: 0.208480]\n",
            "[Epoch 1/2] [Batch 505/1583] [D loss: 0.572919] [G loss: 0.213223]\n",
            "[Epoch 1/2] [Batch 506/1583] [D loss: 0.580341] [G loss: 0.205917]\n",
            "[Epoch 1/2] [Batch 507/1583] [D loss: 0.545321] [G loss: 0.213262]\n",
            "[Epoch 1/2] [Batch 508/1583] [D loss: 0.539933] [G loss: 0.207591]\n",
            "[Epoch 1/2] [Batch 509/1583] [D loss: 0.561444] [G loss: 0.207613]\n",
            "[Epoch 1/2] [Batch 510/1583] [D loss: 0.552533] [G loss: 0.203205]\n",
            "[Epoch 1/2] [Batch 511/1583] [D loss: 0.568984] [G loss: 0.207808]\n",
            "[Epoch 1/2] [Batch 512/1583] [D loss: 0.521597] [G loss: 0.213734]\n",
            "[Epoch 1/2] [Batch 513/1583] [D loss: 0.615752] [G loss: 0.210375]\n",
            "[Epoch 1/2] [Batch 514/1583] [D loss: 0.553984] [G loss: 0.214471]\n",
            "[Epoch 1/2] [Batch 515/1583] [D loss: 0.555119] [G loss: 0.220758]\n",
            "[Epoch 1/2] [Batch 516/1583] [D loss: 0.523098] [G loss: 0.215338]\n",
            "[Epoch 1/2] [Batch 517/1583] [D loss: 0.580961] [G loss: 0.211680]\n",
            "[Epoch 1/2] [Batch 518/1583] [D loss: 0.594801] [G loss: 0.217381]\n",
            "[Epoch 1/2] [Batch 519/1583] [D loss: 0.545699] [G loss: 0.219593]\n",
            "[Epoch 1/2] [Batch 520/1583] [D loss: 0.599333] [G loss: 0.209624]\n",
            "[Epoch 1/2] [Batch 521/1583] [D loss: 0.547103] [G loss: 0.214009]\n",
            "[Epoch 1/2] [Batch 522/1583] [D loss: 0.556471] [G loss: 0.209313]\n",
            "[Epoch 1/2] [Batch 523/1583] [D loss: 0.570530] [G loss: 0.210774]\n",
            "[Epoch 1/2] [Batch 524/1583] [D loss: 0.599785] [G loss: 0.207094]\n",
            "[Epoch 1/2] [Batch 525/1583] [D loss: 0.593779] [G loss: 0.216387]\n",
            "[Epoch 1/2] [Batch 526/1583] [D loss: 0.568426] [G loss: 0.200418]\n",
            "[Epoch 1/2] [Batch 527/1583] [D loss: 0.557124] [G loss: 0.212262]\n",
            "[Epoch 1/2] [Batch 528/1583] [D loss: 0.575029] [G loss: 0.210996]\n",
            "[Epoch 1/2] [Batch 529/1583] [D loss: 0.570829] [G loss: 0.204505]\n",
            "[Epoch 1/2] [Batch 530/1583] [D loss: 0.565712] [G loss: 0.207867]\n",
            "[Epoch 1/2] [Batch 531/1583] [D loss: 0.568796] [G loss: 0.207410]\n",
            "[Epoch 1/2] [Batch 532/1583] [D loss: 0.578138] [G loss: 0.213395]\n",
            "[Epoch 1/2] [Batch 533/1583] [D loss: 0.576421] [G loss: 0.218793]\n",
            "[Epoch 1/2] [Batch 534/1583] [D loss: 0.521504] [G loss: 0.210474]\n",
            "[Epoch 1/2] [Batch 535/1583] [D loss: 0.556962] [G loss: 0.205788]\n",
            "[Epoch 1/2] [Batch 536/1583] [D loss: 0.567291] [G loss: 0.211279]\n",
            "[Epoch 1/2] [Batch 537/1583] [D loss: 0.556056] [G loss: 0.204616]\n",
            "[Epoch 1/2] [Batch 538/1583] [D loss: 0.610047] [G loss: 0.210565]\n",
            "[Epoch 1/2] [Batch 539/1583] [D loss: 0.532363] [G loss: 0.203696]\n",
            "[Epoch 1/2] [Batch 540/1583] [D loss: 0.585131] [G loss: 0.212094]\n",
            "[Epoch 1/2] [Batch 541/1583] [D loss: 0.552093] [G loss: 0.208980]\n",
            "[Epoch 1/2] [Batch 542/1583] [D loss: 0.565518] [G loss: 0.216050]\n",
            "[Epoch 1/2] [Batch 543/1583] [D loss: 0.580277] [G loss: 0.215872]\n",
            "[Epoch 1/2] [Batch 544/1583] [D loss: 0.590227] [G loss: 0.214679]\n",
            "[Epoch 1/2] [Batch 545/1583] [D loss: 0.616041] [G loss: 0.215160]\n",
            "[Epoch 1/2] [Batch 546/1583] [D loss: 0.546968] [G loss: 0.211968]\n",
            "[Epoch 1/2] [Batch 547/1583] [D loss: 0.534825] [G loss: 0.208547]\n",
            "[Epoch 1/2] [Batch 548/1583] [D loss: 0.550617] [G loss: 0.211713]\n",
            "[Epoch 1/2] [Batch 549/1583] [D loss: 0.544869] [G loss: 0.212480]\n",
            "[Epoch 1/2] [Batch 550/1583] [D loss: 0.544781] [G loss: 0.212910]\n",
            "[Epoch 1/2] [Batch 551/1583] [D loss: 0.596123] [G loss: 0.218795]\n",
            "[Epoch 1/2] [Batch 552/1583] [D loss: 0.571679] [G loss: 0.208814]\n",
            "[Epoch 1/2] [Batch 553/1583] [D loss: 0.542913] [G loss: 0.218144]\n",
            "[Epoch 1/2] [Batch 554/1583] [D loss: 0.565569] [G loss: 0.208866]\n",
            "[Epoch 1/2] [Batch 555/1583] [D loss: 0.558900] [G loss: 0.209296]\n",
            "[Epoch 1/2] [Batch 556/1583] [D loss: 0.525260] [G loss: 0.207532]\n",
            "[Epoch 1/2] [Batch 557/1583] [D loss: 0.573007] [G loss: 0.213409]\n",
            "[Epoch 1/2] [Batch 558/1583] [D loss: 0.602963] [G loss: 0.219933]\n",
            "[Epoch 1/2] [Batch 559/1583] [D loss: 0.579446] [G loss: 0.210131]\n",
            "[Epoch 1/2] [Batch 560/1583] [D loss: 0.576054] [G loss: 0.206292]\n",
            "[Epoch 1/2] [Batch 561/1583] [D loss: 0.522458] [G loss: 0.205033]\n",
            "[Epoch 1/2] [Batch 562/1583] [D loss: 0.612812] [G loss: 0.210356]\n",
            "[Epoch 1/2] [Batch 563/1583] [D loss: 0.549981] [G loss: 0.208509]\n",
            "[Epoch 1/2] [Batch 564/1583] [D loss: 0.535716] [G loss: 0.198326]\n",
            "[Epoch 1/2] [Batch 565/1583] [D loss: 0.540514] [G loss: 0.210050]\n",
            "[Epoch 1/2] [Batch 566/1583] [D loss: 0.545758] [G loss: 0.218194]\n",
            "[Epoch 1/2] [Batch 567/1583] [D loss: 0.550015] [G loss: 0.204164]\n",
            "[Epoch 1/2] [Batch 568/1583] [D loss: 0.558264] [G loss: 0.212376]\n",
            "[Epoch 1/2] [Batch 569/1583] [D loss: 0.542375] [G loss: 0.207987]\n",
            "[Epoch 1/2] [Batch 570/1583] [D loss: 0.565607] [G loss: 0.212250]\n",
            "[Epoch 1/2] [Batch 571/1583] [D loss: 0.553896] [G loss: 0.222214]\n",
            "[Epoch 1/2] [Batch 572/1583] [D loss: 0.574919] [G loss: 0.204101]\n",
            "[Epoch 1/2] [Batch 573/1583] [D loss: 0.534025] [G loss: 0.210397]\n",
            "[Epoch 1/2] [Batch 574/1583] [D loss: 0.608329] [G loss: 0.215624]\n",
            "[Epoch 1/2] [Batch 575/1583] [D loss: 0.599786] [G loss: 0.212721]\n",
            "[Epoch 1/2] [Batch 576/1583] [D loss: 0.551896] [G loss: 0.204553]\n",
            "[Epoch 1/2] [Batch 577/1583] [D loss: 0.591609] [G loss: 0.207188]\n",
            "[Epoch 1/2] [Batch 578/1583] [D loss: 0.592548] [G loss: 0.218451]\n",
            "[Epoch 1/2] [Batch 579/1583] [D loss: 0.572538] [G loss: 0.204571]\n",
            "[Epoch 1/2] [Batch 580/1583] [D loss: 0.541439] [G loss: 0.212885]\n",
            "[Epoch 1/2] [Batch 581/1583] [D loss: 0.548983] [G loss: 0.207444]\n",
            "[Epoch 1/2] [Batch 582/1583] [D loss: 0.582505] [G loss: 0.216450]\n",
            "[Epoch 1/2] [Batch 583/1583] [D loss: 0.562700] [G loss: 0.209926]\n",
            "[Epoch 1/2] [Batch 584/1583] [D loss: 0.537617] [G loss: 0.203928]\n",
            "[Epoch 1/2] [Batch 585/1583] [D loss: 0.578370] [G loss: 0.203951]\n",
            "[Epoch 1/2] [Batch 586/1583] [D loss: 0.565667] [G loss: 0.210842]\n",
            "[Epoch 1/2] [Batch 587/1583] [D loss: 0.594875] [G loss: 0.212044]\n",
            "[Epoch 1/2] [Batch 588/1583] [D loss: 0.579000] [G loss: 0.221326]\n",
            "[Epoch 1/2] [Batch 589/1583] [D loss: 0.551922] [G loss: 0.203902]\n",
            "[Epoch 1/2] [Batch 590/1583] [D loss: 0.538414] [G loss: 0.202080]\n",
            "[Epoch 1/2] [Batch 591/1583] [D loss: 0.558327] [G loss: 0.217313]\n",
            "[Epoch 1/2] [Batch 592/1583] [D loss: 0.603493] [G loss: 0.206108]\n",
            "[Epoch 1/2] [Batch 593/1583] [D loss: 0.573932] [G loss: 0.205807]\n",
            "[Epoch 1/2] [Batch 594/1583] [D loss: 0.551308] [G loss: 0.201748]\n",
            "[Epoch 1/2] [Batch 595/1583] [D loss: 0.592706] [G loss: 0.221728]\n",
            "[Epoch 1/2] [Batch 596/1583] [D loss: 0.561815] [G loss: 0.212684]\n",
            "[Epoch 1/2] [Batch 597/1583] [D loss: 0.540808] [G loss: 0.204041]\n",
            "[Epoch 1/2] [Batch 598/1583] [D loss: 0.582734] [G loss: 0.214618]\n",
            "[Epoch 1/2] [Batch 599/1583] [D loss: 0.583793] [G loss: 0.208441]\n",
            "[Epoch 1/2] [Batch 600/1583] [D loss: 0.596693] [G loss: 0.205657]\n",
            "[Epoch 1/2] [Batch 601/1583] [D loss: 0.587909] [G loss: 0.219584]\n",
            "[Epoch 1/2] [Batch 602/1583] [D loss: 0.559469] [G loss: 0.213226]\n",
            "[Epoch 1/2] [Batch 603/1583] [D loss: 0.575386] [G loss: 0.207341]\n",
            "[Epoch 1/2] [Batch 604/1583] [D loss: 0.586688] [G loss: 0.212415]\n",
            "[Epoch 1/2] [Batch 605/1583] [D loss: 0.537828] [G loss: 0.212643]\n",
            "[Epoch 1/2] [Batch 606/1583] [D loss: 0.543143] [G loss: 0.207503]\n",
            "[Epoch 1/2] [Batch 607/1583] [D loss: 0.573840] [G loss: 0.215012]\n",
            "[Epoch 1/2] [Batch 608/1583] [D loss: 0.540855] [G loss: 0.211956]\n",
            "[Epoch 1/2] [Batch 609/1583] [D loss: 0.576401] [G loss: 0.211238]\n",
            "[Epoch 1/2] [Batch 610/1583] [D loss: 0.562653] [G loss: 0.208712]\n",
            "[Epoch 1/2] [Batch 611/1583] [D loss: 0.599772] [G loss: 0.214799]\n",
            "[Epoch 1/2] [Batch 612/1583] [D loss: 0.552185] [G loss: 0.201547]\n",
            "[Epoch 1/2] [Batch 613/1583] [D loss: 0.607632] [G loss: 0.213303]\n",
            "[Epoch 1/2] [Batch 614/1583] [D loss: 0.526081] [G loss: 0.209970]\n",
            "[Epoch 1/2] [Batch 615/1583] [D loss: 0.588758] [G loss: 0.223816]\n",
            "[Epoch 1/2] [Batch 616/1583] [D loss: 0.567936] [G loss: 0.218004]\n",
            "[Epoch 1/2] [Batch 617/1583] [D loss: 0.552368] [G loss: 0.209764]\n",
            "[Epoch 1/2] [Batch 618/1583] [D loss: 0.535456] [G loss: 0.207678]\n",
            "[Epoch 1/2] [Batch 619/1583] [D loss: 0.580934] [G loss: 0.209942]\n",
            "[Epoch 1/2] [Batch 620/1583] [D loss: 0.537213] [G loss: 0.210244]\n",
            "[Epoch 1/2] [Batch 621/1583] [D loss: 0.556883] [G loss: 0.216378]\n",
            "[Epoch 1/2] [Batch 622/1583] [D loss: 0.582833] [G loss: 0.212728]\n",
            "[Epoch 1/2] [Batch 623/1583] [D loss: 0.540096] [G loss: 0.204476]\n",
            "[Epoch 1/2] [Batch 624/1583] [D loss: 0.587811] [G loss: 0.214377]\n",
            "[Epoch 1/2] [Batch 625/1583] [D loss: 0.576926] [G loss: 0.206457]\n",
            "[Epoch 1/2] [Batch 626/1583] [D loss: 0.570745] [G loss: 0.208938]\n",
            "[Epoch 1/2] [Batch 627/1583] [D loss: 0.547398] [G loss: 0.209114]\n",
            "[Epoch 1/2] [Batch 628/1583] [D loss: 0.572942] [G loss: 0.204637]\n",
            "[Epoch 1/2] [Batch 629/1583] [D loss: 0.571878] [G loss: 0.217163]\n",
            "[Epoch 1/2] [Batch 630/1583] [D loss: 0.584575] [G loss: 0.204810]\n",
            "[Epoch 1/2] [Batch 631/1583] [D loss: 0.567341] [G loss: 0.210233]\n",
            "[Epoch 1/2] [Batch 632/1583] [D loss: 0.552255] [G loss: 0.207678]\n",
            "[Epoch 1/2] [Batch 633/1583] [D loss: 0.552964] [G loss: 0.215102]\n",
            "[Epoch 1/2] [Batch 634/1583] [D loss: 0.638452] [G loss: 0.215101]\n",
            "[Epoch 1/2] [Batch 635/1583] [D loss: 0.537915] [G loss: 0.212713]\n",
            "[Epoch 1/2] [Batch 636/1583] [D loss: 0.518634] [G loss: 0.215668]\n",
            "[Epoch 1/2] [Batch 637/1583] [D loss: 0.542256] [G loss: 0.203941]\n",
            "[Epoch 1/2] [Batch 638/1583] [D loss: 0.599177] [G loss: 0.221251]\n",
            "[Epoch 1/2] [Batch 639/1583] [D loss: 0.572468] [G loss: 0.205803]\n",
            "[Epoch 1/2] [Batch 640/1583] [D loss: 0.576466] [G loss: 0.209820]\n",
            "[Epoch 1/2] [Batch 641/1583] [D loss: 0.554767] [G loss: 0.207921]\n",
            "[Epoch 1/2] [Batch 642/1583] [D loss: 0.577943] [G loss: 0.210252]\n",
            "[Epoch 1/2] [Batch 643/1583] [D loss: 0.579566] [G loss: 0.209761]\n",
            "[Epoch 1/2] [Batch 644/1583] [D loss: 0.539066] [G loss: 0.206806]\n",
            "[Epoch 1/2] [Batch 645/1583] [D loss: 0.595873] [G loss: 0.210145]\n",
            "[Epoch 1/2] [Batch 646/1583] [D loss: 0.546590] [G loss: 0.212024]\n",
            "[Epoch 1/2] [Batch 647/1583] [D loss: 0.553295] [G loss: 0.219101]\n",
            "[Epoch 1/2] [Batch 648/1583] [D loss: 0.553740] [G loss: 0.208020]\n",
            "[Epoch 1/2] [Batch 649/1583] [D loss: 0.558475] [G loss: 0.209050]\n",
            "[Epoch 1/2] [Batch 650/1583] [D loss: 0.585012] [G loss: 0.210323]\n",
            "[Epoch 1/2] [Batch 651/1583] [D loss: 0.560520] [G loss: 0.214333]\n",
            "[Epoch 1/2] [Batch 652/1583] [D loss: 0.547340] [G loss: 0.209134]\n",
            "[Epoch 1/2] [Batch 653/1583] [D loss: 0.521708] [G loss: 0.208287]\n",
            "[Epoch 1/2] [Batch 654/1583] [D loss: 0.559618] [G loss: 0.207574]\n",
            "[Epoch 1/2] [Batch 655/1583] [D loss: 0.614657] [G loss: 0.209219]\n",
            "[Epoch 1/2] [Batch 656/1583] [D loss: 0.544669] [G loss: 0.214707]\n",
            "[Epoch 1/2] [Batch 657/1583] [D loss: 0.555320] [G loss: 0.209275]\n",
            "[Epoch 1/2] [Batch 658/1583] [D loss: 0.596510] [G loss: 0.217037]\n",
            "[Epoch 1/2] [Batch 659/1583] [D loss: 0.553517] [G loss: 0.221044]\n",
            "[Epoch 1/2] [Batch 660/1583] [D loss: 0.536274] [G loss: 0.212344]\n",
            "[Epoch 1/2] [Batch 661/1583] [D loss: 0.557030] [G loss: 0.212037]\n",
            "[Epoch 1/2] [Batch 662/1583] [D loss: 0.550152] [G loss: 0.209843]\n",
            "[Epoch 1/2] [Batch 663/1583] [D loss: 0.568154] [G loss: 0.210091]\n",
            "[Epoch 1/2] [Batch 664/1583] [D loss: 0.590544] [G loss: 0.222136]\n",
            "[Epoch 1/2] [Batch 665/1583] [D loss: 0.543604] [G loss: 0.211866]\n",
            "[Epoch 1/2] [Batch 666/1583] [D loss: 0.593916] [G loss: 0.207805]\n",
            "[Epoch 1/2] [Batch 667/1583] [D loss: 0.587785] [G loss: 0.211303]\n",
            "[Epoch 1/2] [Batch 668/1583] [D loss: 0.546108] [G loss: 0.214386]\n",
            "[Epoch 1/2] [Batch 669/1583] [D loss: 0.532541] [G loss: 0.205033]\n",
            "[Epoch 1/2] [Batch 670/1583] [D loss: 0.561827] [G loss: 0.202498]\n",
            "[Epoch 1/2] [Batch 671/1583] [D loss: 0.577538] [G loss: 0.208293]\n",
            "[Epoch 1/2] [Batch 672/1583] [D loss: 0.604956] [G loss: 0.214920]\n",
            "[Epoch 1/2] [Batch 673/1583] [D loss: 0.567557] [G loss: 0.214907]\n",
            "[Epoch 1/2] [Batch 674/1583] [D loss: 0.568963] [G loss: 0.205158]\n",
            "[Epoch 1/2] [Batch 675/1583] [D loss: 0.539728] [G loss: 0.205420]\n",
            "[Epoch 1/2] [Batch 676/1583] [D loss: 0.551564] [G loss: 0.208028]\n",
            "[Epoch 1/2] [Batch 677/1583] [D loss: 0.572714] [G loss: 0.212705]\n",
            "[Epoch 1/2] [Batch 678/1583] [D loss: 0.576112] [G loss: 0.215892]\n",
            "[Epoch 1/2] [Batch 679/1583] [D loss: 0.559070] [G loss: 0.207733]\n",
            "[Epoch 1/2] [Batch 680/1583] [D loss: 0.601007] [G loss: 0.197480]\n",
            "[Epoch 1/2] [Batch 681/1583] [D loss: 0.551078] [G loss: 0.209808]\n",
            "[Epoch 1/2] [Batch 682/1583] [D loss: 0.592353] [G loss: 0.214129]\n",
            "[Epoch 1/2] [Batch 683/1583] [D loss: 0.579887] [G loss: 0.204879]\n",
            "[Epoch 1/2] [Batch 684/1583] [D loss: 0.586824] [G loss: 0.210103]\n",
            "[Epoch 1/2] [Batch 685/1583] [D loss: 0.565235] [G loss: 0.202655]\n",
            "[Epoch 1/2] [Batch 686/1583] [D loss: 0.557534] [G loss: 0.206696]\n",
            "[Epoch 1/2] [Batch 687/1583] [D loss: 0.565803] [G loss: 0.211031]\n",
            "[Epoch 1/2] [Batch 688/1583] [D loss: 0.568198] [G loss: 0.207968]\n",
            "[Epoch 1/2] [Batch 689/1583] [D loss: 0.602345] [G loss: 0.211704]\n",
            "[Epoch 1/2] [Batch 690/1583] [D loss: 0.572427] [G loss: 0.208841]\n",
            "[Epoch 1/2] [Batch 691/1583] [D loss: 0.552374] [G loss: 0.209845]\n",
            "[Epoch 1/2] [Batch 692/1583] [D loss: 0.586772] [G loss: 0.217995]\n",
            "[Epoch 1/2] [Batch 693/1583] [D loss: 0.572068] [G loss: 0.208601]\n",
            "[Epoch 1/2] [Batch 694/1583] [D loss: 0.580919] [G loss: 0.218772]\n",
            "[Epoch 1/2] [Batch 695/1583] [D loss: 0.557282] [G loss: 0.216863]\n",
            "[Epoch 1/2] [Batch 696/1583] [D loss: 0.569238] [G loss: 0.205145]\n",
            "[Epoch 1/2] [Batch 697/1583] [D loss: 0.558624] [G loss: 0.202772]\n",
            "[Epoch 1/2] [Batch 698/1583] [D loss: 0.535355] [G loss: 0.209710]\n",
            "[Epoch 1/2] [Batch 699/1583] [D loss: 0.592125] [G loss: 0.213060]\n",
            "[Epoch 1/2] [Batch 700/1583] [D loss: 0.600988] [G loss: 0.207548]\n",
            "[Epoch 1/2] [Batch 701/1583] [D loss: 0.572552] [G loss: 0.210627]\n",
            "[Epoch 1/2] [Batch 702/1583] [D loss: 0.563599] [G loss: 0.204438]\n",
            "[Epoch 1/2] [Batch 703/1583] [D loss: 0.546688] [G loss: 0.210633]\n",
            "[Epoch 1/2] [Batch 704/1583] [D loss: 0.537661] [G loss: 0.214104]\n",
            "[Epoch 1/2] [Batch 705/1583] [D loss: 0.535655] [G loss: 0.206532]\n",
            "[Epoch 1/2] [Batch 706/1583] [D loss: 0.576654] [G loss: 0.208860]\n",
            "[Epoch 1/2] [Batch 707/1583] [D loss: 0.565044] [G loss: 0.211810]\n",
            "[Epoch 1/2] [Batch 708/1583] [D loss: 0.533590] [G loss: 0.206749]\n",
            "[Epoch 1/2] [Batch 709/1583] [D loss: 0.591053] [G loss: 0.209441]\n",
            "[Epoch 1/2] [Batch 710/1583] [D loss: 0.586014] [G loss: 0.210442]\n",
            "[Epoch 1/2] [Batch 711/1583] [D loss: 0.567386] [G loss: 0.208422]\n",
            "[Epoch 1/2] [Batch 712/1583] [D loss: 0.618732] [G loss: 0.211313]\n",
            "[Epoch 1/2] [Batch 713/1583] [D loss: 0.545565] [G loss: 0.212884]\n",
            "[Epoch 1/2] [Batch 714/1583] [D loss: 0.577547] [G loss: 0.206924]\n",
            "[Epoch 1/2] [Batch 715/1583] [D loss: 0.617292] [G loss: 0.210186]\n",
            "[Epoch 1/2] [Batch 716/1583] [D loss: 0.596867] [G loss: 0.219221]\n",
            "[Epoch 1/2] [Batch 717/1583] [D loss: 0.578141] [G loss: 0.210660]\n",
            "[Epoch 1/2] [Batch 718/1583] [D loss: 0.547767] [G loss: 0.201989]\n",
            "[Epoch 1/2] [Batch 719/1583] [D loss: 0.571881] [G loss: 0.216309]\n",
            "[Epoch 1/2] [Batch 720/1583] [D loss: 0.523208] [G loss: 0.206737]\n",
            "[Epoch 1/2] [Batch 721/1583] [D loss: 0.527386] [G loss: 0.209228]\n",
            "[Epoch 1/2] [Batch 722/1583] [D loss: 0.567396] [G loss: 0.198048]\n",
            "[Epoch 1/2] [Batch 723/1583] [D loss: 0.579092] [G loss: 0.205127]\n",
            "[Epoch 1/2] [Batch 724/1583] [D loss: 0.564939] [G loss: 0.207721]\n",
            "[Epoch 1/2] [Batch 725/1583] [D loss: 0.538325] [G loss: 0.205300]\n",
            "[Epoch 1/2] [Batch 726/1583] [D loss: 0.533626] [G loss: 0.206868]\n",
            "[Epoch 1/2] [Batch 727/1583] [D loss: 0.512213] [G loss: 0.208364]\n",
            "[Epoch 1/2] [Batch 728/1583] [D loss: 0.546457] [G loss: 0.197713]\n",
            "[Epoch 1/2] [Batch 729/1583] [D loss: 0.522878] [G loss: 0.207509]\n",
            "[Epoch 1/2] [Batch 730/1583] [D loss: 0.576937] [G loss: 0.207703]\n",
            "[Epoch 1/2] [Batch 731/1583] [D loss: 0.590041] [G loss: 0.225936]\n",
            "[Epoch 1/2] [Batch 732/1583] [D loss: 0.584292] [G loss: 0.212003]\n",
            "[Epoch 1/2] [Batch 733/1583] [D loss: 0.538535] [G loss: 0.203033]\n",
            "[Epoch 1/2] [Batch 734/1583] [D loss: 0.601552] [G loss: 0.207528]\n",
            "[Epoch 1/2] [Batch 735/1583] [D loss: 0.533335] [G loss: 0.211257]\n",
            "[Epoch 1/2] [Batch 736/1583] [D loss: 0.613309] [G loss: 0.211944]\n",
            "[Epoch 1/2] [Batch 737/1583] [D loss: 0.558130] [G loss: 0.212410]\n",
            "[Epoch 1/2] [Batch 738/1583] [D loss: 0.601733] [G loss: 0.225557]\n",
            "[Epoch 1/2] [Batch 739/1583] [D loss: 0.522897] [G loss: 0.206719]\n",
            "[Epoch 1/2] [Batch 740/1583] [D loss: 0.592445] [G loss: 0.204578]\n",
            "[Epoch 1/2] [Batch 741/1583] [D loss: 0.549139] [G loss: 0.213507]\n",
            "[Epoch 1/2] [Batch 742/1583] [D loss: 0.567819] [G loss: 0.209503]\n",
            "[Epoch 1/2] [Batch 743/1583] [D loss: 0.532640] [G loss: 0.209795]\n",
            "[Epoch 1/2] [Batch 744/1583] [D loss: 0.547423] [G loss: 0.208977]\n",
            "[Epoch 1/2] [Batch 745/1583] [D loss: 0.573657] [G loss: 0.199841]\n",
            "[Epoch 1/2] [Batch 746/1583] [D loss: 0.596234] [G loss: 0.204457]\n",
            "[Epoch 1/2] [Batch 747/1583] [D loss: 0.560568] [G loss: 0.201654]\n",
            "[Epoch 1/2] [Batch 748/1583] [D loss: 0.563514] [G loss: 0.212200]\n",
            "[Epoch 1/2] [Batch 749/1583] [D loss: 0.565504] [G loss: 0.212206]\n",
            "[Epoch 1/2] [Batch 750/1583] [D loss: 0.597225] [G loss: 0.210328]\n",
            "[Epoch 1/2] [Batch 751/1583] [D loss: 0.554756] [G loss: 0.208064]\n",
            "[Epoch 1/2] [Batch 752/1583] [D loss: 0.570405] [G loss: 0.209684]\n",
            "[Epoch 1/2] [Batch 753/1583] [D loss: 0.615022] [G loss: 0.204044]\n",
            "[Epoch 1/2] [Batch 754/1583] [D loss: 0.549224] [G loss: 0.209804]\n",
            "[Epoch 1/2] [Batch 755/1583] [D loss: 0.559099] [G loss: 0.206413]\n",
            "[Epoch 1/2] [Batch 756/1583] [D loss: 0.582971] [G loss: 0.206682]\n",
            "[Epoch 1/2] [Batch 757/1583] [D loss: 0.585333] [G loss: 0.212766]\n",
            "[Epoch 1/2] [Batch 758/1583] [D loss: 0.586758] [G loss: 0.211491]\n",
            "[Epoch 1/2] [Batch 759/1583] [D loss: 0.538232] [G loss: 0.202755]\n",
            "[Epoch 1/2] [Batch 760/1583] [D loss: 0.579695] [G loss: 0.206817]\n",
            "[Epoch 1/2] [Batch 761/1583] [D loss: 0.553282] [G loss: 0.210364]\n",
            "[Epoch 1/2] [Batch 762/1583] [D loss: 0.605411] [G loss: 0.208515]\n",
            "[Epoch 1/2] [Batch 763/1583] [D loss: 0.585533] [G loss: 0.212667]\n",
            "[Epoch 1/2] [Batch 764/1583] [D loss: 0.583655] [G loss: 0.212120]\n",
            "[Epoch 1/2] [Batch 765/1583] [D loss: 0.588929] [G loss: 0.212801]\n",
            "[Epoch 1/2] [Batch 766/1583] [D loss: 0.561946] [G loss: 0.212588]\n",
            "[Epoch 1/2] [Batch 767/1583] [D loss: 0.577762] [G loss: 0.202675]\n",
            "[Epoch 1/2] [Batch 768/1583] [D loss: 0.524163] [G loss: 0.206063]\n",
            "[Epoch 1/2] [Batch 769/1583] [D loss: 0.537054] [G loss: 0.213786]\n",
            "[Epoch 1/2] [Batch 770/1583] [D loss: 0.557748] [G loss: 0.206494]\n",
            "[Epoch 1/2] [Batch 771/1583] [D loss: 0.543207] [G loss: 0.204217]\n",
            "[Epoch 1/2] [Batch 772/1583] [D loss: 0.501303] [G loss: 0.202450]\n",
            "[Epoch 1/2] [Batch 773/1583] [D loss: 0.604142] [G loss: 0.211738]\n",
            "[Epoch 1/2] [Batch 774/1583] [D loss: 0.589681] [G loss: 0.212441]\n",
            "[Epoch 1/2] [Batch 775/1583] [D loss: 0.569438] [G loss: 0.203795]\n",
            "[Epoch 1/2] [Batch 776/1583] [D loss: 0.571823] [G loss: 0.214457]\n",
            "[Epoch 1/2] [Batch 777/1583] [D loss: 0.595252] [G loss: 0.216356]\n",
            "[Epoch 1/2] [Batch 778/1583] [D loss: 0.552320] [G loss: 0.212054]\n",
            "[Epoch 1/2] [Batch 779/1583] [D loss: 0.591828] [G loss: 0.213996]\n",
            "[Epoch 1/2] [Batch 780/1583] [D loss: 0.559789] [G loss: 0.208995]\n",
            "[Epoch 1/2] [Batch 781/1583] [D loss: 0.560014] [G loss: 0.204705]\n",
            "[Epoch 1/2] [Batch 782/1583] [D loss: 0.553005] [G loss: 0.206961]\n",
            "[Epoch 1/2] [Batch 783/1583] [D loss: 0.563628] [G loss: 0.212283]\n",
            "[Epoch 1/2] [Batch 784/1583] [D loss: 0.595810] [G loss: 0.207592]\n",
            "[Epoch 1/2] [Batch 785/1583] [D loss: 0.550840] [G loss: 0.221918]\n",
            "[Epoch 1/2] [Batch 786/1583] [D loss: 0.554919] [G loss: 0.208246]\n",
            "[Epoch 1/2] [Batch 787/1583] [D loss: 0.536135] [G loss: 0.203108]\n",
            "[Epoch 1/2] [Batch 788/1583] [D loss: 0.599889] [G loss: 0.216036]\n",
            "[Epoch 1/2] [Batch 789/1583] [D loss: 0.558545] [G loss: 0.211118]\n",
            "[Epoch 1/2] [Batch 790/1583] [D loss: 0.576543] [G loss: 0.205991]\n",
            "[Epoch 1/2] [Batch 791/1583] [D loss: 0.587209] [G loss: 0.220306]\n",
            "[Epoch 1/2] [Batch 792/1583] [D loss: 0.592357] [G loss: 0.224577]\n",
            "[Epoch 1/2] [Batch 793/1583] [D loss: 0.553278] [G loss: 0.222407]\n",
            "[Epoch 1/2] [Batch 794/1583] [D loss: 0.603401] [G loss: 0.207913]\n",
            "[Epoch 1/2] [Batch 795/1583] [D loss: 0.538163] [G loss: 0.205004]\n",
            "[Epoch 1/2] [Batch 796/1583] [D loss: 0.587565] [G loss: 0.213971]\n",
            "[Epoch 1/2] [Batch 797/1583] [D loss: 0.577536] [G loss: 0.208095]\n",
            "[Epoch 1/2] [Batch 798/1583] [D loss: 0.539733] [G loss: 0.206756]\n",
            "[Epoch 1/2] [Batch 799/1583] [D loss: 0.512990] [G loss: 0.209562]\n",
            "[Epoch 1/2] [Batch 800/1583] [D loss: 0.596199] [G loss: 0.206204]\n",
            "[Epoch 1/2] [Batch 801/1583] [D loss: 0.553148] [G loss: 0.212612]\n",
            "[Epoch 1/2] [Batch 802/1583] [D loss: 0.570501] [G loss: 0.209124]\n",
            "[Epoch 1/2] [Batch 803/1583] [D loss: 0.589001] [G loss: 0.213738]\n",
            "[Epoch 1/2] [Batch 804/1583] [D loss: 0.601185] [G loss: 0.212998]\n",
            "[Epoch 1/2] [Batch 805/1583] [D loss: 0.561293] [G loss: 0.216830]\n",
            "[Epoch 1/2] [Batch 806/1583] [D loss: 0.582105] [G loss: 0.215086]\n",
            "[Epoch 1/2] [Batch 807/1583] [D loss: 0.571417] [G loss: 0.209196]\n",
            "[Epoch 1/2] [Batch 808/1583] [D loss: 0.518063] [G loss: 0.208087]\n",
            "[Epoch 1/2] [Batch 809/1583] [D loss: 0.580248] [G loss: 0.205562]\n",
            "[Epoch 1/2] [Batch 810/1583] [D loss: 0.547812] [G loss: 0.206041]\n",
            "[Epoch 1/2] [Batch 811/1583] [D loss: 0.551371] [G loss: 0.206583]\n",
            "[Epoch 1/2] [Batch 812/1583] [D loss: 0.579042] [G loss: 0.205497]\n",
            "[Epoch 1/2] [Batch 813/1583] [D loss: 0.576679] [G loss: 0.218149]\n",
            "[Epoch 1/2] [Batch 814/1583] [D loss: 0.572852] [G loss: 0.216218]\n",
            "[Epoch 1/2] [Batch 815/1583] [D loss: 0.505367] [G loss: 0.205352]\n",
            "[Epoch 1/2] [Batch 816/1583] [D loss: 0.582702] [G loss: 0.215623]\n",
            "[Epoch 1/2] [Batch 817/1583] [D loss: 0.571756] [G loss: 0.204061]\n",
            "[Epoch 1/2] [Batch 818/1583] [D loss: 0.548662] [G loss: 0.207026]\n",
            "[Epoch 1/2] [Batch 819/1583] [D loss: 0.559602] [G loss: 0.210752]\n",
            "[Epoch 1/2] [Batch 820/1583] [D loss: 0.601158] [G loss: 0.206928]\n",
            "[Epoch 1/2] [Batch 821/1583] [D loss: 0.592041] [G loss: 0.210385]\n",
            "[Epoch 1/2] [Batch 822/1583] [D loss: 0.542372] [G loss: 0.214024]\n",
            "[Epoch 1/2] [Batch 823/1583] [D loss: 0.545156] [G loss: 0.208353]\n",
            "[Epoch 1/2] [Batch 824/1583] [D loss: 0.546687] [G loss: 0.207616]\n",
            "[Epoch 1/2] [Batch 825/1583] [D loss: 0.547662] [G loss: 0.208004]\n",
            "[Epoch 1/2] [Batch 826/1583] [D loss: 0.560147] [G loss: 0.214997]\n",
            "[Epoch 1/2] [Batch 827/1583] [D loss: 0.528085] [G loss: 0.212831]\n",
            "[Epoch 1/2] [Batch 828/1583] [D loss: 0.593318] [G loss: 0.207068]\n",
            "[Epoch 1/2] [Batch 829/1583] [D loss: 0.583557] [G loss: 0.211760]\n",
            "[Epoch 1/2] [Batch 830/1583] [D loss: 0.523839] [G loss: 0.204463]\n",
            "[Epoch 1/2] [Batch 831/1583] [D loss: 0.580490] [G loss: 0.218853]\n",
            "[Epoch 1/2] [Batch 832/1583] [D loss: 0.594246] [G loss: 0.221106]\n",
            "[Epoch 1/2] [Batch 833/1583] [D loss: 0.578266] [G loss: 0.212892]\n",
            "[Epoch 1/2] [Batch 834/1583] [D loss: 0.556886] [G loss: 0.216013]\n",
            "[Epoch 1/2] [Batch 835/1583] [D loss: 0.595574] [G loss: 0.210911]\n",
            "[Epoch 1/2] [Batch 836/1583] [D loss: 0.548691] [G loss: 0.209337]\n",
            "[Epoch 1/2] [Batch 837/1583] [D loss: 0.554455] [G loss: 0.201112]\n",
            "[Epoch 1/2] [Batch 838/1583] [D loss: 0.587353] [G loss: 0.212620]\n",
            "[Epoch 1/2] [Batch 839/1583] [D loss: 0.511355] [G loss: 0.211466]\n",
            "[Epoch 1/2] [Batch 840/1583] [D loss: 0.567108] [G loss: 0.207605]\n",
            "[Epoch 1/2] [Batch 841/1583] [D loss: 0.541602] [G loss: 0.213050]\n",
            "[Epoch 1/2] [Batch 842/1583] [D loss: 0.559425] [G loss: 0.214054]\n",
            "[Epoch 1/2] [Batch 843/1583] [D loss: 0.569541] [G loss: 0.217779]\n",
            "[Epoch 1/2] [Batch 844/1583] [D loss: 0.561757] [G loss: 0.207701]\n",
            "[Epoch 1/2] [Batch 845/1583] [D loss: 0.581150] [G loss: 0.218556]\n",
            "[Epoch 1/2] [Batch 846/1583] [D loss: 0.572019] [G loss: 0.206837]\n",
            "[Epoch 1/2] [Batch 847/1583] [D loss: 0.534983] [G loss: 0.207706]\n",
            "[Epoch 1/2] [Batch 848/1583] [D loss: 0.558927] [G loss: 0.214407]\n",
            "[Epoch 1/2] [Batch 849/1583] [D loss: 0.593511] [G loss: 0.217450]\n",
            "[Epoch 1/2] [Batch 850/1583] [D loss: 0.580431] [G loss: 0.212482]\n",
            "[Epoch 1/2] [Batch 851/1583] [D loss: 0.579354] [G loss: 0.217935]\n",
            "[Epoch 1/2] [Batch 852/1583] [D loss: 0.588899] [G loss: 0.208986]\n",
            "[Epoch 1/2] [Batch 853/1583] [D loss: 0.543076] [G loss: 0.204967]\n",
            "[Epoch 1/2] [Batch 854/1583] [D loss: 0.586826] [G loss: 0.206887]\n",
            "[Epoch 1/2] [Batch 855/1583] [D loss: 0.515911] [G loss: 0.214273]\n",
            "[Epoch 1/2] [Batch 856/1583] [D loss: 0.573907] [G loss: 0.207595]\n",
            "[Epoch 1/2] [Batch 857/1583] [D loss: 0.576757] [G loss: 0.208205]\n",
            "[Epoch 1/2] [Batch 858/1583] [D loss: 0.556625] [G loss: 0.206403]\n",
            "[Epoch 1/2] [Batch 859/1583] [D loss: 0.567160] [G loss: 0.211509]\n",
            "[Epoch 1/2] [Batch 860/1583] [D loss: 0.600754] [G loss: 0.205421]\n",
            "[Epoch 1/2] [Batch 861/1583] [D loss: 0.551784] [G loss: 0.211898]\n",
            "[Epoch 1/2] [Batch 862/1583] [D loss: 0.545724] [G loss: 0.204998]\n",
            "[Epoch 1/2] [Batch 863/1583] [D loss: 0.591155] [G loss: 0.215042]\n",
            "[Epoch 1/2] [Batch 864/1583] [D loss: 0.596405] [G loss: 0.214241]\n",
            "[Epoch 1/2] [Batch 865/1583] [D loss: 0.543664] [G loss: 0.211539]\n",
            "[Epoch 1/2] [Batch 866/1583] [D loss: 0.566927] [G loss: 0.208226]\n",
            "[Epoch 1/2] [Batch 867/1583] [D loss: 0.583714] [G loss: 0.218745]\n",
            "[Epoch 1/2] [Batch 868/1583] [D loss: 0.553695] [G loss: 0.213701]\n",
            "[Epoch 1/2] [Batch 869/1583] [D loss: 0.536968] [G loss: 0.207332]\n",
            "[Epoch 1/2] [Batch 870/1583] [D loss: 0.546222] [G loss: 0.208951]\n",
            "[Epoch 1/2] [Batch 871/1583] [D loss: 0.585830] [G loss: 0.216559]\n",
            "[Epoch 1/2] [Batch 872/1583] [D loss: 0.542791] [G loss: 0.216936]\n",
            "[Epoch 1/2] [Batch 873/1583] [D loss: 0.577736] [G loss: 0.229067]\n",
            "[Epoch 1/2] [Batch 874/1583] [D loss: 0.551735] [G loss: 0.213504]\n",
            "[Epoch 1/2] [Batch 875/1583] [D loss: 0.607990] [G loss: 0.213118]\n",
            "[Epoch 1/2] [Batch 876/1583] [D loss: 0.556518] [G loss: 0.211544]\n",
            "[Epoch 1/2] [Batch 877/1583] [D loss: 0.542472] [G loss: 0.208996]\n",
            "[Epoch 1/2] [Batch 878/1583] [D loss: 0.552033] [G loss: 0.205071]\n",
            "[Epoch 1/2] [Batch 879/1583] [D loss: 0.587292] [G loss: 0.202023]\n",
            "[Epoch 1/2] [Batch 880/1583] [D loss: 0.610741] [G loss: 0.211087]\n",
            "[Epoch 1/2] [Batch 881/1583] [D loss: 0.594119] [G loss: 0.210779]\n",
            "[Epoch 1/2] [Batch 882/1583] [D loss: 0.601247] [G loss: 0.213821]\n",
            "[Epoch 1/2] [Batch 883/1583] [D loss: 0.626313] [G loss: 0.208903]\n",
            "[Epoch 1/2] [Batch 884/1583] [D loss: 0.574629] [G loss: 0.207651]\n",
            "[Epoch 1/2] [Batch 885/1583] [D loss: 0.565585] [G loss: 0.208077]\n",
            "[Epoch 1/2] [Batch 886/1583] [D loss: 0.538907] [G loss: 0.219507]\n",
            "[Epoch 1/2] [Batch 887/1583] [D loss: 0.588576] [G loss: 0.218819]\n",
            "[Epoch 1/2] [Batch 888/1583] [D loss: 0.603289] [G loss: 0.218717]\n",
            "[Epoch 1/2] [Batch 889/1583] [D loss: 0.571507] [G loss: 0.205318]\n",
            "[Epoch 1/2] [Batch 890/1583] [D loss: 0.572000] [G loss: 0.221670]\n",
            "[Epoch 1/2] [Batch 891/1583] [D loss: 0.557176] [G loss: 0.217666]\n",
            "[Epoch 1/2] [Batch 892/1583] [D loss: 0.584689] [G loss: 0.203990]\n",
            "[Epoch 1/2] [Batch 893/1583] [D loss: 0.601450] [G loss: 0.205463]\n",
            "[Epoch 1/2] [Batch 894/1583] [D loss: 0.541026] [G loss: 0.202089]\n",
            "[Epoch 1/2] [Batch 895/1583] [D loss: 0.536091] [G loss: 0.210306]\n",
            "[Epoch 1/2] [Batch 896/1583] [D loss: 0.571559] [G loss: 0.203675]\n",
            "[Epoch 1/2] [Batch 897/1583] [D loss: 0.606790] [G loss: 0.218972]\n",
            "[Epoch 1/2] [Batch 898/1583] [D loss: 0.579625] [G loss: 0.208007]\n",
            "[Epoch 1/2] [Batch 899/1583] [D loss: 0.544907] [G loss: 0.207488]\n",
            "[Epoch 1/2] [Batch 900/1583] [D loss: 0.508520] [G loss: 0.204963]\n",
            "[Epoch 1/2] [Batch 901/1583] [D loss: 0.577931] [G loss: 0.211124]\n",
            "[Epoch 1/2] [Batch 902/1583] [D loss: 0.621363] [G loss: 0.208108]\n",
            "[Epoch 1/2] [Batch 903/1583] [D loss: 0.567706] [G loss: 0.205771]\n",
            "[Epoch 1/2] [Batch 904/1583] [D loss: 0.574569] [G loss: 0.207368]\n",
            "[Epoch 1/2] [Batch 905/1583] [D loss: 0.571585] [G loss: 0.212162]\n",
            "[Epoch 1/2] [Batch 906/1583] [D loss: 0.582885] [G loss: 0.212252]\n",
            "[Epoch 1/2] [Batch 907/1583] [D loss: 0.582424] [G loss: 0.201722]\n",
            "[Epoch 1/2] [Batch 908/1583] [D loss: 0.579920] [G loss: 0.211757]\n",
            "[Epoch 1/2] [Batch 909/1583] [D loss: 0.568941] [G loss: 0.212839]\n",
            "[Epoch 1/2] [Batch 910/1583] [D loss: 0.555882] [G loss: 0.209978]\n",
            "[Epoch 1/2] [Batch 911/1583] [D loss: 0.602639] [G loss: 0.203637]\n",
            "[Epoch 1/2] [Batch 912/1583] [D loss: 0.554465] [G loss: 0.202822]\n",
            "[Epoch 1/2] [Batch 913/1583] [D loss: 0.599592] [G loss: 0.206796]\n",
            "[Epoch 1/2] [Batch 914/1583] [D loss: 0.569822] [G loss: 0.220996]\n",
            "[Epoch 1/2] [Batch 915/1583] [D loss: 0.602649] [G loss: 0.215257]\n",
            "[Epoch 1/2] [Batch 916/1583] [D loss: 0.530879] [G loss: 0.205345]\n",
            "[Epoch 1/2] [Batch 917/1583] [D loss: 0.527480] [G loss: 0.203523]\n",
            "[Epoch 1/2] [Batch 918/1583] [D loss: 0.559586] [G loss: 0.214578]\n",
            "[Epoch 1/2] [Batch 919/1583] [D loss: 0.561172] [G loss: 0.209094]\n",
            "[Epoch 1/2] [Batch 920/1583] [D loss: 0.567670] [G loss: 0.218077]\n",
            "[Epoch 1/2] [Batch 921/1583] [D loss: 0.557385] [G loss: 0.207980]\n",
            "[Epoch 1/2] [Batch 922/1583] [D loss: 0.539062] [G loss: 0.199955]\n",
            "[Epoch 1/2] [Batch 923/1583] [D loss: 0.517765] [G loss: 0.210411]\n",
            "[Epoch 1/2] [Batch 924/1583] [D loss: 0.554521] [G loss: 0.211442]\n",
            "[Epoch 1/2] [Batch 925/1583] [D loss: 0.545368] [G loss: 0.200028]\n",
            "[Epoch 1/2] [Batch 926/1583] [D loss: 0.549338] [G loss: 0.213540]\n",
            "[Epoch 1/2] [Batch 927/1583] [D loss: 0.513716] [G loss: 0.203003]\n",
            "[Epoch 1/2] [Batch 928/1583] [D loss: 0.592028] [G loss: 0.212107]\n",
            "[Epoch 1/2] [Batch 929/1583] [D loss: 0.569466] [G loss: 0.212543]\n",
            "[Epoch 1/2] [Batch 930/1583] [D loss: 0.555208] [G loss: 0.204155]\n",
            "[Epoch 1/2] [Batch 931/1583] [D loss: 0.596608] [G loss: 0.225098]\n",
            "[Epoch 1/2] [Batch 932/1583] [D loss: 0.570138] [G loss: 0.213799]\n",
            "[Epoch 1/2] [Batch 933/1583] [D loss: 0.584215] [G loss: 0.215047]\n",
            "[Epoch 1/2] [Batch 934/1583] [D loss: 0.585417] [G loss: 0.218537]\n",
            "[Epoch 1/2] [Batch 935/1583] [D loss: 0.585020] [G loss: 0.204079]\n",
            "[Epoch 1/2] [Batch 936/1583] [D loss: 0.556942] [G loss: 0.207971]\n",
            "[Epoch 1/2] [Batch 937/1583] [D loss: 0.528352] [G loss: 0.202869]\n",
            "[Epoch 1/2] [Batch 938/1583] [D loss: 0.554155] [G loss: 0.215510]\n",
            "[Epoch 1/2] [Batch 939/1583] [D loss: 0.563456] [G loss: 0.208580]\n",
            "[Epoch 1/2] [Batch 940/1583] [D loss: 0.552419] [G loss: 0.210838]\n",
            "[Epoch 1/2] [Batch 941/1583] [D loss: 0.590007] [G loss: 0.211287]\n",
            "[Epoch 1/2] [Batch 942/1583] [D loss: 0.573943] [G loss: 0.211282]\n",
            "[Epoch 1/2] [Batch 943/1583] [D loss: 0.583376] [G loss: 0.204351]\n",
            "[Epoch 1/2] [Batch 944/1583] [D loss: 0.572560] [G loss: 0.215248]\n",
            "[Epoch 1/2] [Batch 945/1583] [D loss: 0.560593] [G loss: 0.204441]\n",
            "[Epoch 1/2] [Batch 946/1583] [D loss: 0.520846] [G loss: 0.204029]\n",
            "[Epoch 1/2] [Batch 947/1583] [D loss: 0.539767] [G loss: 0.207035]\n",
            "[Epoch 1/2] [Batch 948/1583] [D loss: 0.630041] [G loss: 0.216416]\n",
            "[Epoch 1/2] [Batch 949/1583] [D loss: 0.608107] [G loss: 0.223217]\n",
            "[Epoch 1/2] [Batch 950/1583] [D loss: 0.554438] [G loss: 0.208762]\n",
            "[Epoch 1/2] [Batch 951/1583] [D loss: 0.554640] [G loss: 0.214127]\n",
            "[Epoch 1/2] [Batch 952/1583] [D loss: 0.639243] [G loss: 0.214601]\n",
            "[Epoch 1/2] [Batch 953/1583] [D loss: 0.573365] [G loss: 0.202546]\n",
            "[Epoch 1/2] [Batch 954/1583] [D loss: 0.540106] [G loss: 0.200583]\n",
            "[Epoch 1/2] [Batch 955/1583] [D loss: 0.548324] [G loss: 0.210022]\n",
            "[Epoch 1/2] [Batch 956/1583] [D loss: 0.576759] [G loss: 0.209282]\n",
            "[Epoch 1/2] [Batch 957/1583] [D loss: 0.568856] [G loss: 0.207794]\n",
            "[Epoch 1/2] [Batch 958/1583] [D loss: 0.560662] [G loss: 0.205215]\n",
            "[Epoch 1/2] [Batch 959/1583] [D loss: 0.513678] [G loss: 0.210432]\n",
            "[Epoch 1/2] [Batch 960/1583] [D loss: 0.553189] [G loss: 0.196682]\n",
            "[Epoch 1/2] [Batch 961/1583] [D loss: 0.573033] [G loss: 0.218246]\n",
            "[Epoch 1/2] [Batch 962/1583] [D loss: 0.529281] [G loss: 0.210192]\n",
            "[Epoch 1/2] [Batch 963/1583] [D loss: 0.533889] [G loss: 0.204141]\n",
            "[Epoch 1/2] [Batch 964/1583] [D loss: 0.576271] [G loss: 0.211254]\n",
            "[Epoch 1/2] [Batch 965/1583] [D loss: 0.579190] [G loss: 0.210996]\n",
            "[Epoch 1/2] [Batch 966/1583] [D loss: 0.562525] [G loss: 0.207503]\n",
            "[Epoch 1/2] [Batch 967/1583] [D loss: 0.569695] [G loss: 0.216661]\n",
            "[Epoch 1/2] [Batch 968/1583] [D loss: 0.548880] [G loss: 0.215938]\n",
            "[Epoch 1/2] [Batch 969/1583] [D loss: 0.616462] [G loss: 0.214769]\n",
            "[Epoch 1/2] [Batch 970/1583] [D loss: 0.583097] [G loss: 0.208828]\n",
            "[Epoch 1/2] [Batch 971/1583] [D loss: 0.588616] [G loss: 0.217992]\n",
            "[Epoch 1/2] [Batch 972/1583] [D loss: 0.559473] [G loss: 0.218775]\n",
            "[Epoch 1/2] [Batch 973/1583] [D loss: 0.580940] [G loss: 0.202425]\n",
            "[Epoch 1/2] [Batch 974/1583] [D loss: 0.562324] [G loss: 0.211745]\n",
            "[Epoch 1/2] [Batch 975/1583] [D loss: 0.486823] [G loss: 0.196907]\n",
            "[Epoch 1/2] [Batch 976/1583] [D loss: 0.557882] [G loss: 0.213276]\n",
            "[Epoch 1/2] [Batch 977/1583] [D loss: 0.592750] [G loss: 0.208457]\n",
            "[Epoch 1/2] [Batch 978/1583] [D loss: 0.554809] [G loss: 0.206724]\n",
            "[Epoch 1/2] [Batch 979/1583] [D loss: 0.550636] [G loss: 0.216531]\n",
            "[Epoch 1/2] [Batch 980/1583] [D loss: 0.592316] [G loss: 0.205014]\n",
            "[Epoch 1/2] [Batch 981/1583] [D loss: 0.550592] [G loss: 0.205475]\n",
            "[Epoch 1/2] [Batch 982/1583] [D loss: 0.566029] [G loss: 0.214349]\n",
            "[Epoch 1/2] [Batch 983/1583] [D loss: 0.528761] [G loss: 0.210042]\n",
            "[Epoch 1/2] [Batch 984/1583] [D loss: 0.634489] [G loss: 0.211977]\n",
            "[Epoch 1/2] [Batch 985/1583] [D loss: 0.591950] [G loss: 0.211016]\n",
            "[Epoch 1/2] [Batch 986/1583] [D loss: 0.524424] [G loss: 0.204127]\n",
            "[Epoch 1/2] [Batch 987/1583] [D loss: 0.533411] [G loss: 0.207024]\n",
            "[Epoch 1/2] [Batch 988/1583] [D loss: 0.582280] [G loss: 0.213308]\n",
            "[Epoch 1/2] [Batch 989/1583] [D loss: 0.643781] [G loss: 0.212398]\n",
            "[Epoch 1/2] [Batch 990/1583] [D loss: 0.532151] [G loss: 0.207387]\n",
            "[Epoch 1/2] [Batch 991/1583] [D loss: 0.579493] [G loss: 0.204395]\n",
            "[Epoch 1/2] [Batch 992/1583] [D loss: 0.561423] [G loss: 0.207452]\n",
            "[Epoch 1/2] [Batch 993/1583] [D loss: 0.586061] [G loss: 0.206366]\n",
            "[Epoch 1/2] [Batch 994/1583] [D loss: 0.579191] [G loss: 0.217419]\n",
            "[Epoch 1/2] [Batch 995/1583] [D loss: 0.602514] [G loss: 0.204077]\n",
            "[Epoch 1/2] [Batch 996/1583] [D loss: 0.585198] [G loss: 0.200715]\n",
            "[Epoch 1/2] [Batch 997/1583] [D loss: 0.604288] [G loss: 0.210743]\n",
            "[Epoch 1/2] [Batch 998/1583] [D loss: 0.546532] [G loss: 0.203977]\n",
            "[Epoch 1/2] [Batch 999/1583] [D loss: 0.546448] [G loss: 0.207952]\n",
            "[Epoch 1/2] [Batch 1000/1583] [D loss: 0.586847] [G loss: 0.216249]\n",
            "[Epoch 1/2] [Batch 1001/1583] [D loss: 0.580431] [G loss: 0.215671]\n",
            "[Epoch 1/2] [Batch 1002/1583] [D loss: 0.562907] [G loss: 0.209391]\n",
            "[Epoch 1/2] [Batch 1003/1583] [D loss: 0.552231] [G loss: 0.207698]\n",
            "[Epoch 1/2] [Batch 1004/1583] [D loss: 0.616140] [G loss: 0.211816]\n",
            "[Epoch 1/2] [Batch 1005/1583] [D loss: 0.576662] [G loss: 0.210457]\n",
            "[Epoch 1/2] [Batch 1006/1583] [D loss: 0.604034] [G loss: 0.214515]\n",
            "[Epoch 1/2] [Batch 1007/1583] [D loss: 0.577399] [G loss: 0.218858]\n",
            "[Epoch 1/2] [Batch 1008/1583] [D loss: 0.573623] [G loss: 0.203028]\n",
            "[Epoch 1/2] [Batch 1009/1583] [D loss: 0.543744] [G loss: 0.208102]\n",
            "[Epoch 1/2] [Batch 1010/1583] [D loss: 0.594353] [G loss: 0.207313]\n",
            "[Epoch 1/2] [Batch 1011/1583] [D loss: 0.548326] [G loss: 0.209387]\n",
            "[Epoch 1/2] [Batch 1012/1583] [D loss: 0.566084] [G loss: 0.209099]\n",
            "[Epoch 1/2] [Batch 1013/1583] [D loss: 0.572097] [G loss: 0.209307]\n",
            "[Epoch 1/2] [Batch 1014/1583] [D loss: 0.517168] [G loss: 0.214646]\n",
            "[Epoch 1/2] [Batch 1015/1583] [D loss: 0.574968] [G loss: 0.208354]\n",
            "[Epoch 1/2] [Batch 1016/1583] [D loss: 0.535603] [G loss: 0.200287]\n",
            "[Epoch 1/2] [Batch 1017/1583] [D loss: 0.541133] [G loss: 0.210471]\n",
            "[Epoch 1/2] [Batch 1018/1583] [D loss: 0.549147] [G loss: 0.197414]\n",
            "[Epoch 1/2] [Batch 1019/1583] [D loss: 0.585242] [G loss: 0.211081]\n",
            "[Epoch 1/2] [Batch 1020/1583] [D loss: 0.568990] [G loss: 0.210375]\n",
            "[Epoch 1/2] [Batch 1021/1583] [D loss: 0.571055] [G loss: 0.212832]\n",
            "[Epoch 1/2] [Batch 1022/1583] [D loss: 0.538746] [G loss: 0.208245]\n",
            "[Epoch 1/2] [Batch 1023/1583] [D loss: 0.570192] [G loss: 0.216136]\n",
            "[Epoch 1/2] [Batch 1024/1583] [D loss: 0.569195] [G loss: 0.213305]\n",
            "[Epoch 1/2] [Batch 1025/1583] [D loss: 0.571021] [G loss: 0.206663]\n",
            "[Epoch 1/2] [Batch 1026/1583] [D loss: 0.568094] [G loss: 0.211488]\n",
            "[Epoch 1/2] [Batch 1027/1583] [D loss: 0.538871] [G loss: 0.209133]\n",
            "[Epoch 1/2] [Batch 1028/1583] [D loss: 0.577023] [G loss: 0.212736]\n",
            "[Epoch 1/2] [Batch 1029/1583] [D loss: 0.578355] [G loss: 0.206917]\n",
            "[Epoch 1/2] [Batch 1030/1583] [D loss: 0.621037] [G loss: 0.217802]\n",
            "[Epoch 1/2] [Batch 1031/1583] [D loss: 0.611527] [G loss: 0.216951]\n",
            "[Epoch 1/2] [Batch 1032/1583] [D loss: 0.586613] [G loss: 0.210638]\n",
            "[Epoch 1/2] [Batch 1033/1583] [D loss: 0.588983] [G loss: 0.209427]\n",
            "[Epoch 1/2] [Batch 1034/1583] [D loss: 0.559450] [G loss: 0.208293]\n",
            "[Epoch 1/2] [Batch 1035/1583] [D loss: 0.569813] [G loss: 0.214731]\n",
            "[Epoch 1/2] [Batch 1036/1583] [D loss: 0.523039] [G loss: 0.219017]\n",
            "[Epoch 1/2] [Batch 1037/1583] [D loss: 0.556273] [G loss: 0.209597]\n",
            "[Epoch 1/2] [Batch 1038/1583] [D loss: 0.562250] [G loss: 0.214502]\n",
            "[Epoch 1/2] [Batch 1039/1583] [D loss: 0.584081] [G loss: 0.213094]\n",
            "[Epoch 1/2] [Batch 1040/1583] [D loss: 0.557888] [G loss: 0.201231]\n",
            "[Epoch 1/2] [Batch 1041/1583] [D loss: 0.602008] [G loss: 0.208111]\n",
            "[Epoch 1/2] [Batch 1042/1583] [D loss: 0.538731] [G loss: 0.204142]\n",
            "[Epoch 1/2] [Batch 1043/1583] [D loss: 0.650143] [G loss: 0.217595]\n",
            "[Epoch 1/2] [Batch 1044/1583] [D loss: 0.566459] [G loss: 0.207115]\n",
            "[Epoch 1/2] [Batch 1045/1583] [D loss: 0.567082] [G loss: 0.209847]\n",
            "[Epoch 1/2] [Batch 1046/1583] [D loss: 0.522706] [G loss: 0.205685]\n",
            "[Epoch 1/2] [Batch 1047/1583] [D loss: 0.540228] [G loss: 0.207343]\n",
            "[Epoch 1/2] [Batch 1048/1583] [D loss: 0.526791] [G loss: 0.207009]\n",
            "[Epoch 1/2] [Batch 1049/1583] [D loss: 0.547651] [G loss: 0.195801]\n",
            "[Epoch 1/2] [Batch 1050/1583] [D loss: 0.585866] [G loss: 0.214624]\n",
            "[Epoch 1/2] [Batch 1051/1583] [D loss: 0.599485] [G loss: 0.210275]\n",
            "[Epoch 1/2] [Batch 1052/1583] [D loss: 0.577992] [G loss: 0.216310]\n",
            "[Epoch 1/2] [Batch 1053/1583] [D loss: 0.574719] [G loss: 0.213935]\n",
            "[Epoch 1/2] [Batch 1054/1583] [D loss: 0.551250] [G loss: 0.217240]\n",
            "[Epoch 1/2] [Batch 1055/1583] [D loss: 0.576494] [G loss: 0.213779]\n",
            "[Epoch 1/2] [Batch 1056/1583] [D loss: 0.579008] [G loss: 0.212158]\n",
            "[Epoch 1/2] [Batch 1057/1583] [D loss: 0.590297] [G loss: 0.205505]\n",
            "[Epoch 1/2] [Batch 1058/1583] [D loss: 0.590035] [G loss: 0.220238]\n",
            "[Epoch 1/2] [Batch 1059/1583] [D loss: 0.531364] [G loss: 0.209178]\n",
            "[Epoch 1/2] [Batch 1060/1583] [D loss: 0.554695] [G loss: 0.212000]\n",
            "[Epoch 1/2] [Batch 1061/1583] [D loss: 0.549541] [G loss: 0.209809]\n",
            "[Epoch 1/2] [Batch 1062/1583] [D loss: 0.572033] [G loss: 0.209911]\n",
            "[Epoch 1/2] [Batch 1063/1583] [D loss: 0.554939] [G loss: 0.212880]\n",
            "[Epoch 1/2] [Batch 1064/1583] [D loss: 0.576484] [G loss: 0.220085]\n",
            "[Epoch 1/2] [Batch 1065/1583] [D loss: 0.557520] [G loss: 0.201918]\n",
            "[Epoch 1/2] [Batch 1066/1583] [D loss: 0.538432] [G loss: 0.206845]\n",
            "[Epoch 1/2] [Batch 1067/1583] [D loss: 0.574236] [G loss: 0.204494]\n",
            "[Epoch 1/2] [Batch 1068/1583] [D loss: 0.548634] [G loss: 0.202385]\n",
            "[Epoch 1/2] [Batch 1069/1583] [D loss: 0.588570] [G loss: 0.201413]\n",
            "[Epoch 1/2] [Batch 1070/1583] [D loss: 0.556416] [G loss: 0.208388]\n",
            "[Epoch 1/2] [Batch 1071/1583] [D loss: 0.534492] [G loss: 0.204684]\n",
            "[Epoch 1/2] [Batch 1072/1583] [D loss: 0.563321] [G loss: 0.209386]\n",
            "[Epoch 1/2] [Batch 1073/1583] [D loss: 0.540390] [G loss: 0.211573]\n",
            "[Epoch 1/2] [Batch 1074/1583] [D loss: 0.509518] [G loss: 0.205079]\n",
            "[Epoch 1/2] [Batch 1075/1583] [D loss: 0.553554] [G loss: 0.211252]\n",
            "[Epoch 1/2] [Batch 1076/1583] [D loss: 0.542545] [G loss: 0.208431]\n",
            "[Epoch 1/2] [Batch 1077/1583] [D loss: 0.572904] [G loss: 0.211516]\n",
            "[Epoch 1/2] [Batch 1078/1583] [D loss: 0.558091] [G loss: 0.207243]\n",
            "[Epoch 1/2] [Batch 1079/1583] [D loss: 0.576848] [G loss: 0.215043]\n",
            "[Epoch 1/2] [Batch 1080/1583] [D loss: 0.563156] [G loss: 0.210785]\n",
            "[Epoch 1/2] [Batch 1081/1583] [D loss: 0.589189] [G loss: 0.203994]\n",
            "[Epoch 1/2] [Batch 1082/1583] [D loss: 0.537797] [G loss: 0.200440]\n",
            "[Epoch 1/2] [Batch 1083/1583] [D loss: 0.560649] [G loss: 0.204199]\n",
            "[Epoch 1/2] [Batch 1084/1583] [D loss: 0.578037] [G loss: 0.199395]\n",
            "[Epoch 1/2] [Batch 1085/1583] [D loss: 0.545957] [G loss: 0.207690]\n",
            "[Epoch 1/2] [Batch 1086/1583] [D loss: 0.607925] [G loss: 0.203043]\n",
            "[Epoch 1/2] [Batch 1087/1583] [D loss: 0.571023] [G loss: 0.204441]\n",
            "[Epoch 1/2] [Batch 1088/1583] [D loss: 0.635585] [G loss: 0.206648]\n",
            "[Epoch 1/2] [Batch 1089/1583] [D loss: 0.547720] [G loss: 0.215591]\n",
            "[Epoch 1/2] [Batch 1090/1583] [D loss: 0.551510] [G loss: 0.210440]\n",
            "[Epoch 1/2] [Batch 1091/1583] [D loss: 0.587064] [G loss: 0.215858]\n",
            "[Epoch 1/2] [Batch 1092/1583] [D loss: 0.593790] [G loss: 0.202518]\n",
            "[Epoch 1/2] [Batch 1093/1583] [D loss: 0.563520] [G loss: 0.213463]\n",
            "[Epoch 1/2] [Batch 1094/1583] [D loss: 0.573956] [G loss: 0.210842]\n",
            "[Epoch 1/2] [Batch 1095/1583] [D loss: 0.578681] [G loss: 0.204269]\n",
            "[Epoch 1/2] [Batch 1096/1583] [D loss: 0.602085] [G loss: 0.208796]\n",
            "[Epoch 1/2] [Batch 1097/1583] [D loss: 0.556030] [G loss: 0.202860]\n",
            "[Epoch 1/2] [Batch 1098/1583] [D loss: 0.637817] [G loss: 0.217029]\n",
            "[Epoch 1/2] [Batch 1099/1583] [D loss: 0.573960] [G loss: 0.217529]\n",
            "[Epoch 1/2] [Batch 1100/1583] [D loss: 0.570252] [G loss: 0.218230]\n",
            "[Epoch 1/2] [Batch 1101/1583] [D loss: 0.566643] [G loss: 0.207754]\n",
            "[Epoch 1/2] [Batch 1102/1583] [D loss: 0.539091] [G loss: 0.206704]\n",
            "[Epoch 1/2] [Batch 1103/1583] [D loss: 0.517709] [G loss: 0.207946]\n",
            "[Epoch 1/2] [Batch 1104/1583] [D loss: 0.559942] [G loss: 0.211851]\n",
            "[Epoch 1/2] [Batch 1105/1583] [D loss: 0.541987] [G loss: 0.212039]\n",
            "[Epoch 1/2] [Batch 1106/1583] [D loss: 0.549289] [G loss: 0.210525]\n",
            "[Epoch 1/2] [Batch 1107/1583] [D loss: 0.582574] [G loss: 0.212719]\n",
            "[Epoch 1/2] [Batch 1108/1583] [D loss: 0.560579] [G loss: 0.212975]\n",
            "[Epoch 1/2] [Batch 1109/1583] [D loss: 0.589875] [G loss: 0.212425]\n",
            "[Epoch 1/2] [Batch 1110/1583] [D loss: 0.556261] [G loss: 0.212697]\n",
            "[Epoch 1/2] [Batch 1111/1583] [D loss: 0.587317] [G loss: 0.216204]\n",
            "[Epoch 1/2] [Batch 1112/1583] [D loss: 0.536437] [G loss: 0.209825]\n",
            "[Epoch 1/2] [Batch 1113/1583] [D loss: 0.537594] [G loss: 0.219106]\n",
            "[Epoch 1/2] [Batch 1114/1583] [D loss: 0.571710] [G loss: 0.206945]\n",
            "[Epoch 1/2] [Batch 1115/1583] [D loss: 0.583003] [G loss: 0.211024]\n",
            "[Epoch 1/2] [Batch 1116/1583] [D loss: 0.567576] [G loss: 0.213457]\n",
            "[Epoch 1/2] [Batch 1117/1583] [D loss: 0.609926] [G loss: 0.203778]\n",
            "[Epoch 1/2] [Batch 1118/1583] [D loss: 0.533185] [G loss: 0.208541]\n",
            "[Epoch 1/2] [Batch 1119/1583] [D loss: 0.527106] [G loss: 0.194547]\n",
            "[Epoch 1/2] [Batch 1120/1583] [D loss: 0.571314] [G loss: 0.214374]\n",
            "[Epoch 1/2] [Batch 1121/1583] [D loss: 0.542296] [G loss: 0.207291]\n",
            "[Epoch 1/2] [Batch 1122/1583] [D loss: 0.523437] [G loss: 0.208651]\n",
            "[Epoch 1/2] [Batch 1123/1583] [D loss: 0.546996] [G loss: 0.208443]\n",
            "[Epoch 1/2] [Batch 1124/1583] [D loss: 0.567733] [G loss: 0.212257]\n",
            "[Epoch 1/2] [Batch 1125/1583] [D loss: 0.558239] [G loss: 0.205933]\n",
            "[Epoch 1/2] [Batch 1126/1583] [D loss: 0.579017] [G loss: 0.208929]\n",
            "[Epoch 1/2] [Batch 1127/1583] [D loss: 0.568481] [G loss: 0.205959]\n",
            "[Epoch 1/2] [Batch 1128/1583] [D loss: 0.526972] [G loss: 0.210610]\n",
            "[Epoch 1/2] [Batch 1129/1583] [D loss: 0.557775] [G loss: 0.205270]\n",
            "[Epoch 1/2] [Batch 1130/1583] [D loss: 0.595919] [G loss: 0.205034]\n",
            "[Epoch 1/2] [Batch 1131/1583] [D loss: 0.592339] [G loss: 0.207404]\n",
            "[Epoch 1/2] [Batch 1132/1583] [D loss: 0.558697] [G loss: 0.208527]\n",
            "[Epoch 1/2] [Batch 1133/1583] [D loss: 0.576855] [G loss: 0.202274]\n",
            "[Epoch 1/2] [Batch 1134/1583] [D loss: 0.564100] [G loss: 0.211143]\n",
            "[Epoch 1/2] [Batch 1135/1583] [D loss: 0.595625] [G loss: 0.205727]\n",
            "[Epoch 1/2] [Batch 1136/1583] [D loss: 0.582665] [G loss: 0.216507]\n",
            "[Epoch 1/2] [Batch 1137/1583] [D loss: 0.555720] [G loss: 0.216776]\n",
            "[Epoch 1/2] [Batch 1138/1583] [D loss: 0.557064] [G loss: 0.204257]\n",
            "[Epoch 1/2] [Batch 1139/1583] [D loss: 0.612094] [G loss: 0.218905]\n",
            "[Epoch 1/2] [Batch 1140/1583] [D loss: 0.509825] [G loss: 0.200758]\n",
            "[Epoch 1/2] [Batch 1141/1583] [D loss: 0.556003] [G loss: 0.208091]\n",
            "[Epoch 1/2] [Batch 1142/1583] [D loss: 0.519095] [G loss: 0.212059]\n",
            "[Epoch 1/2] [Batch 1143/1583] [D loss: 0.565377] [G loss: 0.216168]\n",
            "[Epoch 1/2] [Batch 1144/1583] [D loss: 0.545812] [G loss: 0.213261]\n",
            "[Epoch 1/2] [Batch 1145/1583] [D loss: 0.555512] [G loss: 0.207260]\n",
            "[Epoch 1/2] [Batch 1146/1583] [D loss: 0.519103] [G loss: 0.208022]\n",
            "[Epoch 1/2] [Batch 1147/1583] [D loss: 0.545055] [G loss: 0.210233]\n",
            "[Epoch 1/2] [Batch 1148/1583] [D loss: 0.568545] [G loss: 0.203952]\n",
            "[Epoch 1/2] [Batch 1149/1583] [D loss: 0.580613] [G loss: 0.208112]\n",
            "[Epoch 1/2] [Batch 1150/1583] [D loss: 0.566121] [G loss: 0.209303]\n",
            "[Epoch 1/2] [Batch 1151/1583] [D loss: 0.564781] [G loss: 0.208729]\n",
            "[Epoch 1/2] [Batch 1152/1583] [D loss: 0.588605] [G loss: 0.208870]\n",
            "[Epoch 1/2] [Batch 1153/1583] [D loss: 0.556355] [G loss: 0.209062]\n",
            "[Epoch 1/2] [Batch 1154/1583] [D loss: 0.549224] [G loss: 0.207895]\n",
            "[Epoch 1/2] [Batch 1155/1583] [D loss: 0.570688] [G loss: 0.204626]\n",
            "[Epoch 1/2] [Batch 1156/1583] [D loss: 0.574013] [G loss: 0.212018]\n",
            "[Epoch 1/2] [Batch 1157/1583] [D loss: 0.574037] [G loss: 0.216862]\n",
            "[Epoch 1/2] [Batch 1158/1583] [D loss: 0.585261] [G loss: 0.209196]\n",
            "[Epoch 1/2] [Batch 1159/1583] [D loss: 0.581562] [G loss: 0.216944]\n",
            "[Epoch 1/2] [Batch 1160/1583] [D loss: 0.587520] [G loss: 0.205817]\n",
            "[Epoch 1/2] [Batch 1161/1583] [D loss: 0.598726] [G loss: 0.207296]\n",
            "[Epoch 1/2] [Batch 1162/1583] [D loss: 0.595285] [G loss: 0.212846]\n",
            "[Epoch 1/2] [Batch 1163/1583] [D loss: 0.591363] [G loss: 0.214675]\n",
            "[Epoch 1/2] [Batch 1164/1583] [D loss: 0.569550] [G loss: 0.208628]\n",
            "[Epoch 1/2] [Batch 1165/1583] [D loss: 0.534108] [G loss: 0.210111]\n",
            "[Epoch 1/2] [Batch 1166/1583] [D loss: 0.547042] [G loss: 0.203832]\n",
            "[Epoch 1/2] [Batch 1167/1583] [D loss: 0.564815] [G loss: 0.200545]\n",
            "[Epoch 1/2] [Batch 1168/1583] [D loss: 0.558071] [G loss: 0.210877]\n",
            "[Epoch 1/2] [Batch 1169/1583] [D loss: 0.585690] [G loss: 0.210100]\n",
            "[Epoch 1/2] [Batch 1170/1583] [D loss: 0.572639] [G loss: 0.211940]\n",
            "[Epoch 1/2] [Batch 1171/1583] [D loss: 0.589363] [G loss: 0.219602]\n",
            "[Epoch 1/2] [Batch 1172/1583] [D loss: 0.547557] [G loss: 0.203940]\n",
            "[Epoch 1/2] [Batch 1173/1583] [D loss: 0.526877] [G loss: 0.199598]\n",
            "[Epoch 1/2] [Batch 1174/1583] [D loss: 0.552830] [G loss: 0.206103]\n",
            "[Epoch 1/2] [Batch 1175/1583] [D loss: 0.577525] [G loss: 0.208160]\n",
            "[Epoch 1/2] [Batch 1176/1583] [D loss: 0.576464] [G loss: 0.210966]\n",
            "[Epoch 1/2] [Batch 1177/1583] [D loss: 0.591812] [G loss: 0.213625]\n",
            "[Epoch 1/2] [Batch 1178/1583] [D loss: 0.580349] [G loss: 0.215095]\n",
            "[Epoch 1/2] [Batch 1179/1583] [D loss: 0.558711] [G loss: 0.213608]\n",
            "[Epoch 1/2] [Batch 1180/1583] [D loss: 0.552137] [G loss: 0.206616]\n",
            "[Epoch 1/2] [Batch 1181/1583] [D loss: 0.535200] [G loss: 0.210070]\n",
            "[Epoch 1/2] [Batch 1182/1583] [D loss: 0.579058] [G loss: 0.205817]\n",
            "[Epoch 1/2] [Batch 1183/1583] [D loss: 0.592705] [G loss: 0.210171]\n",
            "[Epoch 1/2] [Batch 1184/1583] [D loss: 0.547437] [G loss: 0.206681]\n",
            "[Epoch 1/2] [Batch 1185/1583] [D loss: 0.576229] [G loss: 0.216365]\n",
            "[Epoch 1/2] [Batch 1186/1583] [D loss: 0.603587] [G loss: 0.211126]\n",
            "[Epoch 1/2] [Batch 1187/1583] [D loss: 0.571932] [G loss: 0.208379]\n",
            "[Epoch 1/2] [Batch 1188/1583] [D loss: 0.576755] [G loss: 0.202675]\n",
            "[Epoch 1/2] [Batch 1189/1583] [D loss: 0.616041] [G loss: 0.210981]\n",
            "[Epoch 1/2] [Batch 1190/1583] [D loss: 0.573332] [G loss: 0.210466]\n",
            "[Epoch 1/2] [Batch 1191/1583] [D loss: 0.548966] [G loss: 0.202904]\n",
            "[Epoch 1/2] [Batch 1192/1583] [D loss: 0.590403] [G loss: 0.202902]\n",
            "[Epoch 1/2] [Batch 1193/1583] [D loss: 0.538233] [G loss: 0.207649]\n",
            "[Epoch 1/2] [Batch 1194/1583] [D loss: 0.556950] [G loss: 0.209521]\n",
            "[Epoch 1/2] [Batch 1195/1583] [D loss: 0.571570] [G loss: 0.206255]\n",
            "[Epoch 1/2] [Batch 1196/1583] [D loss: 0.581210] [G loss: 0.208371]\n",
            "[Epoch 1/2] [Batch 1197/1583] [D loss: 0.580886] [G loss: 0.208954]\n",
            "[Epoch 1/2] [Batch 1198/1583] [D loss: 0.592436] [G loss: 0.208704]\n",
            "[Epoch 1/2] [Batch 1199/1583] [D loss: 0.558817] [G loss: 0.207950]\n",
            "[Epoch 1/2] [Batch 1200/1583] [D loss: 0.563898] [G loss: 0.207089]\n",
            "[Epoch 1/2] [Batch 1201/1583] [D loss: 0.605271] [G loss: 0.207697]\n",
            "[Epoch 1/2] [Batch 1202/1583] [D loss: 0.555008] [G loss: 0.207777]\n",
            "[Epoch 1/2] [Batch 1203/1583] [D loss: 0.581360] [G loss: 0.203533]\n",
            "[Epoch 1/2] [Batch 1204/1583] [D loss: 0.588609] [G loss: 0.212989]\n",
            "[Epoch 1/2] [Batch 1205/1583] [D loss: 0.529762] [G loss: 0.207605]\n",
            "[Epoch 1/2] [Batch 1206/1583] [D loss: 0.582901] [G loss: 0.209505]\n",
            "[Epoch 1/2] [Batch 1207/1583] [D loss: 0.584643] [G loss: 0.206750]\n",
            "[Epoch 1/2] [Batch 1208/1583] [D loss: 0.560770] [G loss: 0.209295]\n",
            "[Epoch 1/2] [Batch 1209/1583] [D loss: 0.557079] [G loss: 0.213844]\n",
            "[Epoch 1/2] [Batch 1210/1583] [D loss: 0.577588] [G loss: 0.212338]\n",
            "[Epoch 1/2] [Batch 1211/1583] [D loss: 0.565203] [G loss: 0.205443]\n",
            "[Epoch 1/2] [Batch 1212/1583] [D loss: 0.567307] [G loss: 0.209853]\n",
            "[Epoch 1/2] [Batch 1213/1583] [D loss: 0.578012] [G loss: 0.202811]\n",
            "[Epoch 1/2] [Batch 1214/1583] [D loss: 0.599346] [G loss: 0.213495]\n",
            "[Epoch 1/2] [Batch 1215/1583] [D loss: 0.598202] [G loss: 0.215913]\n",
            "[Epoch 1/2] [Batch 1216/1583] [D loss: 0.581572] [G loss: 0.203628]\n",
            "[Epoch 1/2] [Batch 1217/1583] [D loss: 0.542412] [G loss: 0.210206]\n",
            "[Epoch 1/2] [Batch 1218/1583] [D loss: 0.557375] [G loss: 0.200901]\n",
            "[Epoch 1/2] [Batch 1219/1583] [D loss: 0.582416] [G loss: 0.198269]\n",
            "[Epoch 1/2] [Batch 1220/1583] [D loss: 0.563226] [G loss: 0.203200]\n",
            "[Epoch 1/2] [Batch 1221/1583] [D loss: 0.536142] [G loss: 0.214537]\n",
            "[Epoch 1/2] [Batch 1222/1583] [D loss: 0.598228] [G loss: 0.215123]\n",
            "[Epoch 1/2] [Batch 1223/1583] [D loss: 0.552339] [G loss: 0.204694]\n",
            "[Epoch 1/2] [Batch 1224/1583] [D loss: 0.573816] [G loss: 0.215605]\n",
            "[Epoch 1/2] [Batch 1225/1583] [D loss: 0.579653] [G loss: 0.203723]\n",
            "[Epoch 1/2] [Batch 1226/1583] [D loss: 0.601971] [G loss: 0.214009]\n",
            "[Epoch 1/2] [Batch 1227/1583] [D loss: 0.566096] [G loss: 0.202999]\n",
            "[Epoch 1/2] [Batch 1228/1583] [D loss: 0.571315] [G loss: 0.206166]\n",
            "[Epoch 1/2] [Batch 1229/1583] [D loss: 0.569393] [G loss: 0.211766]\n",
            "[Epoch 1/2] [Batch 1230/1583] [D loss: 0.559630] [G loss: 0.198168]\n",
            "[Epoch 1/2] [Batch 1231/1583] [D loss: 0.542156] [G loss: 0.207235]\n",
            "[Epoch 1/2] [Batch 1232/1583] [D loss: 0.535453] [G loss: 0.211457]\n",
            "[Epoch 1/2] [Batch 1233/1583] [D loss: 0.551318] [G loss: 0.201852]\n",
            "[Epoch 1/2] [Batch 1234/1583] [D loss: 0.608964] [G loss: 0.206646]\n",
            "[Epoch 1/2] [Batch 1235/1583] [D loss: 0.568685] [G loss: 0.205561]\n",
            "[Epoch 1/2] [Batch 1236/1583] [D loss: 0.571389] [G loss: 0.211966]\n",
            "[Epoch 1/2] [Batch 1237/1583] [D loss: 0.557651] [G loss: 0.207795]\n",
            "[Epoch 1/2] [Batch 1238/1583] [D loss: 0.573295] [G loss: 0.214313]\n",
            "[Epoch 1/2] [Batch 1239/1583] [D loss: 0.554336] [G loss: 0.206884]\n",
            "[Epoch 1/2] [Batch 1240/1583] [D loss: 0.586111] [G loss: 0.218042]\n",
            "[Epoch 1/2] [Batch 1241/1583] [D loss: 0.551105] [G loss: 0.215691]\n",
            "[Epoch 1/2] [Batch 1242/1583] [D loss: 0.547186] [G loss: 0.205013]\n",
            "[Epoch 1/2] [Batch 1243/1583] [D loss: 0.533920] [G loss: 0.201374]\n",
            "[Epoch 1/2] [Batch 1244/1583] [D loss: 0.551869] [G loss: 0.210509]\n",
            "[Epoch 1/2] [Batch 1245/1583] [D loss: 0.640040] [G loss: 0.204448]\n",
            "[Epoch 1/2] [Batch 1246/1583] [D loss: 0.596920] [G loss: 0.209197]\n",
            "[Epoch 1/2] [Batch 1247/1583] [D loss: 0.564177] [G loss: 0.210471]\n",
            "[Epoch 1/2] [Batch 1248/1583] [D loss: 0.568924] [G loss: 0.217927]\n",
            "[Epoch 1/2] [Batch 1249/1583] [D loss: 0.559365] [G loss: 0.217831]\n",
            "[Epoch 1/2] [Batch 1250/1583] [D loss: 0.583910] [G loss: 0.203708]\n",
            "[Epoch 1/2] [Batch 1251/1583] [D loss: 0.552693] [G loss: 0.209768]\n",
            "[Epoch 1/2] [Batch 1252/1583] [D loss: 0.532115] [G loss: 0.206899]\n",
            "[Epoch 1/2] [Batch 1253/1583] [D loss: 0.531062] [G loss: 0.209487]\n",
            "[Epoch 1/2] [Batch 1254/1583] [D loss: 0.540103] [G loss: 0.210507]\n",
            "[Epoch 1/2] [Batch 1255/1583] [D loss: 0.540099] [G loss: 0.212763]\n",
            "[Epoch 1/2] [Batch 1256/1583] [D loss: 0.609328] [G loss: 0.199924]\n",
            "[Epoch 1/2] [Batch 1257/1583] [D loss: 0.544874] [G loss: 0.205260]\n",
            "[Epoch 1/2] [Batch 1258/1583] [D loss: 0.536958] [G loss: 0.201945]\n",
            "[Epoch 1/2] [Batch 1259/1583] [D loss: 0.561299] [G loss: 0.205127]\n",
            "[Epoch 1/2] [Batch 1260/1583] [D loss: 0.523567] [G loss: 0.206697]\n",
            "[Epoch 1/2] [Batch 1261/1583] [D loss: 0.569691] [G loss: 0.213218]\n",
            "[Epoch 1/2] [Batch 1262/1583] [D loss: 0.560643] [G loss: 0.206610]\n",
            "[Epoch 1/2] [Batch 1263/1583] [D loss: 0.571520] [G loss: 0.200621]\n",
            "[Epoch 1/2] [Batch 1264/1583] [D loss: 0.602471] [G loss: 0.215238]\n",
            "[Epoch 1/2] [Batch 1265/1583] [D loss: 0.607284] [G loss: 0.209869]\n",
            "[Epoch 1/2] [Batch 1266/1583] [D loss: 0.606494] [G loss: 0.212194]\n",
            "[Epoch 1/2] [Batch 1267/1583] [D loss: 0.587630] [G loss: 0.211044]\n",
            "[Epoch 1/2] [Batch 1268/1583] [D loss: 0.604690] [G loss: 0.207995]\n",
            "[Epoch 1/2] [Batch 1269/1583] [D loss: 0.553052] [G loss: 0.222904]\n",
            "[Epoch 1/2] [Batch 1270/1583] [D loss: 0.616031] [G loss: 0.204047]\n",
            "[Epoch 1/2] [Batch 1271/1583] [D loss: 0.553802] [G loss: 0.203320]\n",
            "[Epoch 1/2] [Batch 1272/1583] [D loss: 0.533695] [G loss: 0.205433]\n",
            "[Epoch 1/2] [Batch 1273/1583] [D loss: 0.568030] [G loss: 0.216924]\n",
            "[Epoch 1/2] [Batch 1274/1583] [D loss: 0.543760] [G loss: 0.215366]\n",
            "[Epoch 1/2] [Batch 1275/1583] [D loss: 0.587495] [G loss: 0.202006]\n",
            "[Epoch 1/2] [Batch 1276/1583] [D loss: 0.524610] [G loss: 0.206566]\n",
            "[Epoch 1/2] [Batch 1277/1583] [D loss: 0.586736] [G loss: 0.200320]\n",
            "[Epoch 1/2] [Batch 1278/1583] [D loss: 0.538055] [G loss: 0.199249]\n",
            "[Epoch 1/2] [Batch 1279/1583] [D loss: 0.612779] [G loss: 0.212222]\n",
            "[Epoch 1/2] [Batch 1280/1583] [D loss: 0.612831] [G loss: 0.211801]\n",
            "[Epoch 1/2] [Batch 1281/1583] [D loss: 0.575745] [G loss: 0.217424]\n",
            "[Epoch 1/2] [Batch 1282/1583] [D loss: 0.504625] [G loss: 0.207739]\n",
            "[Epoch 1/2] [Batch 1283/1583] [D loss: 0.592271] [G loss: 0.207860]\n",
            "[Epoch 1/2] [Batch 1284/1583] [D loss: 0.567866] [G loss: 0.199019]\n",
            "[Epoch 1/2] [Batch 1285/1583] [D loss: 0.546840] [G loss: 0.202792]\n",
            "[Epoch 1/2] [Batch 1286/1583] [D loss: 0.513951] [G loss: 0.202393]\n",
            "[Epoch 1/2] [Batch 1287/1583] [D loss: 0.579096] [G loss: 0.216685]\n",
            "[Epoch 1/2] [Batch 1288/1583] [D loss: 0.534222] [G loss: 0.201488]\n",
            "[Epoch 1/2] [Batch 1289/1583] [D loss: 0.549547] [G loss: 0.211229]\n",
            "[Epoch 1/2] [Batch 1290/1583] [D loss: 0.561546] [G loss: 0.207746]\n",
            "[Epoch 1/2] [Batch 1291/1583] [D loss: 0.539893] [G loss: 0.209933]\n",
            "[Epoch 1/2] [Batch 1292/1583] [D loss: 0.575155] [G loss: 0.199485]\n",
            "[Epoch 1/2] [Batch 1293/1583] [D loss: 0.535490] [G loss: 0.206060]\n",
            "[Epoch 1/2] [Batch 1294/1583] [D loss: 0.582219] [G loss: 0.216614]\n",
            "[Epoch 1/2] [Batch 1295/1583] [D loss: 0.529457] [G loss: 0.209522]\n",
            "[Epoch 1/2] [Batch 1296/1583] [D loss: 0.551054] [G loss: 0.205507]\n",
            "[Epoch 1/2] [Batch 1297/1583] [D loss: 0.532516] [G loss: 0.202474]\n",
            "[Epoch 1/2] [Batch 1298/1583] [D loss: 0.546002] [G loss: 0.205790]\n",
            "[Epoch 1/2] [Batch 1299/1583] [D loss: 0.550886] [G loss: 0.206020]\n",
            "[Epoch 1/2] [Batch 1300/1583] [D loss: 0.586406] [G loss: 0.217085]\n",
            "[Epoch 1/2] [Batch 1301/1583] [D loss: 0.619651] [G loss: 0.210963]\n",
            "[Epoch 1/2] [Batch 1302/1583] [D loss: 0.555030] [G loss: 0.209140]\n",
            "[Epoch 1/2] [Batch 1303/1583] [D loss: 0.577704] [G loss: 0.212231]\n",
            "[Epoch 1/2] [Batch 1304/1583] [D loss: 0.546496] [G loss: 0.201283]\n",
            "[Epoch 1/2] [Batch 1305/1583] [D loss: 0.558035] [G loss: 0.210581]\n",
            "[Epoch 1/2] [Batch 1306/1583] [D loss: 0.524749] [G loss: 0.200118]\n",
            "[Epoch 1/2] [Batch 1307/1583] [D loss: 0.604896] [G loss: 0.210822]\n",
            "[Epoch 1/2] [Batch 1308/1583] [D loss: 0.593630] [G loss: 0.205278]\n",
            "[Epoch 1/2] [Batch 1309/1583] [D loss: 0.563607] [G loss: 0.209336]\n",
            "[Epoch 1/2] [Batch 1310/1583] [D loss: 0.543658] [G loss: 0.206238]\n",
            "[Epoch 1/2] [Batch 1311/1583] [D loss: 0.564028] [G loss: 0.219065]\n",
            "[Epoch 1/2] [Batch 1312/1583] [D loss: 0.527288] [G loss: 0.206668]\n",
            "[Epoch 1/2] [Batch 1313/1583] [D loss: 0.621795] [G loss: 0.208849]\n",
            "[Epoch 1/2] [Batch 1314/1583] [D loss: 0.533081] [G loss: 0.214899]\n",
            "[Epoch 1/2] [Batch 1315/1583] [D loss: 0.580012] [G loss: 0.212715]\n",
            "[Epoch 1/2] [Batch 1316/1583] [D loss: 0.570654] [G loss: 0.221846]\n",
            "[Epoch 1/2] [Batch 1317/1583] [D loss: 0.559033] [G loss: 0.212368]\n",
            "[Epoch 1/2] [Batch 1318/1583] [D loss: 0.548404] [G loss: 0.198192]\n",
            "[Epoch 1/2] [Batch 1319/1583] [D loss: 0.590999] [G loss: 0.205061]\n",
            "[Epoch 1/2] [Batch 1320/1583] [D loss: 0.588309] [G loss: 0.209647]\n",
            "[Epoch 1/2] [Batch 1321/1583] [D loss: 0.587865] [G loss: 0.208551]\n",
            "[Epoch 1/2] [Batch 1322/1583] [D loss: 0.560216] [G loss: 0.202714]\n",
            "[Epoch 1/2] [Batch 1323/1583] [D loss: 0.574674] [G loss: 0.218091]\n",
            "[Epoch 1/2] [Batch 1324/1583] [D loss: 0.534347] [G loss: 0.204587]\n",
            "[Epoch 1/2] [Batch 1325/1583] [D loss: 0.563740] [G loss: 0.207708]\n",
            "[Epoch 1/2] [Batch 1326/1583] [D loss: 0.559251] [G loss: 0.218210]\n",
            "[Epoch 1/2] [Batch 1327/1583] [D loss: 0.592945] [G loss: 0.204516]\n",
            "[Epoch 1/2] [Batch 1328/1583] [D loss: 0.538887] [G loss: 0.207755]\n",
            "[Epoch 1/2] [Batch 1329/1583] [D loss: 0.559952] [G loss: 0.209124]\n",
            "[Epoch 1/2] [Batch 1330/1583] [D loss: 0.576450] [G loss: 0.213504]\n",
            "[Epoch 1/2] [Batch 1331/1583] [D loss: 0.555036] [G loss: 0.206239]\n",
            "[Epoch 1/2] [Batch 1332/1583] [D loss: 0.568570] [G loss: 0.209438]\n",
            "[Epoch 1/2] [Batch 1333/1583] [D loss: 0.597311] [G loss: 0.207926]\n",
            "[Epoch 1/2] [Batch 1334/1583] [D loss: 0.545395] [G loss: 0.209568]\n",
            "[Epoch 1/2] [Batch 1335/1583] [D loss: 0.559487] [G loss: 0.206796]\n",
            "[Epoch 1/2] [Batch 1336/1583] [D loss: 0.549037] [G loss: 0.208396]\n",
            "[Epoch 1/2] [Batch 1337/1583] [D loss: 0.563616] [G loss: 0.197312]\n",
            "[Epoch 1/2] [Batch 1338/1583] [D loss: 0.588740] [G loss: 0.204500]\n",
            "[Epoch 1/2] [Batch 1339/1583] [D loss: 0.553566] [G loss: 0.206492]\n",
            "[Epoch 1/2] [Batch 1340/1583] [D loss: 0.617146] [G loss: 0.204035]\n",
            "[Epoch 1/2] [Batch 1341/1583] [D loss: 0.554288] [G loss: 0.205160]\n",
            "[Epoch 1/2] [Batch 1342/1583] [D loss: 0.533528] [G loss: 0.202645]\n",
            "[Epoch 1/2] [Batch 1343/1583] [D loss: 0.588623] [G loss: 0.201038]\n",
            "[Epoch 1/2] [Batch 1344/1583] [D loss: 0.552425] [G loss: 0.211049]\n",
            "[Epoch 1/2] [Batch 1345/1583] [D loss: 0.560355] [G loss: 0.208018]\n",
            "[Epoch 1/2] [Batch 1346/1583] [D loss: 0.559038] [G loss: 0.200637]\n",
            "[Epoch 1/2] [Batch 1347/1583] [D loss: 0.566998] [G loss: 0.211925]\n",
            "[Epoch 1/2] [Batch 1348/1583] [D loss: 0.571470] [G loss: 0.210015]\n",
            "[Epoch 1/2] [Batch 1349/1583] [D loss: 0.559787] [G loss: 0.209188]\n",
            "[Epoch 1/2] [Batch 1350/1583] [D loss: 0.573504] [G loss: 0.209313]\n",
            "[Epoch 1/2] [Batch 1351/1583] [D loss: 0.550969] [G loss: 0.220886]\n",
            "[Epoch 1/2] [Batch 1352/1583] [D loss: 0.555008] [G loss: 0.212488]\n",
            "[Epoch 1/2] [Batch 1353/1583] [D loss: 0.564367] [G loss: 0.203126]\n",
            "[Epoch 1/2] [Batch 1354/1583] [D loss: 0.594227] [G loss: 0.215172]\n",
            "[Epoch 1/2] [Batch 1355/1583] [D loss: 0.512665] [G loss: 0.204363]\n",
            "[Epoch 1/2] [Batch 1356/1583] [D loss: 0.567167] [G loss: 0.209050]\n",
            "[Epoch 1/2] [Batch 1357/1583] [D loss: 0.593837] [G loss: 0.200915]\n",
            "[Epoch 1/2] [Batch 1358/1583] [D loss: 0.539742] [G loss: 0.203923]\n",
            "[Epoch 1/2] [Batch 1359/1583] [D loss: 0.594517] [G loss: 0.202817]\n",
            "[Epoch 1/2] [Batch 1360/1583] [D loss: 0.525817] [G loss: 0.200672]\n",
            "[Epoch 1/2] [Batch 1361/1583] [D loss: 0.530239] [G loss: 0.196006]\n",
            "[Epoch 1/2] [Batch 1362/1583] [D loss: 0.611341] [G loss: 0.214327]\n",
            "[Epoch 1/2] [Batch 1363/1583] [D loss: 0.576415] [G loss: 0.206715]\n",
            "[Epoch 1/2] [Batch 1364/1583] [D loss: 0.587778] [G loss: 0.199858]\n",
            "[Epoch 1/2] [Batch 1365/1583] [D loss: 0.541376] [G loss: 0.216911]\n",
            "[Epoch 1/2] [Batch 1366/1583] [D loss: 0.546495] [G loss: 0.208733]\n",
            "[Epoch 1/2] [Batch 1367/1583] [D loss: 0.590030] [G loss: 0.212579]\n",
            "[Epoch 1/2] [Batch 1368/1583] [D loss: 0.509502] [G loss: 0.206637]\n",
            "[Epoch 1/2] [Batch 1369/1583] [D loss: 0.581430] [G loss: 0.200849]\n",
            "[Epoch 1/2] [Batch 1370/1583] [D loss: 0.606765] [G loss: 0.208529]\n",
            "[Epoch 1/2] [Batch 1371/1583] [D loss: 0.590401] [G loss: 0.211277]\n",
            "[Epoch 1/2] [Batch 1372/1583] [D loss: 0.613327] [G loss: 0.205276]\n",
            "[Epoch 1/2] [Batch 1373/1583] [D loss: 0.551562] [G loss: 0.214581]\n",
            "[Epoch 1/2] [Batch 1374/1583] [D loss: 0.573686] [G loss: 0.207224]\n",
            "[Epoch 1/2] [Batch 1375/1583] [D loss: 0.564356] [G loss: 0.201113]\n",
            "[Epoch 1/2] [Batch 1376/1583] [D loss: 0.571321] [G loss: 0.208233]\n",
            "[Epoch 1/2] [Batch 1377/1583] [D loss: 0.578020] [G loss: 0.216088]\n",
            "[Epoch 1/2] [Batch 1378/1583] [D loss: 0.576803] [G loss: 0.206533]\n",
            "[Epoch 1/2] [Batch 1379/1583] [D loss: 0.599087] [G loss: 0.210742]\n",
            "[Epoch 1/2] [Batch 1380/1583] [D loss: 0.560511] [G loss: 0.213212]\n",
            "[Epoch 1/2] [Batch 1381/1583] [D loss: 0.577838] [G loss: 0.196215]\n",
            "[Epoch 1/2] [Batch 1382/1583] [D loss: 0.571502] [G loss: 0.211271]\n",
            "[Epoch 1/2] [Batch 1383/1583] [D loss: 0.545071] [G loss: 0.216153]\n",
            "[Epoch 1/2] [Batch 1384/1583] [D loss: 0.599076] [G loss: 0.209520]\n",
            "[Epoch 1/2] [Batch 1385/1583] [D loss: 0.587108] [G loss: 0.222332]\n",
            "[Epoch 1/2] [Batch 1386/1583] [D loss: 0.571264] [G loss: 0.211095]\n",
            "[Epoch 1/2] [Batch 1387/1583] [D loss: 0.599647] [G loss: 0.207755]\n",
            "[Epoch 1/2] [Batch 1388/1583] [D loss: 0.509682] [G loss: 0.219259]\n",
            "[Epoch 1/2] [Batch 1389/1583] [D loss: 0.582667] [G loss: 0.207552]\n",
            "[Epoch 1/2] [Batch 1390/1583] [D loss: 0.587407] [G loss: 0.217053]\n",
            "[Epoch 1/2] [Batch 1391/1583] [D loss: 0.548649] [G loss: 0.209900]\n",
            "[Epoch 1/2] [Batch 1392/1583] [D loss: 0.564535] [G loss: 0.214246]\n",
            "[Epoch 1/2] [Batch 1393/1583] [D loss: 0.569267] [G loss: 0.204862]\n",
            "[Epoch 1/2] [Batch 1394/1583] [D loss: 0.614494] [G loss: 0.214323]\n",
            "[Epoch 1/2] [Batch 1395/1583] [D loss: 0.540578] [G loss: 0.210306]\n",
            "[Epoch 1/2] [Batch 1396/1583] [D loss: 0.579069] [G loss: 0.202623]\n",
            "[Epoch 1/2] [Batch 1397/1583] [D loss: 0.561160] [G loss: 0.200859]\n",
            "[Epoch 1/2] [Batch 1398/1583] [D loss: 0.525821] [G loss: 0.207160]\n",
            "[Epoch 1/2] [Batch 1399/1583] [D loss: 0.535693] [G loss: 0.202880]\n",
            "[Epoch 1/2] [Batch 1400/1583] [D loss: 0.558736] [G loss: 0.212191]\n",
            "[Epoch 1/2] [Batch 1401/1583] [D loss: 0.579654] [G loss: 0.212509]\n",
            "[Epoch 1/2] [Batch 1402/1583] [D loss: 0.552179] [G loss: 0.200229]\n",
            "[Epoch 1/2] [Batch 1403/1583] [D loss: 0.540814] [G loss: 0.203752]\n",
            "[Epoch 1/2] [Batch 1404/1583] [D loss: 0.582145] [G loss: 0.210192]\n",
            "[Epoch 1/2] [Batch 1405/1583] [D loss: 0.560585] [G loss: 0.206375]\n",
            "[Epoch 1/2] [Batch 1406/1583] [D loss: 0.579080] [G loss: 0.212246]\n",
            "[Epoch 1/2] [Batch 1407/1583] [D loss: 0.558449] [G loss: 0.204991]\n",
            "[Epoch 1/2] [Batch 1408/1583] [D loss: 0.592122] [G loss: 0.205895]\n",
            "[Epoch 1/2] [Batch 1409/1583] [D loss: 0.498640] [G loss: 0.197599]\n",
            "[Epoch 1/2] [Batch 1410/1583] [D loss: 0.546601] [G loss: 0.207981]\n",
            "[Epoch 1/2] [Batch 1411/1583] [D loss: 0.545182] [G loss: 0.201117]\n",
            "[Epoch 1/2] [Batch 1412/1583] [D loss: 0.539445] [G loss: 0.200197]\n",
            "[Epoch 1/2] [Batch 1413/1583] [D loss: 0.537786] [G loss: 0.210258]\n",
            "[Epoch 1/2] [Batch 1414/1583] [D loss: 0.565362] [G loss: 0.201217]\n",
            "[Epoch 1/2] [Batch 1415/1583] [D loss: 0.563266] [G loss: 0.208299]\n",
            "[Epoch 1/2] [Batch 1416/1583] [D loss: 0.580496] [G loss: 0.209345]\n",
            "[Epoch 1/2] [Batch 1417/1583] [D loss: 0.552634] [G loss: 0.209912]\n",
            "[Epoch 1/2] [Batch 1418/1583] [D loss: 0.560608] [G loss: 0.206885]\n",
            "[Epoch 1/2] [Batch 1419/1583] [D loss: 0.547075] [G loss: 0.210363]\n",
            "[Epoch 1/2] [Batch 1420/1583] [D loss: 0.553961] [G loss: 0.204581]\n",
            "[Epoch 1/2] [Batch 1421/1583] [D loss: 0.560793] [G loss: 0.204296]\n",
            "[Epoch 1/2] [Batch 1422/1583] [D loss: 0.559576] [G loss: 0.214493]\n",
            "[Epoch 1/2] [Batch 1423/1583] [D loss: 0.577609] [G loss: 0.208101]\n",
            "[Epoch 1/2] [Batch 1424/1583] [D loss: 0.544671] [G loss: 0.206461]\n",
            "[Epoch 1/2] [Batch 1425/1583] [D loss: 0.510236] [G loss: 0.192450]\n",
            "[Epoch 1/2] [Batch 1426/1583] [D loss: 0.592434] [G loss: 0.216433]\n",
            "[Epoch 1/2] [Batch 1427/1583] [D loss: 0.565792] [G loss: 0.204433]\n",
            "[Epoch 1/2] [Batch 1428/1583] [D loss: 0.566150] [G loss: 0.209254]\n",
            "[Epoch 1/2] [Batch 1429/1583] [D loss: 0.581507] [G loss: 0.214128]\n",
            "[Epoch 1/2] [Batch 1430/1583] [D loss: 0.587608] [G loss: 0.208487]\n",
            "[Epoch 1/2] [Batch 1431/1583] [D loss: 0.582113] [G loss: 0.207489]\n",
            "[Epoch 1/2] [Batch 1432/1583] [D loss: 0.551236] [G loss: 0.205530]\n",
            "[Epoch 1/2] [Batch 1433/1583] [D loss: 0.571523] [G loss: 0.207441]\n",
            "[Epoch 1/2] [Batch 1434/1583] [D loss: 0.578829] [G loss: 0.216588]\n",
            "[Epoch 1/2] [Batch 1435/1583] [D loss: 0.547557] [G loss: 0.202465]\n",
            "[Epoch 1/2] [Batch 1436/1583] [D loss: 0.540676] [G loss: 0.210476]\n",
            "[Epoch 1/2] [Batch 1437/1583] [D loss: 0.521793] [G loss: 0.211488]\n",
            "[Epoch 1/2] [Batch 1438/1583] [D loss: 0.599500] [G loss: 0.209243]\n",
            "[Epoch 1/2] [Batch 1439/1583] [D loss: 0.555980] [G loss: 0.210419]\n",
            "[Epoch 1/2] [Batch 1440/1583] [D loss: 0.596539] [G loss: 0.212272]\n",
            "[Epoch 1/2] [Batch 1441/1583] [D loss: 0.587085] [G loss: 0.211085]\n",
            "[Epoch 1/2] [Batch 1442/1583] [D loss: 0.608654] [G loss: 0.219898]\n",
            "[Epoch 1/2] [Batch 1443/1583] [D loss: 0.551587] [G loss: 0.212762]\n",
            "[Epoch 1/2] [Batch 1444/1583] [D loss: 0.492842] [G loss: 0.195443]\n",
            "[Epoch 1/2] [Batch 1445/1583] [D loss: 0.510059] [G loss: 0.196780]\n",
            "[Epoch 1/2] [Batch 1446/1583] [D loss: 0.548095] [G loss: 0.203653]\n",
            "[Epoch 1/2] [Batch 1447/1583] [D loss: 0.587008] [G loss: 0.207320]\n",
            "[Epoch 1/2] [Batch 1448/1583] [D loss: 0.590462] [G loss: 0.202302]\n",
            "[Epoch 1/2] [Batch 1449/1583] [D loss: 0.560732] [G loss: 0.212311]\n",
            "[Epoch 1/2] [Batch 1450/1583] [D loss: 0.586138] [G loss: 0.214287]\n",
            "[Epoch 1/2] [Batch 1451/1583] [D loss: 0.550749] [G loss: 0.203293]\n",
            "[Epoch 1/2] [Batch 1452/1583] [D loss: 0.573873] [G loss: 0.208461]\n",
            "[Epoch 1/2] [Batch 1453/1583] [D loss: 0.552450] [G loss: 0.205800]\n",
            "[Epoch 1/2] [Batch 1454/1583] [D loss: 0.576144] [G loss: 0.209636]\n",
            "[Epoch 1/2] [Batch 1455/1583] [D loss: 0.554601] [G loss: 0.207192]\n",
            "[Epoch 1/2] [Batch 1456/1583] [D loss: 0.573734] [G loss: 0.206500]\n",
            "[Epoch 1/2] [Batch 1457/1583] [D loss: 0.528784] [G loss: 0.209912]\n",
            "[Epoch 1/2] [Batch 1458/1583] [D loss: 0.570511] [G loss: 0.211572]\n",
            "[Epoch 1/2] [Batch 1459/1583] [D loss: 0.579933] [G loss: 0.218839]\n",
            "[Epoch 1/2] [Batch 1460/1583] [D loss: 0.565666] [G loss: 0.203254]\n",
            "[Epoch 1/2] [Batch 1461/1583] [D loss: 0.570317] [G loss: 0.213794]\n",
            "[Epoch 1/2] [Batch 1462/1583] [D loss: 0.568771] [G loss: 0.201976]\n",
            "[Epoch 1/2] [Batch 1463/1583] [D loss: 0.568244] [G loss: 0.207418]\n",
            "[Epoch 1/2] [Batch 1464/1583] [D loss: 0.559064] [G loss: 0.205882]\n",
            "[Epoch 1/2] [Batch 1465/1583] [D loss: 0.536909] [G loss: 0.205248]\n",
            "[Epoch 1/2] [Batch 1466/1583] [D loss: 0.600675] [G loss: 0.210523]\n",
            "[Epoch 1/2] [Batch 1467/1583] [D loss: 0.563939] [G loss: 0.202737]\n",
            "[Epoch 1/2] [Batch 1468/1583] [D loss: 0.609198] [G loss: 0.209112]\n",
            "[Epoch 1/2] [Batch 1469/1583] [D loss: 0.555918] [G loss: 0.201526]\n",
            "[Epoch 1/2] [Batch 1470/1583] [D loss: 0.541344] [G loss: 0.212858]\n",
            "[Epoch 1/2] [Batch 1471/1583] [D loss: 0.564014] [G loss: 0.216351]\n",
            "[Epoch 1/2] [Batch 1472/1583] [D loss: 0.546126] [G loss: 0.207353]\n",
            "[Epoch 1/2] [Batch 1473/1583] [D loss: 0.498042] [G loss: 0.204968]\n",
            "[Epoch 1/2] [Batch 1474/1583] [D loss: 0.551563] [G loss: 0.206298]\n",
            "[Epoch 1/2] [Batch 1475/1583] [D loss: 0.563529] [G loss: 0.211163]\n",
            "[Epoch 1/2] [Batch 1476/1583] [D loss: 0.555165] [G loss: 0.213600]\n",
            "[Epoch 1/2] [Batch 1477/1583] [D loss: 0.499118] [G loss: 0.206752]\n",
            "[Epoch 1/2] [Batch 1478/1583] [D loss: 0.531686] [G loss: 0.207935]\n",
            "[Epoch 1/2] [Batch 1479/1583] [D loss: 0.549223] [G loss: 0.206427]\n",
            "[Epoch 1/2] [Batch 1480/1583] [D loss: 0.571514] [G loss: 0.204953]\n",
            "[Epoch 1/2] [Batch 1481/1583] [D loss: 0.585379] [G loss: 0.216881]\n",
            "[Epoch 1/2] [Batch 1482/1583] [D loss: 0.562617] [G loss: 0.207199]\n",
            "[Epoch 1/2] [Batch 1483/1583] [D loss: 0.568032] [G loss: 0.216373]\n",
            "[Epoch 1/2] [Batch 1484/1583] [D loss: 0.553630] [G loss: 0.211226]\n",
            "[Epoch 1/2] [Batch 1485/1583] [D loss: 0.586464] [G loss: 0.211555]\n",
            "[Epoch 1/2] [Batch 1486/1583] [D loss: 0.558614] [G loss: 0.199605]\n",
            "[Epoch 1/2] [Batch 1487/1583] [D loss: 0.547774] [G loss: 0.211560]\n",
            "[Epoch 1/2] [Batch 1488/1583] [D loss: 0.588923] [G loss: 0.213218]\n",
            "[Epoch 1/2] [Batch 1489/1583] [D loss: 0.566379] [G loss: 0.207068]\n",
            "[Epoch 1/2] [Batch 1490/1583] [D loss: 0.566324] [G loss: 0.204880]\n",
            "[Epoch 1/2] [Batch 1491/1583] [D loss: 0.505175] [G loss: 0.204990]\n",
            "[Epoch 1/2] [Batch 1492/1583] [D loss: 0.590013] [G loss: 0.204227]\n",
            "[Epoch 1/2] [Batch 1493/1583] [D loss: 0.619739] [G loss: 0.214822]\n",
            "[Epoch 1/2] [Batch 1494/1583] [D loss: 0.545616] [G loss: 0.208540]\n",
            "[Epoch 1/2] [Batch 1495/1583] [D loss: 0.567501] [G loss: 0.215185]\n",
            "[Epoch 1/2] [Batch 1496/1583] [D loss: 0.587164] [G loss: 0.210182]\n",
            "[Epoch 1/2] [Batch 1497/1583] [D loss: 0.561204] [G loss: 0.206558]\n",
            "[Epoch 1/2] [Batch 1498/1583] [D loss: 0.599729] [G loss: 0.215410]\n",
            "[Epoch 1/2] [Batch 1499/1583] [D loss: 0.601640] [G loss: 0.213303]\n",
            "[Epoch 1/2] [Batch 1500/1583] [D loss: 0.613792] [G loss: 0.208563]\n",
            "[Epoch 1/2] [Batch 1501/1583] [D loss: 0.547196] [G loss: 0.204282]\n",
            "[Epoch 1/2] [Batch 1502/1583] [D loss: 0.612577] [G loss: 0.209350]\n",
            "[Epoch 1/2] [Batch 1503/1583] [D loss: 0.536712] [G loss: 0.202104]\n",
            "[Epoch 1/2] [Batch 1504/1583] [D loss: 0.585948] [G loss: 0.210296]\n",
            "[Epoch 1/2] [Batch 1505/1583] [D loss: 0.558088] [G loss: 0.201185]\n",
            "[Epoch 1/2] [Batch 1506/1583] [D loss: 0.589862] [G loss: 0.210309]\n",
            "[Epoch 1/2] [Batch 1507/1583] [D loss: 0.538952] [G loss: 0.208196]\n",
            "[Epoch 1/2] [Batch 1508/1583] [D loss: 0.562943] [G loss: 0.215903]\n",
            "[Epoch 1/2] [Batch 1509/1583] [D loss: 0.516651] [G loss: 0.201133]\n",
            "[Epoch 1/2] [Batch 1510/1583] [D loss: 0.575734] [G loss: 0.208984]\n",
            "[Epoch 1/2] [Batch 1511/1583] [D loss: 0.601807] [G loss: 0.205039]\n",
            "[Epoch 1/2] [Batch 1512/1583] [D loss: 0.578584] [G loss: 0.218284]\n",
            "[Epoch 1/2] [Batch 1513/1583] [D loss: 0.597504] [G loss: 0.211204]\n",
            "[Epoch 1/2] [Batch 1514/1583] [D loss: 0.572791] [G loss: 0.217340]\n",
            "[Epoch 1/2] [Batch 1515/1583] [D loss: 0.545153] [G loss: 0.203350]\n",
            "[Epoch 1/2] [Batch 1516/1583] [D loss: 0.555014] [G loss: 0.206336]\n",
            "[Epoch 1/2] [Batch 1517/1583] [D loss: 0.556549] [G loss: 0.207094]\n",
            "[Epoch 1/2] [Batch 1518/1583] [D loss: 0.541591] [G loss: 0.205650]\n",
            "[Epoch 1/2] [Batch 1519/1583] [D loss: 0.584386] [G loss: 0.205327]\n",
            "[Epoch 1/2] [Batch 1520/1583] [D loss: 0.568738] [G loss: 0.215654]\n",
            "[Epoch 1/2] [Batch 1521/1583] [D loss: 0.553270] [G loss: 0.204272]\n",
            "[Epoch 1/2] [Batch 1522/1583] [D loss: 0.572602] [G loss: 0.204133]\n",
            "[Epoch 1/2] [Batch 1523/1583] [D loss: 0.574076] [G loss: 0.208915]\n",
            "[Epoch 1/2] [Batch 1524/1583] [D loss: 0.615150] [G loss: 0.206942]\n",
            "[Epoch 1/2] [Batch 1525/1583] [D loss: 0.561310] [G loss: 0.204534]\n",
            "[Epoch 1/2] [Batch 1526/1583] [D loss: 0.562849] [G loss: 0.209378]\n",
            "[Epoch 1/2] [Batch 1527/1583] [D loss: 0.570016] [G loss: 0.218158]\n",
            "[Epoch 1/2] [Batch 1528/1583] [D loss: 0.552233] [G loss: 0.205999]\n",
            "[Epoch 1/2] [Batch 1529/1583] [D loss: 0.553510] [G loss: 0.204908]\n",
            "[Epoch 1/2] [Batch 1530/1583] [D loss: 0.552037] [G loss: 0.205475]\n",
            "[Epoch 1/2] [Batch 1531/1583] [D loss: 0.542865] [G loss: 0.200726]\n",
            "[Epoch 1/2] [Batch 1532/1583] [D loss: 0.525643] [G loss: 0.213346]\n",
            "[Epoch 1/2] [Batch 1533/1583] [D loss: 0.535007] [G loss: 0.199508]\n",
            "[Epoch 1/2] [Batch 1534/1583] [D loss: 0.584292] [G loss: 0.211336]\n",
            "[Epoch 1/2] [Batch 1535/1583] [D loss: 0.542564] [G loss: 0.199595]\n",
            "[Epoch 1/2] [Batch 1536/1583] [D loss: 0.569767] [G loss: 0.224983]\n",
            "[Epoch 1/2] [Batch 1537/1583] [D loss: 0.595034] [G loss: 0.210142]\n",
            "[Epoch 1/2] [Batch 1538/1583] [D loss: 0.575494] [G loss: 0.203563]\n",
            "[Epoch 1/2] [Batch 1539/1583] [D loss: 0.546922] [G loss: 0.208170]\n",
            "[Epoch 1/2] [Batch 1540/1583] [D loss: 0.540781] [G loss: 0.209652]\n",
            "[Epoch 1/2] [Batch 1541/1583] [D loss: 0.515128] [G loss: 0.202992]\n",
            "[Epoch 1/2] [Batch 1542/1583] [D loss: 0.565205] [G loss: 0.201288]\n",
            "[Epoch 1/2] [Batch 1543/1583] [D loss: 0.601494] [G loss: 0.212606]\n",
            "[Epoch 1/2] [Batch 1544/1583] [D loss: 0.551590] [G loss: 0.201275]\n",
            "[Epoch 1/2] [Batch 1545/1583] [D loss: 0.549797] [G loss: 0.208841]\n",
            "[Epoch 1/2] [Batch 1546/1583] [D loss: 0.528808] [G loss: 0.203071]\n",
            "[Epoch 1/2] [Batch 1547/1583] [D loss: 0.567472] [G loss: 0.202269]\n",
            "[Epoch 1/2] [Batch 1548/1583] [D loss: 0.617766] [G loss: 0.211009]\n",
            "[Epoch 1/2] [Batch 1549/1583] [D loss: 0.568264] [G loss: 0.211151]\n",
            "[Epoch 1/2] [Batch 1550/1583] [D loss: 0.557760] [G loss: 0.202299]\n",
            "[Epoch 1/2] [Batch 1551/1583] [D loss: 0.556727] [G loss: 0.215300]\n",
            "[Epoch 1/2] [Batch 1552/1583] [D loss: 0.582237] [G loss: 0.208572]\n",
            "[Epoch 1/2] [Batch 1553/1583] [D loss: 0.547925] [G loss: 0.205187]\n",
            "[Epoch 1/2] [Batch 1554/1583] [D loss: 0.540043] [G loss: 0.211537]\n",
            "[Epoch 1/2] [Batch 1555/1583] [D loss: 0.536064] [G loss: 0.205644]\n",
            "[Epoch 1/2] [Batch 1556/1583] [D loss: 0.561065] [G loss: 0.214477]\n",
            "[Epoch 1/2] [Batch 1557/1583] [D loss: 0.578325] [G loss: 0.212228]\n",
            "[Epoch 1/2] [Batch 1558/1583] [D loss: 0.553638] [G loss: 0.205893]\n",
            "[Epoch 1/2] [Batch 1559/1583] [D loss: 0.587303] [G loss: 0.211069]\n",
            "[Epoch 1/2] [Batch 1560/1583] [D loss: 0.542784] [G loss: 0.210148]\n",
            "[Epoch 1/2] [Batch 1561/1583] [D loss: 0.584769] [G loss: 0.220048]\n",
            "[Epoch 1/2] [Batch 1562/1583] [D loss: 0.587302] [G loss: 0.208183]\n",
            "[Epoch 1/2] [Batch 1563/1583] [D loss: 0.518251] [G loss: 0.204723]\n",
            "[Epoch 1/2] [Batch 1564/1583] [D loss: 0.532475] [G loss: 0.205685]\n",
            "[Epoch 1/2] [Batch 1565/1583] [D loss: 0.579981] [G loss: 0.203288]\n",
            "[Epoch 1/2] [Batch 1566/1583] [D loss: 0.575012] [G loss: 0.211858]\n",
            "[Epoch 1/2] [Batch 1567/1583] [D loss: 0.581200] [G loss: 0.212197]\n",
            "[Epoch 1/2] [Batch 1568/1583] [D loss: 0.595234] [G loss: 0.204928]\n",
            "[Epoch 1/2] [Batch 1569/1583] [D loss: 0.549138] [G loss: 0.203825]\n",
            "[Epoch 1/2] [Batch 1570/1583] [D loss: 0.594884] [G loss: 0.201650]\n",
            "[Epoch 1/2] [Batch 1571/1583] [D loss: 0.569837] [G loss: 0.204242]\n",
            "[Epoch 1/2] [Batch 1572/1583] [D loss: 0.528129] [G loss: 0.213504]\n",
            "[Epoch 1/2] [Batch 1573/1583] [D loss: 0.558053] [G loss: 0.206787]\n",
            "[Epoch 1/2] [Batch 1574/1583] [D loss: 0.579965] [G loss: 0.201973]\n",
            "[Epoch 1/2] [Batch 1575/1583] [D loss: 0.547030] [G loss: 0.206128]\n",
            "[Epoch 1/2] [Batch 1576/1583] [D loss: 0.567998] [G loss: 0.216291]\n",
            "[Epoch 1/2] [Batch 1577/1583] [D loss: 0.543449] [G loss: 0.201676]\n",
            "[Epoch 1/2] [Batch 1578/1583] [D loss: 0.547346] [G loss: 0.207627]\n",
            "[Epoch 1/2] [Batch 1579/1583] [D loss: 0.540735] [G loss: 0.209718]\n",
            "[Epoch 1/2] [Batch 1580/1583] [D loss: 0.599376] [G loss: 0.214038]\n",
            "[Epoch 1/2] [Batch 1581/1583] [D loss: 0.587799] [G loss: 0.217886]\n",
            "[Epoch 1/2] [Batch 1582/1583] [D loss: 0.584712] [G loss: 0.211569]\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(n_epochs):\n",
        "    for i, imgs in enumerate(celeba_dataloader):\n",
        "\n",
        "        valid = Variable(Tensor(imgs.shape[0], 1).fill_(1.0), requires_grad=False)\n",
        "        fake = Variable(Tensor(imgs.shape[0], 1).fill_(0.0), requires_grad=False)\n",
        "\n",
        "        real_imgs = Variable(imgs.type(Tensor))\n",
        "\n",
        "        # -----------------\n",
        "        #  Генератор\n",
        "        # -----------------\n",
        "\n",
        "        optimizer_G.zero_grad()\n",
        "\n",
        "        encoded_imgs = encoder(real_imgs)\n",
        "        decoded_imgs = decoder(encoded_imgs)\n",
        "\n",
        "        g_loss = 0.001 * adversarial_loss(discriminator(encoded_imgs), valid) + 0.999 * pixelwise_loss(\n",
        "            decoded_imgs, real_imgs\n",
        "        )\n",
        "\n",
        "        g_loss.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "        # ---------------------\n",
        "        #  Дискриминатор\n",
        "        # ---------------------\n",
        "\n",
        "        optimizer_D.zero_grad()\n",
        "\n",
        "        z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], latent_dim))))\n",
        "\n",
        "        real_loss = adversarial_loss(discriminator(z), valid)\n",
        "        fake_loss = adversarial_loss(discriminator(encoded_imgs.detach()), fake)\n",
        "        d_loss = 0.5 * (real_loss + fake_loss)\n",
        "\n",
        "        d_loss.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        print(\n",
        "            \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n",
        "            % (epoch, n_epochs, i, len(celeba_dataloader), d_loss.item(), g_loss.item())\n",
        "        )\n",
        "\n",
        "        batches_done = epoch * len(celeba_dataloader) + i\n",
        "        if batches_done % sample_interval == 0:\n",
        "            sample_image(n_row=10, batches_done=batches_done)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
